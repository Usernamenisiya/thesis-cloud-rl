{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe41eb39",
      "metadata": {
        "id": "fe41eb39"
      },
      "source": [
        "## 1Ô∏è‚É£ Clone & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fe28e572",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe28e572",
        "outputId": "cc2f0141-70b5-4fb5-8678-e3ad0435a066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'thesis-cloud-rl'...\n",
            "remote: Enumerating objects: 1765, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 1765 (delta 8), reused 16 (delta 6), pack-reused 1742 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1765/1765), 654.03 MiB | 16.78 MiB/s, done.\n",
            "Resolving deltas: 100% (244/244), done.\n",
            "Updating files: 100% (2632/2632), done.\n",
            "/content/thesis-cloud-rl/thesis-cloud-rl\n",
            "/content/thesis-cloud-rl/thesis-cloud-rl\n",
            "total 40064\n",
            "drwxr-xr-x 4 root root     4096 Jan 12 14:24 .\n",
            "drwxr-xr-x 5 root root     4096 Jan 12 14:24 ..\n",
            "-rw-r--r-- 1 root root     3567 Jan 12 14:24 analyze_data_distribution.py\n",
            "-rw-r--r-- 1 root root     5945 Jan 12 14:24 cloudsen12_loader.py\n",
            "-rw-r--r-- 1 root root     1661 Jan 12 14:24 cnn_inference.py\n",
            "-rw-r--r-- 1 root root   200302 Jan 12 14:24 colab_training.ipynb\n",
            "drwxr-xr-x 3 root root     4096 Jan 12 14:24 data\n",
            "-rw-r--r-- 1 root root     4697 Jan 12 14:24 data_download.py\n",
            "-rw-r--r-- 1 root root     4276 Jan 12 14:24 download_cloudsen12_subset.py\n",
            "-rw-r--r-- 1 root root     5988 Jan 12 14:24 enhanced_cnn_baseline.py\n",
            "-rw-r--r-- 1 root root     5458 Jan 12 14:24 evaluate_on_test_set.py\n",
            "-rw-r--r-- 1 root root     4788 Jan 12 14:24 evaluate_rl_model.py\n",
            "-rw-r--r-- 1 root root     3564 Jan 12 14:24 evaluate_saved_model.py\n",
            "-rw-r--r-- 1 root root     9695 Jan 12 14:24 finetune_cnn_baseline.py\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/Usernamenisiya/thesis-cloud-rl.git\n",
        "%cd thesis-cloud-rl\n",
        "\n",
        "# Verify\n",
        "!pwd\n",
        "!ls -la | head -15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "690b0055",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "690b0055",
        "outputId": "866676c2-5691-405b-dc10-197c190e3819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.24.0+cu126)\n",
            "Requirement already satisfied: s2cloudless in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.7.3)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.7.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.4.4)\n",
            "Requirement already satisfied: zarr in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.1.5)\n",
            "Requirement already satisfied: shimmy>=2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.15.0->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: lightgbm>=2.0.11 in /usr/local/lib/python3.12/dist-packages (from s2cloudless->-r requirements.txt (line 3)) (4.6.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from s2cloudless->-r requirements.txt (line 3)) (4.12.0.88)\n",
            "Requirement already satisfied: sentinelhub>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from s2cloudless->-r requirements.txt (line 3)) (3.11.3)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym->-r requirements.txt (line 5)) (0.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (2025.11.12)\n",
            "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (1.1.1.2)\n",
            "Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.12/dist-packages (from zarr->-r requirements.txt (line 11)) (0.8.1.post1)\n",
            "Requirement already satisfied: google-crc32c>=1.5 in /usr/local/lib/python3.12/dist-packages (from zarr->-r requirements.txt (line 11)) (1.7.1)\n",
            "Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.12/dist-packages (from zarr->-r requirements.txt (line 11)) (0.16.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr->-r requirements.txt (line 11)) (6.0.3)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3->-r requirements.txt (line 4)) (0.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: aenum>=2.1.4 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.1.16)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (0.6.7)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.3.1)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.1.2)\n",
            "Requirement already satisfied: tifffile>=2020.9.30 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2025.12.12)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.4.0)\n",
            "Requirement already satisfied: tomli-w in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: utm in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3->-r requirements.txt (line 4)) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n",
            "‚úÖ Dependencies installed\n",
            "PyTorch: 2.9.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install gymnasium  # Updated from deprecated gym\n",
        "\n",
        "import torch\n",
        "import stable_baselines3\n",
        "import rasterio\n",
        "\n",
        "print(\"‚úÖ Dependencies installed\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ced755bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ced755bc",
        "outputId": "0756d34b-9437-41f2-b0e3-e13ee1f682c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Jan 12 14:25:40 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             42W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "‚úÖ Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\n‚úÖ Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2974c679",
      "metadata": {
        "id": "2974c679"
      },
      "source": [
        "## 2Ô∏è‚É£ Setup CloudSEN12 Real Ground Truth Data\n",
        "\n",
        "**Using CloudSEN12 expert-labeled dataset:**\n",
        "- Already downloaded: 100 patches in `Colab_Data/cloudsen12_subset/`\n",
        "- Process with `cloudsen12_loader.py` to extract 10 bands\n",
        "- **26M pixels** for robust evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1c8ad7c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c8ad7c8",
        "outputId": "05eff114-947c-4e40-87c1-e86e694ef773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ CloudSEN12 data found: 100 patches\n",
            "üìÇ Location: /content/drive/MyDrive/Colab_Data/cloudsen12_subset\n",
            "\n",
            "üîß Processing CloudSEN12 patches...\n",
            "\n",
            "============================================================\n",
            "üîß Preparing CloudSEN12 for Training\n",
            "============================================================\n",
            "============================================================\n",
            "üì¶ Loading CloudSEN12 Data\n",
            "============================================================\n",
            "\n",
            "‚úÖ Found 100 patches to load\n",
            "\n",
            "\n",
            "‚úÖ Successfully loaded 100 patches\n",
            "üìä Image shape: (512, 512, 10)\n",
            "üìä Mask shape: (512, 512)\n",
            "üìä Image bands: 10\n",
            "üìä Cloud coverage: 16.0%\n",
            "\n",
            "üíæ Saving 100 patches to data/cloudsen12_processed\n",
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:366: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = writer(\n",
            "  Saved: patch_000\n",
            "  Saved: patch_001\n",
            "  Saved: patch_002\n",
            "  Saved: patch_003\n",
            "  Saved: patch_004\n",
            "  Saved: patch_005\n",
            "  Saved: patch_006\n",
            "  Saved: patch_007\n",
            "  Saved: patch_008\n",
            "  Saved: patch_009\n",
            "  Saved: patch_010\n",
            "  Saved: patch_011\n",
            "  Saved: patch_012\n",
            "  Saved: patch_013\n",
            "  Saved: patch_014\n",
            "  Saved: patch_015\n",
            "  Saved: patch_016\n",
            "  Saved: patch_017\n",
            "  Saved: patch_018\n",
            "  Saved: patch_019\n",
            "  Saved: patch_020\n",
            "  Saved: patch_021\n",
            "  Saved: patch_022\n",
            "  Saved: patch_023\n",
            "  Saved: patch_024\n",
            "  Saved: patch_025\n",
            "  Saved: patch_026\n",
            "  Saved: patch_027\n",
            "  Saved: patch_028\n",
            "  Saved: patch_029\n",
            "  Saved: patch_030\n",
            "  Saved: patch_031\n",
            "  Saved: patch_032\n",
            "  Saved: patch_033\n",
            "  Saved: patch_034\n",
            "  Saved: patch_035\n",
            "  Saved: patch_036\n",
            "  Saved: patch_037\n",
            "  Saved: patch_038\n",
            "  Saved: patch_039\n",
            "  Saved: patch_040\n",
            "  Saved: patch_041\n",
            "  Saved: patch_042\n",
            "  Saved: patch_043\n",
            "  Saved: patch_044\n",
            "  Saved: patch_045\n",
            "  Saved: patch_046\n",
            "  Saved: patch_047\n",
            "  Saved: patch_048\n",
            "  Saved: patch_049\n",
            "  Saved: patch_050\n",
            "  Saved: patch_051\n",
            "  Saved: patch_052\n",
            "  Saved: patch_053\n",
            "  Saved: patch_054\n",
            "  Saved: patch_055\n",
            "  Saved: patch_056\n",
            "  Saved: patch_057\n",
            "  Saved: patch_058\n",
            "  Saved: patch_059\n",
            "  Saved: patch_060\n",
            "  Saved: patch_061\n",
            "  Saved: patch_062\n",
            "  Saved: patch_063\n",
            "  Saved: patch_064\n",
            "  Saved: patch_065\n",
            "  Saved: patch_066\n",
            "  Saved: patch_067\n",
            "  Saved: patch_068\n",
            "  Saved: patch_069\n",
            "  Saved: patch_070\n",
            "  Saved: patch_071\n",
            "  Saved: patch_072\n",
            "  Saved: patch_073\n",
            "  Saved: patch_074\n",
            "  Saved: patch_075\n",
            "  Saved: patch_076\n",
            "  Saved: patch_077\n",
            "  Saved: patch_078\n",
            "  Saved: patch_079\n",
            "  Saved: patch_080\n",
            "  Saved: patch_081\n",
            "  Saved: patch_082\n",
            "  Saved: patch_083\n",
            "  Saved: patch_084\n",
            "  Saved: patch_085\n",
            "  Saved: patch_086\n",
            "  Saved: patch_087\n",
            "  Saved: patch_088\n",
            "  Saved: patch_089\n",
            "  Saved: patch_090\n",
            "  Saved: patch_091\n",
            "  Saved: patch_092\n",
            "  Saved: patch_093\n",
            "  Saved: patch_094\n",
            "  Saved: patch_095\n",
            "  Saved: patch_096\n",
            "  Saved: patch_097\n",
            "  Saved: patch_098\n",
            "  Saved: patch_099\n",
            "\n",
            "‚úÖ Data preparation complete!\n",
            "üìÇ Files saved to: data/cloudsen12_processed\n",
            "\n",
            "üéØ Ready for training with real ground truth!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify CloudSEN12 data exists\n",
        "cloudsen_path = '/content/drive/MyDrive/Colab_Data/cloudsen12_subset'\n",
        "\n",
        "if os.path.exists(cloudsen_path):\n",
        "    num_patches = len([d for d in Path(cloudsen_path).iterdir() if d.is_dir()])\n",
        "    print(f\"‚úÖ CloudSEN12 data found: {num_patches} patches\")\n",
        "    print(f\"üìÇ Location: {cloudsen_path}\")\n",
        "\n",
        "    # Process CloudSEN12 data with loader (extracts 10 bands, converts masks)\n",
        "    print(\"\\nüîß Processing CloudSEN12 patches...\")\n",
        "    !python cloudsen12_loader.py\n",
        "else:\n",
        "    print(f\"‚ùå CloudSEN12 data not found at: {cloudsen_path}\")\n",
        "    print(\"Please run CloudSEN12 download notebook first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "45e4f059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45e4f059",
        "outputId": "30debb7c-3f25-4c7b-d211-a81f41ed4196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CloudSEN12 data processed successfully!\n",
            "üìä Found 100 image patches\n",
            "üìä Found 100 mask patches\n",
            "\n",
            "üéØ Ready for training with real ground truth!\n"
          ]
        }
      ],
      "source": [
        "# Verify processed CloudSEN12 data\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "processed_dir = 'data/cloudsen12_processed'\n",
        "image_files = glob.glob(f'{processed_dir}/*_image.tif')\n",
        "mask_files = glob.glob(f'{processed_dir}/*_mask.tif')\n",
        "\n",
        "if len(image_files) > 0 and len(mask_files) > 0:\n",
        "    print(f\"‚úÖ CloudSEN12 data processed successfully!\")\n",
        "    print(f\"üìä Found {len(image_files)} image patches\")\n",
        "    print(f\"üìä Found {len(mask_files)} mask patches\")\n",
        "    print(\"\\nüéØ Ready for training with real ground truth!\")\n",
        "else:\n",
        "    print(\"‚ùå Processed data not found\")\n",
        "    print(\"Please check cloudsen12_loader.py output for errors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71cc30ed",
      "metadata": {
        "id": "71cc30ed"
      },
      "source": [
        "## 3Ô∏è‚É£ Check CNN Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2f381a12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f381a12",
        "outputId": "5ebfcda8-521f-4e10-84af-ff81e3a9081d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß† Evaluating CNN Baseline on CloudSEN12 Real Ground Truth\n",
            "============================================================\n",
            "Processing 100 patches...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Evaluated on 100 CloudSEN12 patches\n",
            "üìä Total pixels: 26,214,400\n",
            "\n",
            "üß† CNN Baseline (Real Ground Truth):\n",
            "  Accuracy:  0.6652\n",
            "  Precision: 0.1313\n",
            "  Recall:    0.1935\n",
            "  F1-Score:  0.1564\n",
            "üìä CNN predicted: 6,198,343 cloud pixels (23.6%)\n",
            "\n",
            "üìä Ground truth: 4,205,740 cloud pixels (16.0%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# Load and test CNN baseline on CloudSEN12 patches\n",
        "from cnn_inference import load_sentinel2_image, get_cloud_mask\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "print(\"üß† Evaluating CNN Baseline on CloudSEN12 Real Ground Truth\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load all processed CloudSEN12 patches\n",
        "image_files = sorted(glob.glob('data/cloudsen12_processed/*_image.tif'))\n",
        "mask_files = sorted(glob.glob('data/cloudsen12_processed/*_mask.tif'))\n",
        "\n",
        "all_gt = []\n",
        "all_cnn = []\n",
        "\n",
        "print(f\"Processing {len(image_files)} patches...\\n\")\n",
        "\n",
        "for img_path, mask_path in zip(image_files, mask_files):  # Use ALL patches\n",
        "    # Load image and get CNN prediction\n",
        "    image = load_sentinel2_image(img_path)\n",
        "    cnn_prob = get_cloud_mask(image)\n",
        "\n",
        "    # Load real ground truth\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        ground_truth = src.read(1)\n",
        "\n",
        "    # Binary conversion\n",
        "    gt_binary = (ground_truth > 0).astype(np.uint8)\n",
        "    cnn_binary = (cnn_prob > 0.5).astype(np.uint8)\n",
        "\n",
        "    all_gt.append(gt_binary.flatten())\n",
        "    all_cnn.append(cnn_binary.flatten())\n",
        "\n",
        "# Combine all patches\n",
        "all_gt = np.concatenate(all_gt)\n",
        "all_cnn = np.concatenate(all_cnn)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(all_gt, all_cnn)\n",
        "precision = precision_score(all_gt, all_cnn, zero_division=0)\n",
        "recall = recall_score(all_gt, all_cnn, zero_division=0)\n",
        "f1 = f1_score(all_gt, all_cnn, zero_division=0)\n",
        "\n",
        "print(f\"\\nüìä Evaluated on {len(image_files)} CloudSEN12 patches\")\n",
        "print(f\"üìä Total pixels: {len(all_gt):,}\")\n",
        "print(\"\\nüß† CNN Baseline (Real Ground Truth):\")\n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "\n",
        "print(f\"  F1-Score:  {f1:.4f}\")\n",
        "print(f\"üìä CNN predicted: {all_cnn.sum():,} cloud pixels ({all_cnn.mean()*100:.1f}%)\")\n",
        "print(f\"\\nüìä Ground truth: {all_gt.sum():,} cloud pixels ({all_gt.mean()*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "088c8f8a",
      "metadata": {
        "id": "088c8f8a"
      },
      "source": [
        "## 4Ô∏è‚É£ Pull Latest Code & Train PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6f2470c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f2470c4",
        "outputId": "c5be55fa-4043-4ebc-e302-0a8b869a492b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/Usernamenisiya/thesis-cloud-rl\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "‚úÖ Repository updated\n"
          ]
        }
      ],
      "source": [
        "# Get latest code with PPO improvements\n",
        "!git pull origin master\n",
        "print(\"‚úÖ Repository updated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e3c35457",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3c35457",
        "outputId": "46642c52-6a09-4513-a601-fa819da0e0f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Finding optimal CNN threshold...\n",
            "============================================================\n",
            "üîç Optimizing CNN Threshold on CloudSEN12\n",
            "============================================================\n",
            "\n",
            "üìÇ Loading 100 CloudSEN12 patches...\n",
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
            "‚úÖ Data loaded\n",
            "\n",
            "üî¨ Testing thresholds...\n",
            "  Threshold 0.10: F1=0.2435, Acc=0.3680, Prec=0.1507, Rec=0.6341\n",
            "  Threshold 0.15: F1=0.2293, Acc=0.4220, Prec=0.1459, Rec=0.5360\n",
            "  Threshold 0.20: F1=0.2216, Acc=0.4737, Prec=0.1453, Rec=0.4670\n",
            "  Threshold 0.25: F1=0.2122, Acc=0.5077, Prec=0.1427, Rec=0.4132\n",
            "  Threshold 0.30: F1=0.2046, Acc=0.5424, Prec=0.1418, Rec=0.3668\n",
            "  Threshold 0.35: F1=0.1950, Acc=0.5765, Prec=0.1403, Rec=0.3198\n",
            "  Threshold 0.40: F1=0.1829, Acc=0.6090, Prec=0.1376, Rec=0.2728\n",
            "  Threshold 0.45: F1=0.1709, Acc=0.6414, Prec=0.1359, Rec=0.2304\n",
            "  Threshold 0.50: F1=0.1564, Acc=0.6652, Prec=0.1313, Rec=0.1935\n",
            "  Threshold 0.55: F1=0.1411, Acc=0.6822, Prec=0.1246, Rec=0.1627\n",
            "  Threshold 0.60: F1=0.1285, Acc=0.6935, Prec=0.1181, Rec=0.1409\n",
            "  Threshold 0.65: F1=0.1160, Acc=0.7014, Prec=0.1105, Rec=0.1221\n",
            "  Threshold 0.70: F1=0.1004, Acc=0.7098, Prec=0.0998, Rec=0.1009\n",
            "  Threshold 0.75: F1=0.0802, Acc=0.7169, Prec=0.0838, Rec=0.0769\n",
            "  Threshold 0.80: F1=0.0501, Acc=0.7232, Prec=0.0558, Rec=0.0455\n",
            "  Threshold 0.85: F1=0.0366, Acc=0.7302, Prec=0.0428, Rec=0.0319\n",
            "  Threshold 0.90: F1=0.0242, Acc=0.7379, Prec=0.0301, Rec=0.0203\n",
            "\n",
            "============================================================\n",
            "üéØ OPTIMAL CNN BASELINE\n",
            "============================================================\n",
            "\n",
            "‚úÖ Best threshold: 0.10\n",
            "\n",
            "üß† Optimized CNN Performance:\n",
            "  Accuracy:  0.3680\n",
            "  Precision: 0.1507\n",
            "  Recall:    0.6341\n",
            "  F1-Score:  0.2435\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/thesis-cloud-rl/thesis-cloud-rl/optimize_cnn_threshold.py\", line 110, in <module>\n",
            "    optimize_cnn_threshold()\n",
            "  File \"/content/thesis-cloud-rl/thesis-cloud-rl/optimize_cnn_threshold.py\", line 97, in optimize_cnn_threshold\n",
            "    with open('results/optimal_cnn_threshold.json', 'w') as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'results/optimal_cnn_threshold.json'\n"
          ]
        }
      ],
      "source": [
        "# Optimize CNN threshold for fair baseline comparison\n",
        "print(\"üîç Finding optimal CNN threshold...\")\n",
        "!python optimize_cnn_threshold.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bc358b",
      "metadata": {},
      "source": [
        "## üéØ Comprehensive Approach: Three Methods\n",
        "\n",
        "We'll implement three approaches with progressive improvements:\n",
        "\n",
        "1. **Optimal Threshold (Classical)** - Grid search, 5 minutes\n",
        "2. **CNN Fine-Tuning (Transfer Learning)** - Domain adaptation, 30 minutes  \n",
        "3. **RL Threshold Refinement (Novel)** - Spatially-adaptive thresholds, 1 hour\n",
        "\n",
        "This provides:\n",
        "- ‚úÖ Multiple baselines for comparison\n",
        "- ‚úÖ Progressive improvement narrative\n",
        "- ‚úÖ Novel RL contribution that actually improves results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dbf35e3",
      "metadata": {},
      "source": [
        "### üìä Approach 1: Optimal Threshold (Grid Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c9a4d5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimal threshold grid search (fast, no training)\n",
        "print(\"üîç Finding optimal CNN threshold via grid search...\")\n",
        "print(\"Testing thresholds from 0.1 to 0.9 on train set\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python optimize_threshold_grid_search.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91149fe",
      "metadata": {},
      "source": [
        "### üî• Approach 2: CNN Fine-Tuning (Transfer Learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510d569d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tune CNN on CloudSEN12 train set (30 minutes)\n",
        "print(\"üî• Fine-tuning CNN on CloudSEN12 with transfer learning...\")\n",
        "print(\"Low learning rate (1e-5) for 10 epochs\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python finetune_cnn_cloudsen12.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d901a81",
      "metadata": {},
      "source": [
        "### üéØ Approach 3: RL Adaptive Threshold Refinement (Novel Contribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce9f239",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RL-based adaptive threshold refinement (1 hour)\n",
        "print(\"üéØ Training RL agent for spatially-adaptive thresholds...\")\n",
        "print(\"Agent learns to adjust CNN threshold per patch based on local context\")\n",
        "print(\"Action: continuous threshold delta [-0.3, +0.3]\")\n",
        "print(\"Reward: F1-score improvement over baseline\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python train_ppo_threshold_refinement.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e98a86",
      "metadata": {},
      "source": [
        "### üìä Compare All Approaches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70858b4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all three approaches\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä COMPREHENSIVE COMPARISON - ALL APPROACHES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load baseline CNN (threshold=0.5)\n",
        "baseline_f1 = 0.2571  # From earlier evaluation\n",
        "baseline_acc = 0.6719\n",
        "\n",
        "print(\"\\nüß† Baseline CNN (threshold=0.5):\")\n",
        "print(f\"  Accuracy:  {baseline_acc:.4f}\")\n",
        "print(f\"  F1-Score:  {baseline_f1:.4f}\")\n",
        "\n",
        "# Load optimal threshold results\n",
        "if Path('results/optimal_threshold_results.json').exists():\n",
        "    with open('results/optimal_threshold_results.json') as f:\n",
        "        opt_results = json.load(f)\n",
        "    opt_threshold = opt_results['best_threshold']\n",
        "    opt_f1 = opt_results['train_metrics']['f1_score']\n",
        "    opt_acc = opt_results['train_metrics']['accuracy']\n",
        "    \n",
        "    print(f\"\\nüìä Approach 1: Optimal Threshold ({opt_threshold:.2f}):\")\n",
        "    print(f\"  Accuracy:  {opt_acc:.4f}\")\n",
        "    print(f\"  F1-Score:  {opt_f1:.4f}\")\n",
        "    print(f\"  Improvement: {(opt_f1 - baseline_f1) / baseline_f1 * 100:+.2f}%\")\n",
        "\n",
        "# Load fine-tuned CNN results\n",
        "if Path('results/cnn_finetuning_results.json').exists():\n",
        "    with open('results/cnn_finetuning_results.json') as f:\n",
        "        finetune_results = json.load(f)\n",
        "    ft_f1 = finetune_results['finetuned_metrics']['f1_score']\n",
        "    ft_acc = finetune_results['finetuned_metrics']['accuracy']\n",
        "    \n",
        "    print(f\"\\nüî• Approach 2: Fine-Tuned CNN:\")\n",
        "    print(f\"  Accuracy:  {ft_acc:.4f}\")\n",
        "    print(f\"  F1-Score:  {ft_f1:.4f}\")\n",
        "    print(f\"  Improvement: {(ft_f1 - baseline_f1) / baseline_f1 * 100:+.2f}%\")\n",
        "\n",
        "# Load RL threshold refinement results\n",
        "if Path('results/threshold_refinement_results.json').exists():\n",
        "    with open('results/threshold_refinement_results.json') as f:\n",
        "        rl_results = json.load(f)\n",
        "    rl_f1 = rl_results['rl_threshold_refinement']['f1_score']\n",
        "    rl_acc = rl_results['rl_threshold_refinement']['accuracy']\n",
        "    \n",
        "    print(f\"\\nüéØ Approach 3: RL Adaptive Threshold:\")\n",
        "    print(f\"  Accuracy:  {rl_acc:.4f}\")\n",
        "    print(f\"  F1-Score:  {rl_f1:.4f}\")\n",
        "    print(f\"  Improvement: {(rl_f1 - baseline_f1) / baseline_f1 * 100:+.2f}%\")\n",
        "    \n",
        "    mean_delta = rl_results['threshold_statistics']['mean_delta']\n",
        "    print(f\"  Mean threshold adjustment: {mean_delta:+.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ All approaches evaluated!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a94b2378",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a94b2378",
        "outputId": "7ffa7f62-597c-452a-8033-6669fd84ec0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting PPO training...\n",
            "This will take 1-2 hours with GPU\n",
            "============================================================\n",
            "2026-01-12 14:36:50.150236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768228610.171002    8622 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768228610.177290    8622 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768228610.193083    8622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768228610.193108    8622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768228610.193111    8622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768228610.193113    8622 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "============================================================\n",
            "ü§ñ Training PPO Agent for Cloud Mask Refinement\n",
            "============================================================\n",
            "\n",
            "üìÇ Loading CloudSEN12 data...\n",
            "‚úÖ Found 100 CloudSEN12 patches\n",
            "üìä Train: 80 patches, Test: 20 patches\n",
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
            "‚úÖ Training data loaded: Image shape (512, 512, 10), CNN prob shape (512, 512)\n",
            "üìä Cloud coverage: 12.2% (Real Ground Truth)\n",
            "\n",
            "üéÆ Creating RL environment...\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üéØ Using EPISODE-PER-PATCH configuration for stable learning\n",
            "\n",
            "üß† Creating PPO model with CUSTOM CNN for 11-channel input:\n",
            "   learning_rate: 0.0003\n",
            "   n_steps: 4096\n",
            "   batch_size: 256\n",
            "   n_epochs: 10\n",
            "   gamma: 0.99\n",
            "   gae_lambda: 0.95\n",
            "   clip_range: 0.2\n",
            "   clip_range_vf: None\n",
            "   ent_coef: 0.01\n",
            "   vf_coef: 0.1\n",
            "   max_grad_norm: 0.5\n",
            "   use_sde: False\n",
            "   sde_sample_freq: -1\n",
            "   target_kl: None\n",
            "\n",
            "üñ•Ô∏è  Using device: cuda\n",
            "Using cuda device\n",
            "\n",
            "============================================================\n",
            "üöÄ Starting PPO Training\n",
            "============================================================\n",
            "Training for 500,000 timesteps...\n",
            "This will take approximately 20-25 minutes with GPU...\n",
            "Logging to ./logs/PPO_1\n",
            "\u001b[2K-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 387  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 10   |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n",
            "\u001b[2KTimestep 5000: 18.0s elapsed, Mean Reward: -0.0145\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 328        |\n",
            "|    iterations           | 2          |\n",
            "|    time_elapsed         | 24         |\n",
            "|    total_timesteps      | 8192       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09470302 |\n",
            "|    clip_fraction        | 0.678      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.641     |\n",
            "|    explained_variance   | 0.00211    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.06       |\n",
            "|    n_updates            | 10         |\n",
            "|    policy_gradient_loss | -0.134     |\n",
            "|    value_loss           | 12.7       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 10000: 33.5s elapsed, Mean Reward: 1.4545\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 317      |\n",
            "|    iterations           | 3        |\n",
            "|    time_elapsed         | 38       |\n",
            "|    total_timesteps      | 12288    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.190883 |\n",
            "|    clip_fraction        | 0.863    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.366   |\n",
            "|    explained_variance   | 0.0763   |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 1.02     |\n",
            "|    n_updates            | 20       |\n",
            "|    policy_gradient_loss | -0.16    |\n",
            "|    value_loss           | 11.3     |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 15000: 49.5s elapsed, Mean Reward: 2.7671\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 311        |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 52         |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.46934777 |\n",
            "|    clip_fraction        | 0.245      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0522    |\n",
            "|    explained_variance   | 0.105      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.495      |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.102     |\n",
            "|    value_loss           | 5.43       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 20000: 65.2s elapsed, Mean Reward: 2.3193\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 308        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 66         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.12880996 |\n",
            "|    clip_fraction        | 0.349      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.193     |\n",
            "|    explained_variance   | 0.499      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.063     |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.071     |\n",
            "|    value_loss           | 0.249      |\n",
            "----------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 307       |\n",
            "|    iterations           | 6         |\n",
            "|    time_elapsed         | 79        |\n",
            "|    total_timesteps      | 24576     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.2871183 |\n",
            "|    clip_fraction        | 0.382     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.125    |\n",
            "|    explained_variance   | -0.26     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.263     |\n",
            "|    n_updates            | 50        |\n",
            "|    policy_gradient_loss | -0.0902   |\n",
            "|    value_loss           | 3.71      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 25000: 85.5s elapsed, Mean Reward: 2.4452\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 306      |\n",
            "|    iterations           | 7        |\n",
            "|    time_elapsed         | 93       |\n",
            "|    total_timesteps      | 28672    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 8.615578 |\n",
            "|    clip_fraction        | 0.652    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.00477 |\n",
            "|    explained_variance   | -0.485   |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 0.0968   |\n",
            "|    n_updates            | 60       |\n",
            "|    policy_gradient_loss | 2.19     |\n",
            "|    value_loss           | 2.16     |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 30000: 101.2s elapsed, Mean Reward: -0.3997\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 305         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 107         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.060864475 |\n",
            "|    clip_fraction        | 0.375       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.262      |\n",
            "|    explained_variance   | -0.0736     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0487      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0657     |\n",
            "|    value_loss           | 6.53        |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 35000: 116.6s elapsed, Mean Reward: 0.5419\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 305        |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 120        |\n",
            "|    total_timesteps      | 36864      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.22963893 |\n",
            "|    clip_fraction        | 0.826      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.56      |\n",
            "|    explained_variance   | 0.497      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.604      |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.129     |\n",
            "|    value_loss           | 6.98       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 40000: 132.0s elapsed, Mean Reward: 1.4944\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 305        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 134        |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.21273029 |\n",
            "|    clip_fraction        | 0.882      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.404     |\n",
            "|    explained_variance   | -0.785     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.961      |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.152     |\n",
            "|    value_loss           | 11.6       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 45000: 147.4s elapsed, Mean Reward: 2.7277\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 305        |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 147        |\n",
            "|    total_timesteps      | 45056      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.28363186 |\n",
            "|    clip_fraction        | 0.551      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.122     |\n",
            "|    explained_variance   | 0.0385     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.484      |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.126     |\n",
            "|    value_loss           | 6.08       |\n",
            "----------------------------------------\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 304        |\n",
            "|    iterations           | 12         |\n",
            "|    time_elapsed         | 161        |\n",
            "|    total_timesteps      | 49152      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.52645785 |\n",
            "|    clip_fraction        | 0.301      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.154     |\n",
            "|    explained_variance   | -0.157     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.419      |\n",
            "|    n_updates            | 110        |\n",
            "|    policy_gradient_loss | 0.0492     |\n",
            "|    value_loss           | 2.03       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 50000: 167.6s elapsed, Mean Reward: 2.4550\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 304        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 174        |\n",
            "|    total_timesteps      | 53248      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.41681218 |\n",
            "|    clip_fraction        | 0.236      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0474    |\n",
            "|    explained_variance   | 0.0456     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.241      |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.0732    |\n",
            "|    value_loss           | 4.37       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 55000: 183.0s elapsed, Mean Reward: 2.5576\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 304        |\n",
            "|    iterations           | 14         |\n",
            "|    time_elapsed         | 188        |\n",
            "|    total_timesteps      | 57344      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.22866227 |\n",
            "|    clip_fraction        | 0.466      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.189     |\n",
            "|    explained_variance   | -3.83      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0654    |\n",
            "|    n_updates            | 130        |\n",
            "|    policy_gradient_loss | -0.0255    |\n",
            "|    value_loss           | 0.23       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 60000: 198.4s elapsed, Mean Reward: 2.0955\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 304       |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 201       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.3452025 |\n",
            "|    clip_fraction        | 0.559     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.215    |\n",
            "|    explained_variance   | -0.0946   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.445     |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | -0.121    |\n",
            "|    value_loss           | 6.21      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 65000: 213.8s elapsed, Mean Reward: 1.5043\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 304       |\n",
            "|    iterations           | 16        |\n",
            "|    time_elapsed         | 214       |\n",
            "|    total_timesteps      | 65536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.4877051 |\n",
            "|    clip_fraction        | 0.491     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.188    |\n",
            "|    explained_variance   | -0.427    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.111     |\n",
            "|    n_updates            | 150       |\n",
            "|    policy_gradient_loss | -0.123    |\n",
            "|    value_loss           | 2.63      |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 304       |\n",
            "|    iterations           | 17        |\n",
            "|    time_elapsed         | 228       |\n",
            "|    total_timesteps      | 69632     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.8679066 |\n",
            "|    clip_fraction        | 0.401     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0447   |\n",
            "|    explained_variance   | -0.0811   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.403     |\n",
            "|    n_updates            | 160       |\n",
            "|    policy_gradient_loss | -0.0983   |\n",
            "|    value_loss           | 6.43      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 70000: 234.1s elapsed, Mean Reward: 2.7455\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 304       |\n",
            "|    iterations           | 18        |\n",
            "|    time_elapsed         | 242       |\n",
            "|    total_timesteps      | 73728     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 10.153668 |\n",
            "|    clip_fraction        | 0.436     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0105   |\n",
            "|    explained_variance   | -23.7     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.0724   |\n",
            "|    n_updates            | 170       |\n",
            "|    policy_gradient_loss | -0.0628   |\n",
            "|    value_loss           | 0.615     |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 75000: 249.8s elapsed, Mean Reward: 0.2314\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 304       |\n",
            "|    iterations           | 19        |\n",
            "|    time_elapsed         | 255       |\n",
            "|    total_timesteps      | 77824     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.53e-05 |\n",
            "|    explained_variance   | -0.195    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.65e-05  |\n",
            "|    n_updates            | 180       |\n",
            "|    policy_gradient_loss | 4.23e-06  |\n",
            "|    value_loss           | 1.71      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 80000: 265.3s elapsed, Mean Reward: 0.2323\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 269       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.86e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -2.94e-08 |\n",
            "|    n_updates            | 190       |\n",
            "|    policy_gradient_loss | -1.48e-08 |\n",
            "|    value_loss           | 2.58e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 85000: 280.7s elapsed, Mean Reward: 0.2323\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 21        |\n",
            "|    time_elapsed         | 282       |\n",
            "|    total_timesteps      | 86016     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.48e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -3.87e-08 |\n",
            "|    n_updates            | 200       |\n",
            "|    policy_gradient_loss | -1.24e-08 |\n",
            "|    value_loss           | 1.12e-07  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 90000: 296.2s elapsed, Mean Reward: 0.2311\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 22        |\n",
            "|    time_elapsed         | 296       |\n",
            "|    total_timesteps      | 90112     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.33e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -1.13e-08 |\n",
            "|    n_updates            | 210       |\n",
            "|    policy_gradient_loss | -2.88e-10 |\n",
            "|    value_loss           | 1.03e-07  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 309       |\n",
            "|    total_timesteps      | 94208     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.25e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -1.7e-08  |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -7.04e-09 |\n",
            "|    value_loss           | 1.87e-07  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 95000: 316.1s elapsed, Mean Reward: 0.2309\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 304       |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 323       |\n",
            "|    total_timesteps      | 98304     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.9e-06  |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -7.4e-08  |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | -4.58e-08 |\n",
            "|    value_loss           | 2.31e-07  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 100000: 331.7s elapsed, Mean Reward: 0.2323\n",
            "\u001b[2K--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 303            |\n",
            "|    iterations           | 25             |\n",
            "|    time_elapsed         | 337            |\n",
            "|    total_timesteps      | 102400         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -7.1304385e-10 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.83e-06      |\n",
            "|    explained_variance   | 1              |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 3.46e-10       |\n",
            "|    n_updates            | 240            |\n",
            "|    policy_gradient_loss | -2.8e-08       |\n",
            "|    value_loss           | 3.29e-07       |\n",
            "--------------------------------------------\n",
            "\u001b[2KTimestep 105000: 347.2s elapsed, Mean Reward: 0.2323\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 26        |\n",
            "|    time_elapsed         | 350       |\n",
            "|    total_timesteps      | 106496    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.32e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.16e-08  |\n",
            "|    n_updates            | 250       |\n",
            "|    policy_gradient_loss | -6.27e-09 |\n",
            "|    value_loss           | 9.48e-07  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 110000: 362.7s elapsed, Mean Reward: 0.2315\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 303      |\n",
            "|    iterations           | 27       |\n",
            "|    time_elapsed         | 363      |\n",
            "|    total_timesteps      | 110592   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.0      |\n",
            "|    clip_fraction        | 0        |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -2.4e-06 |\n",
            "|    explained_variance   | 1        |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 1.39e-06 |\n",
            "|    n_updates            | 260      |\n",
            "|    policy_gradient_loss | -6.2e-09 |\n",
            "|    value_loss           | 3.97e-06 |\n",
            "--------------------------------------\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 303           |\n",
            "|    iterations           | 28            |\n",
            "|    time_elapsed         | 377           |\n",
            "|    total_timesteps      | 114688        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.0559022e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.32e-06     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 2.8e-06       |\n",
            "|    n_updates            | 270           |\n",
            "|    policy_gradient_loss | -1.35e-07     |\n",
            "|    value_loss           | 0.000747      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 115000: 382.7s elapsed, Mean Reward: 0.2323\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 303           |\n",
            "|    iterations           | 29            |\n",
            "|    time_elapsed         | 390           |\n",
            "|    total_timesteps      | 118784        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.2573235e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -6.81e-06     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -5.25e-07     |\n",
            "|    n_updates            | 280           |\n",
            "|    policy_gradient_loss | -1.44e-07     |\n",
            "|    value_loss           | 8.61e-06      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 120000: 398.1s elapsed, Mean Reward: 0.2323\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 303           |\n",
            "|    iterations           | 30            |\n",
            "|    time_elapsed         | 404           |\n",
            "|    total_timesteps      | 122880        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.2200554e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.74e-05     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.92e-06      |\n",
            "|    n_updates            | 290           |\n",
            "|    policy_gradient_loss | -3.09e-07     |\n",
            "|    value_loss           | 0.000353      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 125000: 413.4s elapsed, Mean Reward: 0.2323\n",
            "\u001b[2K--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 303            |\n",
            "|    iterations           | 31             |\n",
            "|    time_elapsed         | 417            |\n",
            "|    total_timesteps      | 126976         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -6.1118044e-10 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -3.28e-05      |\n",
            "|    explained_variance   | 1              |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 0.000258       |\n",
            "|    n_updates            | 300            |\n",
            "|    policy_gradient_loss | -4.18e-08      |\n",
            "|    value_loss           | 0.012          |\n",
            "--------------------------------------------\n",
            "\u001b[2KTimestep 130000: 428.9s elapsed, Mean Reward: 0.2312\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 32        |\n",
            "|    time_elapsed         | 431       |\n",
            "|    total_timesteps      | 131072    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.75e-05 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -3.65e-07 |\n",
            "|    n_updates            | 310       |\n",
            "|    policy_gradient_loss | -4e-08    |\n",
            "|    value_loss           | 0.000356  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 135000: 444.5s elapsed, Mean Reward: 0.2294\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 33        |\n",
            "|    time_elapsed         | 444       |\n",
            "|    total_timesteps      | 135168    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.02e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -2.68e-06 |\n",
            "|    n_updates            | 320       |\n",
            "|    policy_gradient_loss | -1.95e-06 |\n",
            "|    value_loss           | 2.83e-07  |\n",
            "---------------------------------------\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 303          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 458          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.966285e-10 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -5.18e-06    |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -4.39e-07    |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -7.68e-08    |\n",
            "|    value_loss           | 2.17e-07     |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 140000: 464.9s elapsed, Mean Reward: 0.2309\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 35        |\n",
            "|    time_elapsed         | 472       |\n",
            "|    total_timesteps      | 143360    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.94e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -8.66e-07 |\n",
            "|    n_updates            | 340       |\n",
            "|    policy_gradient_loss | -2.79e-07 |\n",
            "|    value_loss           | 3.3e-07   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 145000: 480.4s elapsed, Mean Reward: 0.2323\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 36        |\n",
            "|    time_elapsed         | 485       |\n",
            "|    total_timesteps      | 147456    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.24e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.27e-08  |\n",
            "|    n_updates            | 350       |\n",
            "|    policy_gradient_loss | -1.64e-08 |\n",
            "|    value_loss           | 4.43e-07  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 150000: 495.9s elapsed, Mean Reward: 0.2299\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 37        |\n",
            "|    time_elapsed         | 499       |\n",
            "|    total_timesteps      | 151552    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.03e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.15e-07  |\n",
            "|    n_updates            | 360       |\n",
            "|    policy_gradient_loss | -4.16e-10 |\n",
            "|    value_loss           | 1.9e-06   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 155000: 511.3s elapsed, Mean Reward: 0.2300\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 512        |\n",
            "|    total_timesteps      | 155648     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 6.8394e-10 |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -6.04e-06  |\n",
            "|    explained_variance   | 1          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.000858   |\n",
            "|    n_updates            | 370        |\n",
            "|    policy_gradient_loss | -7.1e-07   |\n",
            "|    value_loss           | 0.000439   |\n",
            "----------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 39        |\n",
            "|    time_elapsed         | 526       |\n",
            "|    total_timesteps      | 159744    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.18e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -3.75e-06 |\n",
            "|    n_updates            | 380       |\n",
            "|    policy_gradient_loss | -2.99e-06 |\n",
            "|    value_loss           | 0.000441  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 160000: 531.5s elapsed, Mean Reward: 0.2305\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 303           |\n",
            "|    iterations           | 40            |\n",
            "|    time_elapsed         | 539           |\n",
            "|    total_timesteps      | 163840        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.6379788e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -4.36e-06     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.59e-05      |\n",
            "|    n_updates            | 390           |\n",
            "|    policy_gradient_loss | -9.45e-08     |\n",
            "|    value_loss           | 2.13e-05      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 165000: 546.9s elapsed, Mean Reward: 0.5133\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 41         |\n",
            "|    time_elapsed         | 553        |\n",
            "|    total_timesteps      | 167936     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.60350937 |\n",
            "|    clip_fraction        | 0.0983     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0417    |\n",
            "|    explained_variance   | 1          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0721    |\n",
            "|    n_updates            | 400        |\n",
            "|    policy_gradient_loss | -0.0235    |\n",
            "|    value_loss           | 0.0191     |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 170000: 562.4s elapsed, Mean Reward: 1.1475\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 42         |\n",
            "|    time_elapsed         | 566        |\n",
            "|    total_timesteps      | 172032     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.20077083 |\n",
            "|    clip_fraction        | 0.875      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.403     |\n",
            "|    explained_variance   | -0.242     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.123      |\n",
            "|    n_updates            | 410        |\n",
            "|    policy_gradient_loss | -0.12      |\n",
            "|    value_loss           | 2.87       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 175000: 577.8s elapsed, Mean Reward: 1.3370\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 43         |\n",
            "|    time_elapsed         | 580        |\n",
            "|    total_timesteps      | 176128     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.10813391 |\n",
            "|    clip_fraction        | 0.772      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.385     |\n",
            "|    explained_variance   | -0.469     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.927      |\n",
            "|    n_updates            | 420        |\n",
            "|    policy_gradient_loss | -0.125     |\n",
            "|    value_loss           | 11         |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 180000: 593.5s elapsed, Mean Reward: 2.5859\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 44         |\n",
            "|    time_elapsed         | 593        |\n",
            "|    total_timesteps      | 180224     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.25347337 |\n",
            "|    clip_fraction        | 0.698      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.139     |\n",
            "|    explained_variance   | 0.0718     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.617      |\n",
            "|    n_updates            | 430        |\n",
            "|    policy_gradient_loss | -0.148     |\n",
            "|    value_loss           | 7.62       |\n",
            "----------------------------------------\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 45         |\n",
            "|    time_elapsed         | 607        |\n",
            "|    total_timesteps      | 184320     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.24413246 |\n",
            "|    clip_fraction        | 0.147      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0298    |\n",
            "|    explained_variance   | 0.0147     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.155      |\n",
            "|    n_updates            | 440        |\n",
            "|    policy_gradient_loss | -0.0642    |\n",
            "|    value_loss           | 2.08       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 185000: 613.5s elapsed, Mean Reward: 2.9642\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 303         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 621         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.048502974 |\n",
            "|    clip_fraction        | 0.0721      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0362     |\n",
            "|    explained_variance   | 0.268       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00605    |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.0411     |\n",
            "|    value_loss           | 0.535       |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 190000: 629.0s elapsed, Mean Reward: 3.0247\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 303         |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 634         |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029482111 |\n",
            "|    clip_fraction        | 0.0819      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0372     |\n",
            "|    explained_variance   | 0.0631      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0673      |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.0411     |\n",
            "|    value_loss           | 1.06        |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 195000: 644.6s elapsed, Mean Reward: 3.1540\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 303         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 648         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027100835 |\n",
            "|    clip_fraction        | 0.0366      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0112     |\n",
            "|    explained_variance   | 0.216       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0452      |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.0282     |\n",
            "|    value_loss           | 0.672       |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 200000: 660.1s elapsed, Mean Reward: 3.1886\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 303         |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 661         |\n",
            "|    total_timesteps      | 200704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024525441 |\n",
            "|    clip_fraction        | 0.00706     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.00601    |\n",
            "|    explained_variance   | 0.422       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0123     |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.0178     |\n",
            "|    value_loss           | 0.156       |\n",
            "-----------------------------------------\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 303         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 675         |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.038904883 |\n",
            "|    clip_fraction        | 0.0203      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.00286    |\n",
            "|    explained_variance   | 0.588       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00545    |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    value_loss           | 0.118       |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 205000: 680.1s elapsed, Mean Reward: 3.1053\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 51        |\n",
            "|    time_elapsed         | 688       |\n",
            "|    total_timesteps      | 208896    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.3713778 |\n",
            "|    clip_fraction        | 0.0561    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.035    |\n",
            "|    explained_variance   | 0.704     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.0164   |\n",
            "|    n_updates            | 500       |\n",
            "|    policy_gradient_loss | -0.00283  |\n",
            "|    value_loss           | 0.00877   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 210000: 695.5s elapsed, Mean Reward: 1.1808\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 52        |\n",
            "|    time_elapsed         | 701       |\n",
            "|    total_timesteps      | 212992    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 3.8608892 |\n",
            "|    clip_fraction        | 0.46      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0498   |\n",
            "|    explained_variance   | 0.102     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.505     |\n",
            "|    n_updates            | 510       |\n",
            "|    policy_gradient_loss | -0.111    |\n",
            "|    value_loss           | 7.32      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 215000: 710.9s elapsed, Mean Reward: 2.0224\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 303      |\n",
            "|    iterations           | 53       |\n",
            "|    time_elapsed         | 715      |\n",
            "|    total_timesteps      | 217088   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 7.89513  |\n",
            "|    clip_fraction        | 0.471    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.0128  |\n",
            "|    explained_variance   | -21.3    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | -0.0919  |\n",
            "|    n_updates            | 520      |\n",
            "|    policy_gradient_loss | -0.0671  |\n",
            "|    value_loss           | 0.584    |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 220000: 726.5s elapsed, Mean Reward: 1.6608\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 54         |\n",
            "|    time_elapsed         | 729        |\n",
            "|    total_timesteps      | 221184     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.27341154 |\n",
            "|    clip_fraction        | 0.0304     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0191    |\n",
            "|    explained_variance   | -0.194     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0878    |\n",
            "|    n_updates            | 530        |\n",
            "|    policy_gradient_loss | -0.00526   |\n",
            "|    value_loss           | 1.61       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 225000: 741.9s elapsed, Mean Reward: 1.7565\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 55         |\n",
            "|    time_elapsed         | 742        |\n",
            "|    total_timesteps      | 225280     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.55099523 |\n",
            "|    clip_fraction        | 0.642      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.255     |\n",
            "|    explained_variance   | -1.89      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.24       |\n",
            "|    n_updates            | 540        |\n",
            "|    policy_gradient_loss | 0.629      |\n",
            "|    value_loss           | 2.36       |\n",
            "----------------------------------------\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 56         |\n",
            "|    time_elapsed         | 756        |\n",
            "|    total_timesteps      | 229376     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.42300165 |\n",
            "|    clip_fraction        | 0.471      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.155     |\n",
            "|    explained_variance   | -0.0684    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.646      |\n",
            "|    n_updates            | 550        |\n",
            "|    policy_gradient_loss | -0.103     |\n",
            "|    value_loss           | 8.17       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 230000: 762.0s elapsed, Mean Reward: 2.5459\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 303      |\n",
            "|    iterations           | 57       |\n",
            "|    time_elapsed         | 769      |\n",
            "|    total_timesteps      | 233472   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 4.829689 |\n",
            "|    clip_fraction        | 0.484    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.0206  |\n",
            "|    explained_variance   | -0.981   |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 0.105    |\n",
            "|    n_updates            | 560      |\n",
            "|    policy_gradient_loss | 0.497    |\n",
            "|    value_loss           | 2.22     |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 235000: 777.5s elapsed, Mean Reward: 0.9050\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 58         |\n",
            "|    time_elapsed         | 783        |\n",
            "|    total_timesteps      | 237568     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.32552278 |\n",
            "|    clip_fraction        | 0.396      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.224     |\n",
            "|    explained_variance   | -0.513     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0735    |\n",
            "|    n_updates            | 570        |\n",
            "|    policy_gradient_loss | -0.0824    |\n",
            "|    value_loss           | 2.29       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 240000: 792.9s elapsed, Mean Reward: 0.5650\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 303      |\n",
            "|    iterations           | 59       |\n",
            "|    time_elapsed         | 796      |\n",
            "|    total_timesteps      | 241664   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 8.547977 |\n",
            "|    clip_fraction        | 0.897    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.0347  |\n",
            "|    explained_variance   | -0.165   |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 0.269    |\n",
            "|    n_updates            | 580      |\n",
            "|    policy_gradient_loss | -0.145   |\n",
            "|    value_loss           | 4.22     |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 245000: 808.7s elapsed, Mean Reward: -0.7258\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 60         |\n",
            "|    time_elapsed         | 810        |\n",
            "|    total_timesteps      | 245760     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16309424 |\n",
            "|    clip_fraction        | 0.0286     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.00979   |\n",
            "|    explained_variance   | -0.595     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0939     |\n",
            "|    n_updates            | 590        |\n",
            "|    policy_gradient_loss | -0.0136    |\n",
            "|    value_loss           | 5.2        |\n",
            "----------------------------------------\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 303           |\n",
            "|    iterations           | 61            |\n",
            "|    time_elapsed         | 824           |\n",
            "|    total_timesteps      | 249856        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.1827873e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.2e-05      |\n",
            "|    explained_variance   | 0.992         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.00146       |\n",
            "|    n_updates            | 600           |\n",
            "|    policy_gradient_loss | -5.54e-06     |\n",
            "|    value_loss           | 0.0281        |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 250000: 828.9s elapsed, Mean Reward: -0.6944\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 303      |\n",
            "|    iterations           | 62       |\n",
            "|    time_elapsed         | 837      |\n",
            "|    total_timesteps      | 253952   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.0      |\n",
            "|    clip_fraction        | 0        |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1.6e-05 |\n",
            "|    explained_variance   | 1        |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 1.7e-05  |\n",
            "|    n_updates            | 610      |\n",
            "|    policy_gradient_loss | 1.99e-07 |\n",
            "|    value_loss           | 0.0148   |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 255000: 844.3s elapsed, Mean Reward: -0.6907\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 63        |\n",
            "|    time_elapsed         | 850       |\n",
            "|    total_timesteps      | 258048    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.27e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -6.76e-07 |\n",
            "|    n_updates            | 620       |\n",
            "|    policy_gradient_loss | -5.57e-07 |\n",
            "|    value_loss           | 7.94e-06  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 260000: 859.8s elapsed, Mean Reward: -0.6913\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 64        |\n",
            "|    time_elapsed         | 864       |\n",
            "|    total_timesteps      | 262144    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -5.67e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 6.9e-07   |\n",
            "|    n_updates            | 630       |\n",
            "|    policy_gradient_loss | -6.29e-09 |\n",
            "|    value_loss           | 2.31e-06  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 265000: 875.4s elapsed, Mean Reward: -0.6944\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 65        |\n",
            "|    time_elapsed         | 878       |\n",
            "|    total_timesteps      | 266240    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -5.58e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.59e-07  |\n",
            "|    n_updates            | 640       |\n",
            "|    policy_gradient_loss | 5.97e-10  |\n",
            "|    value_loss           | 2.49e-06  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 270000: 891.2s elapsed, Mean Reward: -0.6927\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 66        |\n",
            "|    time_elapsed         | 891       |\n",
            "|    total_timesteps      | 270336    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -5.13e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -7.39e-08 |\n",
            "|    n_updates            | 650       |\n",
            "|    policy_gradient_loss | -2.44e-08 |\n",
            "|    value_loss           | 3.93e-06  |\n",
            "---------------------------------------\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 303          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 905          |\n",
            "|    total_timesteps      | 274432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.566996e-10 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -5.18e-06    |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.5e-06      |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -1.95e-08    |\n",
            "|    value_loss           | 7.87e-06     |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 275000: 911.5s elapsed, Mean Reward: -0.6909\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 303          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 919          |\n",
            "|    total_timesteps      | 278528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.566996e-10 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -6.49e-06    |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.35e-07     |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -2.54e-08    |\n",
            "|    value_loss           | 2.46e-05     |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 280000: 927.1s elapsed, Mean Reward: -0.6908\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 69        |\n",
            "|    time_elapsed         | 932       |\n",
            "|    total_timesteps      | 282624    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.44e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.26e-06  |\n",
            "|    n_updates            | 680       |\n",
            "|    policy_gradient_loss | -1.21e-10 |\n",
            "|    value_loss           | 0.000109  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 285000: 942.7s elapsed, Mean Reward: -0.6911\n",
            "\u001b[2K--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 302            |\n",
            "|    iterations           | 70             |\n",
            "|    time_elapsed         | 946            |\n",
            "|    total_timesteps      | 286720         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -1.4551915e-11 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -8.92e-06      |\n",
            "|    explained_variance   | 1              |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 2.46e-05       |\n",
            "|    n_updates            | 690            |\n",
            "|    policy_gradient_loss | -6.94e-08      |\n",
            "|    value_loss           | 0.000422       |\n",
            "--------------------------------------------\n",
            "\u001b[2KTimestep 290000: 958.5s elapsed, Mean Reward: -0.6911\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 302          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 960          |\n",
            "|    total_timesteps      | 290816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.820766e-10 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.09e-05    |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -2.48e-06    |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -6.43e-07    |\n",
            "|    value_loss           | 0.000545     |\n",
            "------------------------------------------\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 72            |\n",
            "|    time_elapsed         | 973           |\n",
            "|    total_timesteps      | 294912        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.1118044e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -5.21e-05     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -2.13e-07     |\n",
            "|    n_updates            | 710           |\n",
            "|    policy_gradient_loss | 5.57e-08      |\n",
            "|    value_loss           | 2.8e-05       |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 295000: 978.8s elapsed, Mean Reward: -0.6909\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 73            |\n",
            "|    time_elapsed         | 987           |\n",
            "|    total_timesteps      | 299008        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.1118044e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.6e-05      |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.000194      |\n",
            "|    n_updates            | 720           |\n",
            "|    policy_gradient_loss | -6.12e-06     |\n",
            "|    value_loss           | 0.000368      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 300000: 994.4s elapsed, Mean Reward: -0.6928\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 74        |\n",
            "|    time_elapsed         | 1001      |\n",
            "|    total_timesteps      | 303104    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -6.61e-06 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.55e-05  |\n",
            "|    n_updates            | 730       |\n",
            "|    policy_gradient_loss | -4.38e-08 |\n",
            "|    value_loss           | 0.00049   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 305000: 1010.1s elapsed, Mean Reward: -0.6916\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 302          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 1015         |\n",
            "|    total_timesteps      | 307200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.675247e-10 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -6.78e-06    |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.84e-05     |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -2.06e-08    |\n",
            "|    value_loss           | 0.000572     |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 310000: 1025.7s elapsed, Mean Reward: -0.6911\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 76            |\n",
            "|    time_elapsed         | 1028          |\n",
            "|    total_timesteps      | 311296        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.3655746e-11 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.38e-05     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 2.1e-05       |\n",
            "|    n_updates            | 750           |\n",
            "|    policy_gradient_loss | -5.93e-07     |\n",
            "|    value_loss           | 3.12e-05      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 315000: 1041.4s elapsed, Mean Reward: -0.6928\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 77            |\n",
            "|    time_elapsed         | 1042          |\n",
            "|    total_timesteps      | 315392        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | -4.947651e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -5.18e-05     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.18e-06      |\n",
            "|    n_updates            | 760           |\n",
            "|    policy_gradient_loss | -7.41e-08     |\n",
            "|    value_loss           | 0.00058       |\n",
            "-------------------------------------------\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 78         |\n",
            "|    time_elapsed         | 1055       |\n",
            "|    total_timesteps      | 319488     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07965782 |\n",
            "|    clip_fraction        | 0.0416     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0198    |\n",
            "|    explained_variance   | 1          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0077    |\n",
            "|    n_updates            | 770        |\n",
            "|    policy_gradient_loss | -0.00524   |\n",
            "|    value_loss           | 0.000677   |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 320000: 1061.6s elapsed, Mean Reward: -0.3442\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 79         |\n",
            "|    time_elapsed         | 1069       |\n",
            "|    total_timesteps      | 323584     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.19348614 |\n",
            "|    clip_fraction        | 0.82       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.515     |\n",
            "|    explained_variance   | 0.856      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0291     |\n",
            "|    n_updates            | 780        |\n",
            "|    policy_gradient_loss | -0.0547    |\n",
            "|    value_loss           | 0.795      |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 325000: 1076.9s elapsed, Mean Reward: 0.2312\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 302         |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 1082        |\n",
            "|    total_timesteps      | 327680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.047004007 |\n",
            "|    clip_fraction        | 0.812       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.604      |\n",
            "|    explained_variance   | -0.714      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.09        |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | -0.124      |\n",
            "|    value_loss           | 12.3        |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 330000: 1092.4s elapsed, Mean Reward: 1.6904\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 81         |\n",
            "|    time_elapsed         | 1096       |\n",
            "|    total_timesteps      | 331776     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.18813494 |\n",
            "|    clip_fraction        | 0.892      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.28      |\n",
            "|    explained_variance   | -0.0209    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.811      |\n",
            "|    n_updates            | 800        |\n",
            "|    policy_gradient_loss | -0.169     |\n",
            "|    value_loss           | 10.1       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 335000: 1107.8s elapsed, Mean Reward: 2.8086\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 82        |\n",
            "|    time_elapsed         | 1109      |\n",
            "|    total_timesteps      | 335872    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.3001452 |\n",
            "|    clip_fraction        | 0.451     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0616   |\n",
            "|    explained_variance   | -0.0776   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.324     |\n",
            "|    n_updates            | 810       |\n",
            "|    policy_gradient_loss | -0.101    |\n",
            "|    value_loss           | 4.98      |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 83        |\n",
            "|    time_elapsed         | 1123      |\n",
            "|    total_timesteps      | 339968    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.5282561 |\n",
            "|    clip_fraction        | 0.352     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.104    |\n",
            "|    explained_variance   | -0.383    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.0673   |\n",
            "|    n_updates            | 820       |\n",
            "|    policy_gradient_loss | -0.0869   |\n",
            "|    value_loss           | 0.779     |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 340000: 1127.9s elapsed, Mean Reward: 1.8915\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 302      |\n",
            "|    iterations           | 84       |\n",
            "|    time_elapsed         | 1136     |\n",
            "|    total_timesteps      | 344064   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 1.22878  |\n",
            "|    clip_fraction        | 0.383    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.0494  |\n",
            "|    explained_variance   | 0.0497   |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 0.425    |\n",
            "|    n_updates            | 830      |\n",
            "|    policy_gradient_loss | -0.0936  |\n",
            "|    value_loss           | 5.99     |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 345000: 1143.3s elapsed, Mean Reward: 2.6558\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 302      |\n",
            "|    iterations           | 85       |\n",
            "|    time_elapsed         | 1150     |\n",
            "|    total_timesteps      | 348160   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 9.720384 |\n",
            "|    clip_fraction        | 0.41     |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.00898 |\n",
            "|    explained_variance   | -11.9    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | -0.0674  |\n",
            "|    n_updates            | 840      |\n",
            "|    policy_gradient_loss | -0.0549  |\n",
            "|    value_loss           | 0.447    |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 350000: 1158.9s elapsed, Mean Reward: 1.3223\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 86        |\n",
            "|    time_elapsed         | 1163      |\n",
            "|    total_timesteps      | 352256    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 5.1023755 |\n",
            "|    clip_fraction        | 0.25      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0147   |\n",
            "|    explained_variance   | -0.184    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.0926   |\n",
            "|    n_updates            | 850       |\n",
            "|    policy_gradient_loss | -0.046    |\n",
            "|    value_loss           | 1.55      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 355000: 1174.6s elapsed, Mean Reward: 1.0521\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 302      |\n",
            "|    iterations           | 87       |\n",
            "|    time_elapsed         | 1177     |\n",
            "|    total_timesteps      | 356352   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 5.481521 |\n",
            "|    clip_fraction        | 0.455    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.00769 |\n",
            "|    explained_variance   | -19.4    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | -0.0848  |\n",
            "|    n_updates            | 860      |\n",
            "|    policy_gradient_loss | -0.0832  |\n",
            "|    value_loss           | 1.3      |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 360000: 1190.3s elapsed, Mean Reward: 0.7272\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 88         |\n",
            "|    time_elapsed         | 1191       |\n",
            "|    total_timesteps      | 360448     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.10343569 |\n",
            "|    clip_fraction        | 0.377      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.192     |\n",
            "|    explained_variance   | 0.0948     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.103     |\n",
            "|    n_updates            | 870        |\n",
            "|    policy_gradient_loss | -0.0787    |\n",
            "|    value_loss           | 4.42       |\n",
            "----------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 89        |\n",
            "|    time_elapsed         | 1204      |\n",
            "|    total_timesteps      | 364544    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.5139365 |\n",
            "|    clip_fraction        | 0.661     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.185    |\n",
            "|    explained_variance   | 0.103     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.522     |\n",
            "|    n_updates            | 880       |\n",
            "|    policy_gradient_loss | 0.463     |\n",
            "|    value_loss           | 8.02      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 365000: 1210.4s elapsed, Mean Reward: 1.8152\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 90         |\n",
            "|    time_elapsed         | 1218       |\n",
            "|    total_timesteps      | 368640     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.27229294 |\n",
            "|    clip_fraction        | 0.332      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.287     |\n",
            "|    explained_variance   | -0.965     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.492      |\n",
            "|    n_updates            | 890        |\n",
            "|    policy_gradient_loss | -0.0936    |\n",
            "|    value_loss           | 7.59       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 370000: 1226.0s elapsed, Mean Reward: 2.4734\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 91         |\n",
            "|    time_elapsed         | 1232       |\n",
            "|    total_timesteps      | 372736     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.33670655 |\n",
            "|    clip_fraction        | 0.631      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.2       |\n",
            "|    explained_variance   | 0.1        |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.121      |\n",
            "|    n_updates            | 900        |\n",
            "|    policy_gradient_loss | -0.118     |\n",
            "|    value_loss           | 3.06       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 375000: 1241.5s elapsed, Mean Reward: 2.6424\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 92         |\n",
            "|    time_elapsed         | 1245       |\n",
            "|    total_timesteps      | 376832     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.24089538 |\n",
            "|    clip_fraction        | 0.266      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0768    |\n",
            "|    explained_variance   | -0.169     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.349      |\n",
            "|    n_updates            | 910        |\n",
            "|    policy_gradient_loss | -0.0643    |\n",
            "|    value_loss           | 4.93       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 380000: 1257.2s elapsed, Mean Reward: 1.8900\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 93        |\n",
            "|    time_elapsed         | 1259      |\n",
            "|    total_timesteps      | 380928    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.2639825 |\n",
            "|    clip_fraction        | 0.438     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.248    |\n",
            "|    explained_variance   | -0.379    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.0141   |\n",
            "|    n_updates            | 920       |\n",
            "|    policy_gradient_loss | -0.0609   |\n",
            "|    value_loss           | 1.45      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 385000: 1272.6s elapsed, Mean Reward: 2.1693\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 94         |\n",
            "|    time_elapsed         | 1272       |\n",
            "|    total_timesteps      | 385024     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.20670374 |\n",
            "|    clip_fraction        | 0.631      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.289     |\n",
            "|    explained_variance   | -0.135     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.452      |\n",
            "|    n_updates            | 930        |\n",
            "|    policy_gradient_loss | -0.123     |\n",
            "|    value_loss           | 7.2        |\n",
            "----------------------------------------\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 95         |\n",
            "|    time_elapsed         | 1286       |\n",
            "|    total_timesteps      | 389120     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.48247668 |\n",
            "|    clip_fraction        | 0.768      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.185     |\n",
            "|    explained_variance   | -0.0896    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.31       |\n",
            "|    n_updates            | 940        |\n",
            "|    policy_gradient_loss | -0.148     |\n",
            "|    value_loss           | 4.38       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 390000: 1292.8s elapsed, Mean Reward: 1.8994\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 96        |\n",
            "|    time_elapsed         | 1299      |\n",
            "|    total_timesteps      | 393216    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.4308288 |\n",
            "|    clip_fraction        | 0.353     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0874   |\n",
            "|    explained_variance   | -0.194    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.504     |\n",
            "|    n_updates            | 950       |\n",
            "|    policy_gradient_loss | -0.0826   |\n",
            "|    value_loss           | 6.4       |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 395000: 1308.5s elapsed, Mean Reward: 2.4809\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 97        |\n",
            "|    time_elapsed         | 1313      |\n",
            "|    total_timesteps      | 397312    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.0442982 |\n",
            "|    clip_fraction        | 0.313     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0558   |\n",
            "|    explained_variance   | -0.0935   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.223     |\n",
            "|    n_updates            | 960       |\n",
            "|    policy_gradient_loss | -0.0701   |\n",
            "|    value_loss           | 2.95      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 400000: 1324.1s elapsed, Mean Reward: 2.5631\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 98         |\n",
            "|    time_elapsed         | 1327       |\n",
            "|    total_timesteps      | 401408     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.26325828 |\n",
            "|    clip_fraction        | 0.178      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.052     |\n",
            "|    explained_variance   | -0.12      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0234     |\n",
            "|    n_updates            | 970        |\n",
            "|    policy_gradient_loss | -0.0667    |\n",
            "|    value_loss           | 2.78       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 405000: 1339.9s elapsed, Mean Reward: 1.0837\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 302      |\n",
            "|    iterations           | 99       |\n",
            "|    time_elapsed         | 1341     |\n",
            "|    total_timesteps      | 405504   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.533365 |\n",
            "|    clip_fraction        | 0.67     |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.315   |\n",
            "|    explained_variance   | -1.36    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 0.0624   |\n",
            "|    n_updates            | 980      |\n",
            "|    policy_gradient_loss | -0.0904  |\n",
            "|    value_loss           | 1.75     |\n",
            "--------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 100       |\n",
            "|    time_elapsed         | 1354      |\n",
            "|    total_timesteps      | 409600    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.5240967 |\n",
            "|    clip_fraction        | 0.787     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.204    |\n",
            "|    explained_variance   | -0.136    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.764     |\n",
            "|    n_updates            | 990       |\n",
            "|    policy_gradient_loss | -0.142    |\n",
            "|    value_loss           | 9.97      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 410000: 1360.2s elapsed, Mean Reward: 2.4490\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 101       |\n",
            "|    time_elapsed         | 1368      |\n",
            "|    total_timesteps      | 413696    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.3421598 |\n",
            "|    clip_fraction        | 0.211     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0435   |\n",
            "|    explained_variance   | -0.588    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.229     |\n",
            "|    n_updates            | 1000      |\n",
            "|    policy_gradient_loss | -0.0698   |\n",
            "|    value_loss           | 3.37      |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 415000: 1375.8s elapsed, Mean Reward: 3.1626\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 102        |\n",
            "|    time_elapsed         | 1382       |\n",
            "|    total_timesteps      | 417792     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09524083 |\n",
            "|    clip_fraction        | 0.0502     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0023    |\n",
            "|    explained_variance   | -0.022     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.011     |\n",
            "|    n_updates            | 1010       |\n",
            "|    policy_gradient_loss | -0.038     |\n",
            "|    value_loss           | 0.362      |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 420000: 1391.6s elapsed, Mean Reward: 3.2242\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 103           |\n",
            "|    time_elapsed         | 1395          |\n",
            "|    total_timesteps      | 421888        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00022231194 |\n",
            "|    clip_fraction        | 0.000244      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000344     |\n",
            "|    explained_variance   | 0.78          |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -4.17e-05     |\n",
            "|    n_updates            | 1020          |\n",
            "|    policy_gradient_loss | 0.000722      |\n",
            "|    value_loss           | 0.0218        |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 425000: 1407.1s elapsed, Mean Reward: 3.2242\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 104           |\n",
            "|    time_elapsed         | 1409          |\n",
            "|    total_timesteps      | 425984        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.3786713e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.00038      |\n",
            "|    explained_variance   | 0.997         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -5.72e-05     |\n",
            "|    n_updates            | 1030          |\n",
            "|    policy_gradient_loss | -2.31e-05     |\n",
            "|    value_loss           | 5.39e-05      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 430000: 1422.9s elapsed, Mean Reward: 3.2255\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 105           |\n",
            "|    time_elapsed         | 1423          |\n",
            "|    total_timesteps      | 430080        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00067439186 |\n",
            "|    clip_fraction        | 0.000244      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000296     |\n",
            "|    explained_variance   | 0.974         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.000292     |\n",
            "|    n_updates            | 1040          |\n",
            "|    policy_gradient_loss | -0.000931     |\n",
            "|    value_loss           | 0.00898       |\n",
            "-------------------------------------------\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 106           |\n",
            "|    time_elapsed         | 1436          |\n",
            "|    total_timesteps      | 434176        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | -8.731149e-11 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000153     |\n",
            "|    explained_variance   | 0.999         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -9.12e-06     |\n",
            "|    n_updates            | 1050          |\n",
            "|    policy_gradient_loss | -3.75e-06     |\n",
            "|    value_loss           | 1e-05         |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 435000: 1443.2s elapsed, Mean Reward: 3.2257\n",
            "\u001b[2K--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 302            |\n",
            "|    iterations           | 107            |\n",
            "|    time_elapsed         | 1450           |\n",
            "|    total_timesteps      | 438272         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -4.3655746e-11 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -0.000144      |\n",
            "|    explained_variance   | 1              |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | -7.84e-06      |\n",
            "|    n_updates            | 1060           |\n",
            "|    policy_gradient_loss | -2.6e-06       |\n",
            "|    value_loss           | 4.98e-07       |\n",
            "--------------------------------------------\n",
            "\u001b[2KTimestep 440000: 1458.7s elapsed, Mean Reward: 3.2257\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 302          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 1463         |\n",
            "|    total_timesteps      | 442368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.313226e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.000192    |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -4.75e-05    |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -8.17e-06    |\n",
            "|    value_loss           | 2.08e-06     |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 445000: 1474.2s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 109           |\n",
            "|    time_elapsed         | 1477          |\n",
            "|    total_timesteps      | 446464        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.4447218e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000192     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -7.28e-05     |\n",
            "|    n_updates            | 1080          |\n",
            "|    policy_gradient_loss | -4.81e-05     |\n",
            "|    value_loss           | 5.59e-06      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 450000: 1489.7s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 302          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 1490         |\n",
            "|    total_timesteps      | 450560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.831236e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.000157    |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -1.06e-05    |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -2.91e-06    |\n",
            "|    value_loss           | 8.67e-07     |\n",
            "------------------------------------------\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 111           |\n",
            "|    time_elapsed         | 1504          |\n",
            "|    total_timesteps      | 454656        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.8812792e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000129     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -3.2e-05      |\n",
            "|    n_updates            | 1100          |\n",
            "|    policy_gradient_loss | -2.3e-05      |\n",
            "|    value_loss           | 2.01e-06      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 455000: 1510.1s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 112           |\n",
            "|    time_elapsed         | 1518          |\n",
            "|    total_timesteps      | 458752        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.1787051e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000127     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.000105     |\n",
            "|    n_updates            | 1110          |\n",
            "|    policy_gradient_loss | -7.63e-06     |\n",
            "|    value_loss           | 2.37e-06      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 460000: 1525.6s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 302          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 1531         |\n",
            "|    total_timesteps      | 462848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 2.415618e-08 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.000157    |\n",
            "|    explained_variance   | 1            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.000167    |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.000123    |\n",
            "|    value_loss           | 2.23e-05     |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 465000: 1541.1s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 114           |\n",
            "|    time_elapsed         | 1545          |\n",
            "|    total_timesteps      | 466944        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 9.0221874e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000135     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -1.11e-05     |\n",
            "|    n_updates            | 1130          |\n",
            "|    policy_gradient_loss | -3.81e-06     |\n",
            "|    value_loss           | 7.53e-07      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 470000: 1556.6s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 115       |\n",
            "|    time_elapsed         | 1558      |\n",
            "|    total_timesteps      | 471040    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0001   |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -1.27e-05 |\n",
            "|    n_updates            | 1140      |\n",
            "|    policy_gradient_loss | -5.04e-06 |\n",
            "|    value_loss           | 1.08e-06  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 475000: 1572.2s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 116           |\n",
            "|    time_elapsed         | 1572          |\n",
            "|    total_timesteps      | 475136        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.0163286e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000103     |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -1.29e-05     |\n",
            "|    n_updates            | 1150          |\n",
            "|    policy_gradient_loss | -2.6e-06      |\n",
            "|    value_loss           | 9.41e-07      |\n",
            "-------------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 117       |\n",
            "|    time_elapsed         | 1586      |\n",
            "|    total_timesteps      | 479232    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.63e-05 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -1.37e-05 |\n",
            "|    n_updates            | 1160      |\n",
            "|    policy_gradient_loss | -8.61e-06 |\n",
            "|    value_loss           | 1.52e-06  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 480000: 1592.4s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 302           |\n",
            "|    iterations           | 118           |\n",
            "|    time_elapsed         | 1599          |\n",
            "|    total_timesteps      | 483328        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.0972525e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0001       |\n",
            "|    explained_variance   | 1             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -8.94e-06     |\n",
            "|    n_updates            | 1170          |\n",
            "|    policy_gradient_loss | -2.79e-06     |\n",
            "|    value_loss           | 7.04e-07      |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 485000: 1608.3s elapsed, Mean Reward: 3.2256\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 119       |\n",
            "|    time_elapsed         | 1613      |\n",
            "|    total_timesteps      | 487424    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.000112 |\n",
            "|    explained_variance   | 1         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -1.5e-05  |\n",
            "|    n_updates            | 1180      |\n",
            "|    policy_gradient_loss | -8.74e-06 |\n",
            "|    value_loss           | 1.29e-06  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 490000: 1623.7s elapsed, Mean Reward: 2.3204\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 302         |\n",
            "|    iterations           | 120         |\n",
            "|    time_elapsed         | 1627        |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.060244977 |\n",
            "|    clip_fraction        | 0.0108      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.00988    |\n",
            "|    explained_variance   | 1           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0636     |\n",
            "|    n_updates            | 1190        |\n",
            "|    policy_gradient_loss | -0.00271    |\n",
            "|    value_loss           | 0.0008      |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 495000: 1639.4s elapsed, Mean Reward: 1.9623\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 121        |\n",
            "|    time_elapsed         | 1640       |\n",
            "|    total_timesteps      | 495616     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.11511166 |\n",
            "|    clip_fraction        | 0.453      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.244     |\n",
            "|    explained_variance   | -0.233     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.257      |\n",
            "|    n_updates            | 1200       |\n",
            "|    policy_gradient_loss | -0.105     |\n",
            "|    value_loss           | 3.87       |\n",
            "----------------------------------------\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 302        |\n",
            "|    iterations           | 122        |\n",
            "|    time_elapsed         | 1654       |\n",
            "|    total_timesteps      | 499712     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.20777291 |\n",
            "|    clip_fraction        | 0.829      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.299     |\n",
            "|    explained_variance   | -0.0119    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.155      |\n",
            "|    n_updates            | 1210       |\n",
            "|    policy_gradient_loss | -0.145     |\n",
            "|    value_loss           | 4.01       |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 500000: 1659.7s elapsed, Mean Reward: 1.1321\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 123       |\n",
            "|    time_elapsed         | 1668      |\n",
            "|    total_timesteps      | 503808    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.8471739 |\n",
            "|    clip_fraction        | 0.644     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.18     |\n",
            "|    explained_variance   | -0.262    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.874     |\n",
            "|    n_updates            | 1220      |\n",
            "|    policy_gradient_loss | -0.144    |\n",
            "|    value_loss           | 10.4      |\n",
            "---------------------------------------\n",
            "\u001b[2K\u001b[35m 100%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m503,808/500,000 \u001b[0m [ \u001b[33m0:27:39\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m300 it/s\u001b[0m ]\n",
            "\u001b[?25h\n",
            "============================================================\n",
            "‚úÖ Training completed in 1672.7 seconds (27.9 minutes)\n",
            "============================================================\n",
            "\n",
            "üíæ Model saved to: models/ppo_cloud_refinement_model_20260112_150456\n",
            "üîç Model params hash: 5478501895101228479\n",
            "\n",
            "============================================================\n",
            "üìä Evaluating PPO Agent on Test Set\n",
            "============================================================\n",
            "\n",
            "üìä Evaluating on 20 test patches...\n",
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "\n",
            "‚úÖ Evaluation completed on 20 test patches\n",
            "\n",
            "============================================================\n",
            "üìà TEST SET PERFORMANCE (20 patches, 5,242,880 pixels)\n",
            "============================================================\n",
            "\n",
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.6719\n",
            "  Precision: 0.1918\n",
            "  Recall:    0.3898\n",
            "  F1-Score:  0.2571\n",
            "\n",
            "ü§ñ PPO Refined:\n",
            "  Accuracy:  0.5011\n",
            "  Precision: 0.1347\n",
            "  Recall:    0.4473\n",
            "  F1-Score:  0.2071\n",
            "\n",
            "üéØ Improvements:\n",
            "  F1-Score:  -19.45%\n",
            "  Accuracy:  -25.42%\n",
            "  Precision: -0.0571\n",
            "  Recall:    +0.0575\n",
            "\n",
            "üíæ Results saved to: results/ppo_training_results.json\n",
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:366: NotGeoreferencedWarning: The given matrix is equal to Affine.identity or its flipped counterpart. GDAL may ignore this matrix and save no geotransform without raising an error. This behavior is somewhat driver-specific.\n",
            "  dataset = writer(\n",
            "üíæ Refined cloud mask saved to: data/ppo_refined_cloud_mask.tif\n",
            "\n",
            "============================================================\n",
            "‚úÖ PPO Training and Evaluation Complete!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Run PPO training (main step - takes 1-2 hours)\n",
        "print(\"üöÄ Starting PPO training...\")\n",
        "print(\"This will take 1-2 hours with GPU\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python train_ppo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a499b332",
      "metadata": {},
      "source": [
        "### üîÑ Train PPO with Multiple Patches (Better Generalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd03da1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö° FAST Multi-Patch PPO training (pre-loads all patches into RAM)\n",
        "print(\"üöÄ Starting FAST Multi-Patch PPO training...\")\n",
        "print(\"Pre-loading 80 patches into RAM to avoid I/O overhead\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python train_ppo_multipatch_fast.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bddc2e88",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save multi-patch model to Google Drive\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "model_dirs = sorted(glob.glob(\"models/ppo_multipatch_model_*\"))\n",
        "if model_dirs:\n",
        "    latest_model = model_dirs[-1]\n",
        "    drive_model_path = \"/content/drive/MyDrive/Colab_Data/ppo_multipatch_model_final\"\n",
        "    \n",
        "    print(f\"üì¶ Copying multi-patch model to Drive: {drive_model_path}\")\n",
        "    if os.path.exists(drive_model_path):\n",
        "        shutil.rmtree(drive_model_path)\n",
        "    shutil.copytree(latest_model, drive_model_path)\n",
        "    print(f\"‚úÖ Multi-patch model saved to Google Drive!\")\n",
        "else:\n",
        "    print(\"‚ùå No multi-patch model found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7yfzCWR5Dpt4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yfzCWR5Dpt4",
        "outputId": "c9c4afed-b733-4d02-aca2-7269d593d10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-12 07:23:24.410071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768202604.431626   31076 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768202604.438035   31076 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768202604.454205   31076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202604.454240   31076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202604.454243   31076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202604.454246   31076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Loading model from: models/ppo_cloud_refinement_model_20260112_062116\n",
            "Loading data...\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 7225\n",
            "\n",
            "Evaluating on 7225 patches...\n",
            "  Progress: 1000/7225\n",
            "  Progress: 2000/7225\n",
            "  Progress: 3000/7225\n",
            "  Progress: 4000/7225\n",
            "  Progress: 5000/7225\n",
            "  Progress: 6000/7225\n",
            "  Progress: 7000/7225\n",
            "‚úÖ Evaluation complete!\n",
            "\n",
            "============================================================\n",
            "üìà RESULTS\n",
            "============================================================\n",
            "\n",
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.4187\n",
            "  Precision: 0.1706\n",
            "  Recall:    0.6232\n",
            "  F1-Score:  0.2679\n",
            "\n",
            "ü§ñ PPO Refined:\n",
            "  Accuracy:  0.1826\n",
            "  Precision: 0.1707\n",
            "  Recall:    0.9819\n",
            "  F1-Score:  0.2908\n",
            "\n",
            "üéØ F1-Score Improvement: +8.54%\n"
          ]
        }
      ],
      "source": [
        "!python evaluate_saved_model.py models/ppo_cloud_refinement_model_20260112_062116"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ca4cbf",
      "metadata": {},
      "source": [
        "### üì¶ Backup Current Results (Single-Patch Training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee525085",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preserve the single-patch training results for manuscript\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Backup paths\n",
        "drive_backup = \"/content/drive/MyDrive/Colab_Data/thesis_results_backup_single_patch\"\n",
        "os.makedirs(drive_backup, exist_ok=True)\n",
        "\n",
        "# Copy current model to backup location\n",
        "current_model = \"models/ppo_cloud_refinement_model_20260112_150456\"\n",
        "if os.path.exists(current_model):\n",
        "    backup_model = f\"{drive_backup}/ppo_single_patch_model\"\n",
        "    if os.path.exists(backup_model):\n",
        "        shutil.rmtree(backup_model)\n",
        "    shutil.copytree(current_model, backup_model)\n",
        "    print(f\"‚úÖ Model backed up to: {backup_model}\")\n",
        "\n",
        "# Copy results JSON\n",
        "if os.path.exists(\"results/ppo_training_results.json\"):\n",
        "    shutil.copy(\"results/ppo_training_results.json\", f\"{drive_backup}/single_patch_results.json\")\n",
        "    print(f\"‚úÖ Results backed up to: {drive_backup}/single_patch_results.json\")\n",
        "\n",
        "# Copy refined mask\n",
        "if os.path.exists(\"data/ppo_refined_cloud_mask.tif\"):\n",
        "    shutil.copy(\"data/ppo_refined_cloud_mask.tif\", f\"{drive_backup}/single_patch_refined_mask.tif\")\n",
        "    print(f\"‚úÖ Refined mask backed up\")\n",
        "\n",
        "print(f\"\\nüìÇ Backup location: {drive_backup}\")\n",
        "print(\"‚úÖ Single-patch training results preserved for manuscript!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EP2RYcJqCuEX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP2RYcJqCuEX",
        "outputId": "418e380d-6edc-4125-c158-0d0004689e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-12 07:14:10.610183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768202050.631174   28746 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768202050.637559   28746 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768202050.653443   28746 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202050.653470   28746 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202050.653473   28746 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202050.653476   28746 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Loading model from: models/ppo_cloud_refinement_model_20260112_065746\n",
            "Loading data...\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 7225\n",
            "\n",
            "Evaluating on 7225 patches...\n",
            "  Progress: 1000/7225\n",
            "  Progress: 2000/7225\n",
            "  Progress: 3000/7225\n",
            "  Progress: 4000/7225\n",
            "  Progress: 5000/7225\n",
            "  Progress: 6000/7225\n",
            "  Progress: 7000/7225\n",
            "‚úÖ Evaluation complete!\n",
            "\n",
            "============================================================\n",
            "üìà RESULTS\n",
            "============================================================\n",
            "\n",
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.4187\n",
            "  Precision: 0.1706\n",
            "  Recall:    0.6232\n",
            "  F1-Score:  0.2679\n",
            "\n",
            "ü§ñ PPO Refined:\n",
            "  Accuracy:  0.1826\n",
            "  Precision: 0.1707\n",
            "  Recall:    0.9819\n",
            "  F1-Score:  0.2908\n",
            "\n",
            "üéØ F1-Score Improvement: +8.54%\n"
          ]
        }
      ],
      "source": [
        "!python evaluate_saved_model.py models/ppo_cloud_refinement_model_20260112_065746"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84ada1a3",
      "metadata": {
        "id": "84ada1a3"
      },
      "source": [
        "## 5Ô∏è‚É£ Results & Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "81e0513a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81e0513a",
        "outputId": "802f7439-d143-40bf-9c8a-85f1449b20dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üìà PPO TRAINING RESULTS\n",
            "============================================================\n",
            "\n",
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.6719\n",
            "  Precision: 0.1918\n",
            "  Recall:    0.3898\n",
            "  F1-Score:  0.2571\n",
            "\n",
            "ü§ñ PPO Refined:\n",
            "  Accuracy:  0.5011\n",
            "  Precision: 0.1347\n",
            "  Recall:    0.4473\n",
            "  F1-Score:  0.2071\n",
            "\n",
            "üéØ Improvements:\n",
            "  F1-Score:  -19.45%\n",
            "  Accuracy:  -25.42%\n",
            "  Precision: -0.0571\n",
            "  Recall:    +0.0575\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Display training results\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "results_file = Path('results/ppo_training_results.json')\n",
        "\n",
        "if results_file.exists():\n",
        "    with open(results_file) as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    cnn = results['cnn_baseline']\n",
        "    ppo = results['ppo_refined']\n",
        "    imp = results['improvements']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìà PPO TRAINING RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\nüß† CNN Baseline:\")\n",
        "    print(f\"  Accuracy:  {cnn['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {cnn['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {cnn['recall']:.4f}\")\n",
        "    print(f\"  F1-Score:  {cnn['f1_score']:.4f}\")\n",
        "\n",
        "    print(\"\\nü§ñ PPO Refined:\")\n",
        "    print(f\"  Accuracy:  {ppo['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {ppo['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {ppo['recall']:.4f}\")\n",
        "    print(f\"  F1-Score:  {ppo['f1_score']:.4f}\")\n",
        "\n",
        "    print(\"\\nüéØ Improvements:\")\n",
        "    print(f\"  F1-Score:  {imp['f1_score_percent']:+.2f}%\")\n",
        "    print(f\"  Accuracy:  {imp['accuracy_percent']:+.2f}%\")\n",
        "    print(f\"  Precision: {imp['precision_delta']:+.4f}\")\n",
        "    print(f\"  Recall:    {imp['recall_delta']:+.4f}\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "else:\n",
        "    print(\"‚ùå Results file not found\")\n",
        "    print(\"Make sure PPO training completed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7b1345f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b1345f2",
        "outputId": "89dda1d0-35ea-4e23-e5c2-cd16212fdc5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Results saved to Google Drive\n",
            "‚úÖ Model saved to Google Drive\n",
            "\n",
            "üìÇ Results at: /content/drive/MyDrive/Colab_Data/thesis_results\n"
          ]
        }
      ],
      "source": [
        "# Save to Google Drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "gdrive_results = '/content/drive/MyDrive/Colab_Data/thesis_results'\n",
        "Path(gdrive_results).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy results\n",
        "try:\n",
        "    shutil.copy('results/ppo_training_results.json', f'{gdrive_results}/ppo_results.json')\n",
        "    print(\"‚úÖ Results saved to Google Drive\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è  Could not save results to Google Drive\")\n",
        "\n",
        "# Copy model\n",
        "try:\n",
        "    import glob\n",
        "    model_files = glob.glob('models/ppo_cloud_refinement_model*')\n",
        "    for f in model_files:\n",
        "        shutil.copy(f, f'{gdrive_results}/{Path(f).name}')\n",
        "    print(\"‚úÖ Model saved to Google Drive\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è  Could not save model\")\n",
        "\n",
        "print(f\"\\nüìÇ Results at: {gdrive_results}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37b8fd9",
      "metadata": {
        "id": "b37b8fd9"
      },
      "source": [
        "## ‚úÖ Summary\n",
        "\n",
        "**Done!** Your PPO agent has been trained.\n",
        "\n",
        "**What happened:**\n",
        "1. ‚úÖ Loaded CNN baseline performance\n",
        "2. ‚úÖ Trained PPO with balanced reward structure\n",
        "3. ‚úÖ Evaluated on test data\n",
        "4. ‚úÖ Saved results and model\n",
        "\n",
        "**Key improvements in PPO:**\n",
        "- Better exploration with entropy coefficient\n",
        "- Policy gradient approach handles reward shaping better\n",
        "- Larger patch size (64√ó64) for better context\n",
        "- 100k timesteps for better convergence\n",
        "\n",
        "**Next steps:**\n",
        "1. Download results from Google Drive\n",
        "2. Analyze the refined cloud mask\n",
        "3. Consider hyperparameter tuning if needed\n",
        "\n",
        "**For thesis writing:**\n",
        "- See `thesis_recommendations.md` for advanced techniques\n",
        "- Check `training_results.json` for detailed metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a270516",
      "metadata": {
        "id": "9a270516"
      },
      "source": [
        "## üéØ Evaluate Saved Model on Test Set (80/20 split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d74bc8b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d74bc8b2",
        "outputId": "bcb76a26-9c23-468e-c8f0-a784c98f6dcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Loading model from: /content/drive/MyDrive/Colab_Data/thesis_results/ppo_cloud_refinement_model_20260112_150456.zip\n",
            "‚úÖ Model loaded successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Define the Google Drive results directory (this should be consistent)\n",
        "gdrive_results = '/content/drive/MyDrive/Colab_Data/thesis_results'\n",
        "\n",
        "# Find the latest PPO model saved in that directory\n",
        "# Models are saved as 'ppo_cloud_refinement_model_<timestamp>.zip'\n",
        "model_files_in_drive = glob.glob(os.path.join(gdrive_results, 'ppo_cloud_refinement_model*.zip'))\n",
        "\n",
        "if not model_files_in_drive:\n",
        "    print(f\"‚ùå No PPO model found in {gdrive_results}. Please ensure the training step completed and saved the model correctly.\")\n",
        "    # You might want to exit or raise an error here depending on desired behavior\n",
        "    raise FileNotFoundError(f\"No PPO model found in {gdrive_results}\")\n",
        "\n",
        "# Sort by modification time to get the latest model\n",
        "model_files_in_drive.sort(key=os.path.getmtime, reverse=True)\n",
        "model_path = model_files_in_drive[0]\n",
        "\n",
        "print(f\"ü§ñ Loading model from: {model_path}\")\n",
        "\n",
        "model = PPO.load(model_path)\n",
        "print(\"‚úÖ Model loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ba936e11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba936e11",
        "outputId": "ffab0511-a3b2-495c-cf22-c100069035c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Total patches: 100\n",
            "üìä Train patches: 80 (indices 0-79)\n",
            "üìä Test patches: 20 (indices 80-99)\n",
            "‚úÖ Test set loaded: 20 patches\n"
          ]
        }
      ],
      "source": [
        "# Load test data (20 patches: indices 80-100)\n",
        "import glob\n",
        "import os\n",
        "\n",
        "data_dir = \"data/cloudsen12_processed\"\n",
        "image_files = sorted(glob.glob(os.path.join(data_dir, \"*_image.tif\")))\n",
        "mask_files = sorted(glob.glob(os.path.join(data_dir, \"*_mask.tif\")))\n",
        "\n",
        "# 80/20 split\n",
        "split_idx = int(0.8 * len(image_files))\n",
        "test_image_files = image_files[split_idx:]\n",
        "test_mask_files = mask_files[split_idx:]\n",
        "\n",
        "print(f\"üìä Total patches: {len(image_files)}\")\n",
        "print(f\"üìä Train patches: {split_idx} (indices 0-{split_idx-1})\")\n",
        "print(f\"üìä Test patches: {len(test_image_files)} (indices {split_idx}-{len(image_files)-1})\")\n",
        "print(f\"‚úÖ Test set loaded: {len(test_image_files)} patches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f0dbdaa1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0dbdaa1",
        "outputId": "2e59e2a2-5216-435b-c0ad-0c89f9703ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Evaluating on 20 test patches...\n",
            "  Processing test patch 1/20\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 49\n",
            "\n",
            "‚úÖ Evaluation completed on 20 test patches\n",
            "üìä Total test pixels: 5,242,880\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on all test patches\n",
        "from rl_environment import CloudMaskRefinementEnv\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(f\"\\nüìä Evaluating on {len(test_image_files)} test patches...\")\n",
        "\n",
        "all_gt = []\n",
        "all_cnn = []\n",
        "all_ppo = []\n",
        "\n",
        "for idx, (img_path, mask_path) in enumerate(zip(test_image_files, test_mask_files)):\n",
        "    print(f\"  Processing test patch {idx+1}/{len(test_image_files)}\", end='\\r')\n",
        "\n",
        "    # Load test patch\n",
        "    test_image = load_sentinel2_image(img_path)\n",
        "    test_cnn_prob = get_cloud_mask(test_image)\n",
        "\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        test_gt = src.read(1)\n",
        "\n",
        "    # Create evaluation environment for this patch\n",
        "    eval_env = CloudMaskRefinementEnv(test_image, test_cnn_prob, test_gt, patch_size=64)\n",
        "    rl_predictions = np.zeros_like(test_gt, dtype=np.uint8)\n",
        "\n",
        "    # Evaluate all patches (each is a separate episode)\n",
        "    num_patches = len(eval_env.all_positions)\n",
        "\n",
        "    for patch_idx in range(num_patches):\n",
        "        obs, _ = eval_env.reset()\n",
        "        i, j = eval_env.current_pos\n",
        "        patch_size = eval_env.patch_size\n",
        "\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        rl_predictions[i:i+patch_size, j:j+patch_size] = action\n",
        "\n",
        "        obs, reward, done, truncated, info = eval_env.step(action)\n",
        "\n",
        "    # Collect predictions\n",
        "    gt_binary = (test_gt > 0).astype(np.uint8)\n",
        "    cnn_binary = (test_cnn_prob > 0.5).astype(np.uint8)\n",
        "    rl_binary = (rl_predictions > 0).astype(np.uint8)\n",
        "\n",
        "    all_gt.append(gt_binary.flatten())\n",
        "    all_cnn.append(cnn_binary.flatten())\n",
        "    all_ppo.append(rl_binary.flatten())\n",
        "\n",
        "print(f\"\\n‚úÖ Evaluation completed on {len(test_image_files)} test patches\")\n",
        "\n",
        "# Combine all test patches\n",
        "all_gt = np.concatenate(all_gt)\n",
        "all_cnn = np.concatenate(all_cnn)\n",
        "all_ppo = np.concatenate(all_ppo)\n",
        "\n",
        "print(f\"üìä Total test pixels: {len(all_gt):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "92e1dc8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92e1dc8f",
        "outputId": "f424f1ac-c9e6-4600-981c-6afdf9989e95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üìà TEST SET RESULTS (20 patches, 5,242,880 pixels)\n",
            "============================================================\n",
            "\n",
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.6719 (67.19%)\n",
            "  Precision: 0.1918\n",
            "  Recall:    0.3898\n",
            "  F1-Score:  0.2571\n",
            "\n",
            "ü§ñ PPO Refined:\n",
            "  Accuracy:  0.5011 (50.11%)\n",
            "  Precision: 0.1347\n",
            "  Recall:    0.4473\n",
            "  F1-Score:  0.2071\n",
            "\n",
            "üéØ Improvements:\n",
            "  F1-Score:  -19.45%\n",
            "  Accuracy:  -25.42%\n",
            "  Precision: -0.0571\n",
            "  Recall:    +0.0575\n",
            "\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# Calculate metrics on test set\n",
        "cnn_accuracy = accuracy_score(all_gt, all_cnn)\n",
        "cnn_precision = precision_score(all_gt, all_cnn, zero_division=0)\n",
        "cnn_recall = recall_score(all_gt, all_cnn, zero_division=0)\n",
        "cnn_f1 = f1_score(all_gt, all_cnn, zero_division=0)\n",
        "\n",
        "ppo_accuracy = accuracy_score(all_gt, all_ppo)\n",
        "ppo_precision = precision_score(all_gt, all_ppo, zero_division=0)\n",
        "ppo_recall = recall_score(all_gt, all_ppo, zero_division=0)\n",
        "ppo_f1 = f1_score(all_gt, all_ppo, zero_division=0)\n",
        "\n",
        "# Calculate improvements\n",
        "f1_improvement = ((ppo_f1 - cnn_f1) / cnn_f1 * 100) if cnn_f1 > 0 else 0\n",
        "accuracy_improvement = ((ppo_accuracy - cnn_accuracy) / cnn_accuracy * 100) if cnn_accuracy > 0 else 0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"üìà TEST SET RESULTS ({len(test_image_files)} patches, {len(all_gt):,} pixels)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüß† CNN Baseline:\")\n",
        "print(f\"  Accuracy:  {cnn_accuracy:.4f} ({cnn_accuracy*100:.2f}%)\")\n",
        "print(f\"  Precision: {cnn_precision:.4f}\")\n",
        "print(f\"  Recall:    {cnn_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {cnn_f1:.4f}\")\n",
        "\n",
        "print(\"\\nü§ñ PPO Refined:\")\n",
        "print(f\"  Accuracy:  {ppo_accuracy:.4f} ({ppo_accuracy*100:.2f}%)\")\n",
        "print(f\"  Precision: {ppo_precision:.4f}\")\n",
        "print(f\"  Recall:    {ppo_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {ppo_f1:.4f}\")\n",
        "\n",
        "print(\"\\nüéØ Improvements:\")\n",
        "print(f\"  F1-Score:  {f1_improvement:+.2f}%\")\n",
        "print(f\"  Accuracy:  {accuracy_improvement:+.2f}%\")\n",
        "print(f\"  Precision: {ppo_precision - cnn_precision:+.4f}\")\n",
        "print(f\"  Recall:    {ppo_recall - cnn_recall:+.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
