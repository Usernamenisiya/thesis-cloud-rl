{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe41eb39",
      "metadata": {
        "id": "fe41eb39"
      },
      "source": [
        "## 1ï¸âƒ£ Clone & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fe28e572",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe28e572",
        "outputId": "cc2f0141-70b5-4fb5-8678-e3ad0435a066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'thesis-cloud-rl'...\n",
            "remote: Enumerating objects: 1765, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 1765 (delta 8), reused 16 (delta 6), pack-reused 1742 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1765/1765), 654.03 MiB | 16.78 MiB/s, done.\n",
            "Resolving deltas: 100% (244/244), done.\n",
            "Updating files: 100% (2632/2632), done.\n",
            "/content/thesis-cloud-rl/thesis-cloud-rl\n",
            "/content/thesis-cloud-rl/thesis-cloud-rl\n",
            "total 40064\n",
            "drwxr-xr-x 4 root root     4096 Jan 12 14:24 .\n",
            "drwxr-xr-x 5 root root     4096 Jan 12 14:24 ..\n",
            "-rw-r--r-- 1 root root     3567 Jan 12 14:24 analyze_data_distribution.py\n",
            "-rw-r--r-- 1 root root     5945 Jan 12 14:24 cloudsen12_loader.py\n",
            "-rw-r--r-- 1 root root     1661 Jan 12 14:24 cnn_inference.py\n",
            "-rw-r--r-- 1 root root   200302 Jan 12 14:24 colab_training.ipynb\n",
            "drwxr-xr-x 3 root root     4096 Jan 12 14:24 data\n",
            "-rw-r--r-- 1 root root     4697 Jan 12 14:24 data_download.py\n",
            "-rw-r--r-- 1 root root     4276 Jan 12 14:24 download_cloudsen12_subset.py\n",
            "-rw-r--r-- 1 root root     5988 Jan 12 14:24 enhanced_cnn_baseline.py\n",
            "-rw-r--r-- 1 root root     5458 Jan 12 14:24 evaluate_on_test_set.py\n",
            "-rw-r--r-- 1 root root     4788 Jan 12 14:24 evaluate_rl_model.py\n",
            "-rw-r--r-- 1 root root     3564 Jan 12 14:24 evaluate_saved_model.py\n",
            "-rw-r--r-- 1 root root     9695 Jan 12 14:24 finetune_cnn_baseline.py\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/Usernamenisiya/thesis-cloud-rl.git\n",
        "%cd thesis-cloud-rl\n",
        "\n",
        "# Verify\n",
        "!pwd\n",
        "!ls -la | head -15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "690b0055",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "690b0055",
        "outputId": "866676c2-5691-405b-dc10-197c190e3819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.24.0+cu126)\n",
            "Requirement already satisfied: s2cloudless in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.7.3)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.7.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.4.4)\n",
            "Requirement already satisfied: zarr in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.1.5)\n",
            "Requirement already satisfied: shimmy>=2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.15.0->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: lightgbm>=2.0.11 in /usr/local/lib/python3.12/dist-packages (from s2cloudless->-r requirements.txt (line 3)) (4.6.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from s2cloudless->-r requirements.txt (line 3)) (4.12.0.88)\n",
            "Requirement already satisfied: sentinelhub>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from s2cloudless->-r requirements.txt (line 3)) (3.11.3)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym->-r requirements.txt (line 5)) (0.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (2025.11.12)\n",
            "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (1.1.1.2)\n",
            "Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.12/dist-packages (from zarr->-r requirements.txt (line 11)) (0.8.1.post1)\n",
            "Requirement already satisfied: google-crc32c>=1.5 in /usr/local/lib/python3.12/dist-packages (from zarr->-r requirements.txt (line 11)) (1.7.1)\n",
            "Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.12/dist-packages (from zarr->-r requirements.txt (line 11)) (0.16.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr->-r requirements.txt (line 11)) (6.0.3)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3->-r requirements.txt (line 4)) (0.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: aenum>=2.1.4 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.1.16)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (0.6.7)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.3.1)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.1.2)\n",
            "Requirement already satisfied: tifffile>=2020.9.30 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2025.12.12)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.4.0)\n",
            "Requirement already satisfied: tomli-w in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: utm in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3->-r requirements.txt (line 4)) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n",
            "âœ… Dependencies installed\n",
            "PyTorch: 2.9.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install gymnasium  # Updated from deprecated gym\n",
        "\n",
        "import torch\n",
        "import stable_baselines3\n",
        "import rasterio\n",
        "\n",
        "print(\"âœ… Dependencies installed\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ced755bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ced755bc",
        "outputId": "0756d34b-9437-41f2-b0e3-e13ee1f682c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Jan 12 14:25:40 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             42W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "âœ… Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nâœ… Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2974c679",
      "metadata": {
        "id": "2974c679"
      },
      "source": [
        "## 2ï¸âƒ£ Setup CloudSEN12 Real Ground Truth Data\n",
        "\n",
        "**Using CloudSEN12 expert-labeled dataset:**\n",
        "- Already downloaded: 100 patches in `Colab_Data/cloudsen12_subset/`\n",
        "- Process with `cloudsen12_loader.py` to extract 10 bands\n",
        "- **26M pixels** for robust evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1c8ad7c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c8ad7c8",
        "outputId": "05eff114-947c-4e40-87c1-e86e694ef773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… CloudSEN12 data found: 100 patches\n",
            "ðŸ“‚ Location: /content/drive/MyDrive/Colab_Data/cloudsen12_subset\n",
            "\n",
            "ðŸ”§ Processing CloudSEN12 patches...\n",
            "\n",
            "============================================================\n",
            "ðŸ”§ Preparing CloudSEN12 for Training\n",
            "============================================================\n",
            "============================================================\n",
            "ðŸ“¦ Loading CloudSEN12 Data\n",
            "============================================================\n",
            "\n",
            "âœ… Found 100 patches to load\n",
            "\n",
            "\n",
            "âœ… Successfully loaded 100 patches\n",
            "ðŸ“Š Image shape: (512, 512, 10)\n",
            "ðŸ“Š Mask shape: (512, 512)\n",
            "ðŸ“Š Image bands: 10\n",
            "ðŸ“Š Cloud coverage: 16.0%\n",
            "\n",
            "ðŸ’¾ Saving 100 patches to data/cloudsen12_processed\n",
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:366: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = writer(\n",
            "  Saved: patch_000\n",
            "  Saved: patch_001\n",
            "  Saved: patch_002\n",
            "  Saved: patch_003\n",
            "  Saved: patch_004\n",
            "  Saved: patch_005\n",
            "  Saved: patch_006\n",
            "  Saved: patch_007\n",
            "  Saved: patch_008\n",
            "  Saved: patch_009\n",
            "  Saved: patch_010\n",
            "  Saved: patch_011\n",
            "  Saved: patch_012\n",
            "  Saved: patch_013\n",
            "  Saved: patch_014\n",
            "  Saved: patch_015\n",
            "  Saved: patch_016\n",
            "  Saved: patch_017\n",
            "  Saved: patch_018\n",
            "  Saved: patch_019\n",
            "  Saved: patch_020\n",
            "  Saved: patch_021\n",
            "  Saved: patch_022\n",
            "  Saved: patch_023\n",
            "  Saved: patch_024\n",
            "  Saved: patch_025\n",
            "  Saved: patch_026\n",
            "  Saved: patch_027\n",
            "  Saved: patch_028\n",
            "  Saved: patch_029\n",
            "  Saved: patch_030\n",
            "  Saved: patch_031\n",
            "  Saved: patch_032\n",
            "  Saved: patch_033\n",
            "  Saved: patch_034\n",
            "  Saved: patch_035\n",
            "  Saved: patch_036\n",
            "  Saved: patch_037\n",
            "  Saved: patch_038\n",
            "  Saved: patch_039\n",
            "  Saved: patch_040\n",
            "  Saved: patch_041\n",
            "  Saved: patch_042\n",
            "  Saved: patch_043\n",
            "  Saved: patch_044\n",
            "  Saved: patch_045\n",
            "  Saved: patch_046\n",
            "  Saved: patch_047\n",
            "  Saved: patch_048\n",
            "  Saved: patch_049\n",
            "  Saved: patch_050\n",
            "  Saved: patch_051\n",
            "  Saved: patch_052\n",
            "  Saved: patch_053\n",
            "  Saved: patch_054\n",
            "  Saved: patch_055\n",
            "  Saved: patch_056\n",
            "  Saved: patch_057\n",
            "  Saved: patch_058\n",
            "  Saved: patch_059\n",
            "  Saved: patch_060\n",
            "  Saved: patch_061\n",
            "  Saved: patch_062\n",
            "  Saved: patch_063\n",
            "  Saved: patch_064\n",
            "  Saved: patch_065\n",
            "  Saved: patch_066\n",
            "  Saved: patch_067\n",
            "  Saved: patch_068\n",
            "  Saved: patch_069\n",
            "  Saved: patch_070\n",
            "  Saved: patch_071\n",
            "  Saved: patch_072\n",
            "  Saved: patch_073\n",
            "  Saved: patch_074\n",
            "  Saved: patch_075\n",
            "  Saved: patch_076\n",
            "  Saved: patch_077\n",
            "  Saved: patch_078\n",
            "  Saved: patch_079\n",
            "  Saved: patch_080\n",
            "  Saved: patch_081\n",
            "  Saved: patch_082\n",
            "  Saved: patch_083\n",
            "  Saved: patch_084\n",
            "  Saved: patch_085\n",
            "  Saved: patch_086\n",
            "  Saved: patch_087\n",
            "  Saved: patch_088\n",
            "  Saved: patch_089\n",
            "  Saved: patch_090\n",
            "  Saved: patch_091\n",
            "  Saved: patch_092\n",
            "  Saved: patch_093\n",
            "  Saved: patch_094\n",
            "  Saved: patch_095\n",
            "  Saved: patch_096\n",
            "  Saved: patch_097\n",
            "  Saved: patch_098\n",
            "  Saved: patch_099\n",
            "\n",
            "âœ… Data preparation complete!\n",
            "ðŸ“‚ Files saved to: data/cloudsen12_processed\n",
            "\n",
            "ðŸŽ¯ Ready for training with real ground truth!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify CloudSEN12 data exists\n",
        "cloudsen_path = '/content/drive/MyDrive/Colab_Data/cloudsen12_subset'\n",
        "\n",
        "if os.path.exists(cloudsen_path):\n",
        "    num_patches = len([d for d in Path(cloudsen_path).iterdir() if d.is_dir()])\n",
        "    print(f\"âœ… CloudSEN12 data found: {num_patches} patches\")\n",
        "    print(f\"ðŸ“‚ Location: {cloudsen_path}\")\n",
        "\n",
        "    # Process CloudSEN12 data with loader (extracts 10 bands, converts masks)\n",
        "    print(\"\\nðŸ”§ Processing CloudSEN12 patches...\")\n",
        "    !python cloudsen12_loader.py\n",
        "else:\n",
        "    print(f\"âŒ CloudSEN12 data not found at: {cloudsen_path}\")\n",
        "    print(\"Please run CloudSEN12 download notebook first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "45e4f059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45e4f059",
        "outputId": "30debb7c-3f25-4c7b-d211-a81f41ed4196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… CloudSEN12 data processed successfully!\n",
            "ðŸ“Š Found 100 image patches\n",
            "ðŸ“Š Found 100 mask patches\n",
            "\n",
            "ðŸŽ¯ Ready for training with real ground truth!\n"
          ]
        }
      ],
      "source": [
        "# Verify processed CloudSEN12 data\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "processed_dir = 'data/cloudsen12_processed'\n",
        "image_files = glob.glob(f'{processed_dir}/*_image.tif')\n",
        "mask_files = glob.glob(f'{processed_dir}/*_mask.tif')\n",
        "\n",
        "if len(image_files) > 0 and len(mask_files) > 0:\n",
        "    print(f\"âœ… CloudSEN12 data processed successfully!\")\n",
        "    print(f\"ðŸ“Š Found {len(image_files)} image patches\")\n",
        "    print(f\"ðŸ“Š Found {len(mask_files)} mask patches\")\n",
        "    print(\"\\nðŸŽ¯ Ready for training with real ground truth!\")\n",
        "else:\n",
        "    print(\"âŒ Processed data not found\")\n",
        "    print(\"Please check cloudsen12_loader.py output for errors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71cc30ed",
      "metadata": {
        "id": "71cc30ed"
      },
      "source": [
        "## 3ï¸âƒ£ Check CNN Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2f381a12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f381a12",
        "outputId": "5ebfcda8-521f-4e10-84af-ff81e3a9081d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ§  Evaluating CNN Baseline on CloudSEN12 Real Ground Truth\n",
            "============================================================\n",
            "Processing 100 patches...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Evaluated on 100 CloudSEN12 patches\n",
            "ðŸ“Š Total pixels: 26,214,400\n",
            "\n",
            "ðŸ§  CNN Baseline (Real Ground Truth):\n",
            "  Accuracy:  0.6652\n",
            "  Precision: 0.1313\n",
            "  Recall:    0.1935\n",
            "  F1-Score:  0.1564\n",
            "ðŸ“Š CNN predicted: 6,198,343 cloud pixels (23.6%)\n",
            "\n",
            "ðŸ“Š Ground truth: 4,205,740 cloud pixels (16.0%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# Load and test CNN baseline on CloudSEN12 patches\n",
        "from cnn_inference import load_sentinel2_image, get_cloud_mask\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "print(\"ðŸ§  Evaluating CNN Baseline on CloudSEN12 Real Ground Truth\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load all processed CloudSEN12 patches\n",
        "image_files = sorted(glob.glob('data/cloudsen12_processed/*_image.tif'))\n",
        "mask_files = sorted(glob.glob('data/cloudsen12_processed/*_mask.tif'))\n",
        "\n",
        "all_gt = []\n",
        "all_cnn = []\n",
        "\n",
        "print(f\"Processing {len(image_files)} patches...\\n\")\n",
        "\n",
        "for img_path, mask_path in zip(image_files, mask_files):  # Use ALL patches\n",
        "    # Load image and get CNN prediction\n",
        "    image = load_sentinel2_image(img_path)\n",
        "    cnn_prob = get_cloud_mask(image)\n",
        "\n",
        "    # Load real ground truth\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        ground_truth = src.read(1)\n",
        "\n",
        "    # Binary conversion\n",
        "    gt_binary = (ground_truth > 0).astype(np.uint8)\n",
        "    cnn_binary = (cnn_prob > 0.5).astype(np.uint8)\n",
        "\n",
        "    all_gt.append(gt_binary.flatten())\n",
        "    all_cnn.append(cnn_binary.flatten())\n",
        "\n",
        "# Combine all patches\n",
        "all_gt = np.concatenate(all_gt)\n",
        "all_cnn = np.concatenate(all_cnn)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(all_gt, all_cnn)\n",
        "precision = precision_score(all_gt, all_cnn, zero_division=0)\n",
        "recall = recall_score(all_gt, all_cnn, zero_division=0)\n",
        "f1 = f1_score(all_gt, all_cnn, zero_division=0)\n",
        "\n",
        "print(f\"\\nðŸ“Š Evaluated on {len(image_files)} CloudSEN12 patches\")\n",
        "print(f\"ðŸ“Š Total pixels: {len(all_gt):,}\")\n",
        "print(\"\\nðŸ§  CNN Baseline (Real Ground Truth):\")\n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "\n",
        "print(f\"  F1-Score:  {f1:.4f}\")\n",
        "print(f\"ðŸ“Š CNN predicted: {all_cnn.sum():,} cloud pixels ({all_cnn.mean()*100:.1f}%)\")\n",
        "print(f\"\\nðŸ“Š Ground truth: {all_gt.sum():,} cloud pixels ({all_gt.mean()*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "088c8f8a",
      "metadata": {
        "id": "088c8f8a"
      },
      "source": [
        "## 4ï¸âƒ£ Pull Latest Code & Train PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6f2470c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f2470c4",
        "outputId": "c5be55fa-4043-4ebc-e302-0a8b869a492b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/Usernamenisiya/thesis-cloud-rl\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "âœ… Repository updated\n"
          ]
        }
      ],
      "source": [
        "# Get latest code with PPO improvements\n",
        "!git pull origin master\n",
        "print(\"âœ… Repository updated\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bc358b",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Comprehensive Approach: Three Methods\n",
        "\n",
        "We'll implement three approaches with progressive improvements:\n",
        "\n",
        "1. **Optimal Threshold (Classical)** - Grid search, 5 minutes\n",
        "2. **CNN Fine-Tuning (Transfer Learning)** - Domain adaptation, 30 minutes  \n",
        "3. **RL Threshold Refinement (Novel)** - Spatially-adaptive thresholds, 1 hour\n",
        "\n",
        "This provides:\n",
        "- âœ… Multiple baselines for comparison\n",
        "- âœ… Progressive improvement narrative\n",
        "- âœ… Novel RL contribution that actually improves results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dbf35e3",
      "metadata": {},
      "source": [
        "### ðŸ“Š Approach 1: Optimal Threshold (Grid Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c9a4d5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimal threshold grid search (fast, no training)\n",
        "print(\"ðŸ” Finding optimal CNN threshold via grid search...\")\n",
        "print(\"Testing thresholds from 0.1 to 0.9 on train set\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python optimize_threshold_grid_search.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91149fe",
      "metadata": {},
      "source": [
        "### ðŸ“Š Approach 2: Optimal Threshold Evaluated on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510d569d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate optimal threshold from train set on test set\n",
        "print(\"ðŸ“Š Evaluating optimal threshold on test set...\")\n",
        "print(\"Applying best threshold from training to held-out test data\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python finetune_cnn_cloudsen12.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d901a81",
      "metadata": {},
      "source": [
        "### ðŸŽ¯ Approach 3: RL Adaptive Threshold Refinement (Novel Contribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce9f239",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RL-based adaptive threshold refinement (1 hour)\n",
        "print(\"ðŸŽ¯ Training RL agent for spatially-adaptive thresholds...\")\n",
        "print(\"Agent learns to adjust CNN threshold per patch based on local context\")\n",
        "print(\"Action: continuous threshold delta [-0.3, +0.3]\")\n",
        "print(\"Reward: F1-score improvement over baseline\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python train_ppo_threshold_refinement.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e98a86",
      "metadata": {},
      "source": [
        "### ðŸ“Š Compare All Approaches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70858b4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all three approaches\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š COMPREHENSIVE COMPARISON - ALL APPROACHES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load baseline CNN (threshold=0.5)\n",
        "baseline_f1 = 0.2571  # From earlier evaluation\n",
        "baseline_acc = 0.6719\n",
        "\n",
        "print(\"\\nðŸ§  Baseline CNN (threshold=0.5):\")\n",
        "print(f\"  Accuracy:  {baseline_acc:.4f}\")\n",
        "print(f\"  F1-Score:  {baseline_f1:.4f}\")\n",
        "\n",
        "# Load optimal threshold results (TEST SET)\n",
        "if Path('results/optimal_threshold_test_results.json').exists():\n",
        "    with open('results/optimal_threshold_test_results.json') as f:\n",
        "        opt_results = json.load(f)\n",
        "    opt_threshold = opt_results['optimal_threshold']\n",
        "    opt_f1 = opt_results['test_optimal_metrics']['f1_score']\n",
        "    opt_acc = opt_results['test_optimal_metrics']['accuracy']\n",
        "    \n",
        "    print(f\"\\nðŸ“Š Approach 1: Optimal Threshold ({opt_threshold:.2f}):\")\n",
        "    print(f\"  Accuracy:  {opt_acc:.4f}\")\n",
        "    print(f\"  F1-Score:  {opt_f1:.4f}\")\n",
        "    print(f\"  Improvement: {(opt_f1 - baseline_f1) / baseline_f1 * 100:+.2f}%\")\n",
        "\n",
        "# Load RL threshold refinement results\n",
        "if Path('results/threshold_refinement_results.json').exists():\n",
        "    with open('results/threshold_refinement_results.json') as f:\n",
        "        rl_results = json.load(f)\n",
        "    rl_f1 = rl_results['rl_threshold_refinement']['f1_score']\n",
        "    rl_acc = rl_results['rl_threshold_refinement']['accuracy']\n",
        "    \n",
        "    print(f\"\\nðŸŽ¯ Approach 2: RL Adaptive Threshold:\")\n",
        "    print(f\"  Accuracy:  {rl_acc:.4f}\")\n",
        "    print(f\"  F1-Score:  {rl_f1:.4f}\")\n",
        "    print(f\"  Improvement: {(rl_f1 - baseline_f1) / baseline_f1 * 100:+.2f}%\")\n",
        "    \n",
        "    mean_delta = rl_results['threshold_statistics']['mean_delta']\n",
        "    print(f\"  Mean threshold adjustment: {mean_delta:+.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… All approaches evaluated!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0780f1ef",
      "metadata": {},
      "source": [
        "### ðŸ“¸ Visual Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6fab5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions from all three approaches on test patches\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from stable_baselines3 import PPO\n",
        "from cnn_inference import load_sentinel2_image, get_cloud_mask\n",
        "from rl_threshold_environment import ThresholdRefinementEnv\n",
        "\n",
        "# Load test patches\n",
        "data_dir = 'data/cloudsen12_processed'\n",
        "image_files = sorted(glob.glob(f'{data_dir}/*_image.tif'))\n",
        "mask_files = sorted(glob.glob(f'{data_dir}/*_mask.tif'))\n",
        "\n",
        "split_idx = int(0.8 * len(image_files))\n",
        "test_image_files = image_files[split_idx:]\n",
        "test_mask_files = mask_files[split_idx:]\n",
        "\n",
        "# Select 3 diverse test patches to visualize\n",
        "patch_indices = [0, 10, 19]  # First, middle, last\n",
        "\n",
        "# Load RL model\n",
        "model_path = sorted(glob.glob('models/ppo_threshold_refinement_*'))[-1]\n",
        "rl_model = PPO.load(model_path)\n",
        "print(f\"âœ… Loaded RL model: {Path(model_path).name}\")\n",
        "\n",
        "# Optimal threshold from results\n",
        "with open('results/optimal_threshold_test_results.json') as f:\n",
        "    opt_threshold = json.load(f)['optimal_threshold']\n",
        "\n",
        "print(f\"ðŸ“Š Comparing: Baseline (0.5) | Optimal ({opt_threshold:.2f}) | RL Adaptive\\n\")\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(len(patch_indices), 5, figsize=(20, 4*len(patch_indices)))\n",
        "\n",
        "for row, patch_idx in enumerate(patch_indices):\n",
        "    img_path = test_image_files[patch_idx]\n",
        "    mask_path = test_mask_files[patch_idx]\n",
        "    \n",
        "    # Load data\n",
        "    image = load_sentinel2_image(img_path)\n",
        "    cnn_prob = get_cloud_mask(image)\n",
        "    \n",
        "    with rasterio.open(mask_path) as src:\n",
        "        ground_truth = src.read(1)\n",
        "    \n",
        "    # Get predictions\n",
        "    baseline_pred = (cnn_prob > 0.5).astype(np.uint8)\n",
        "    optimal_pred = (cnn_prob > opt_threshold).astype(np.uint8)\n",
        "    \n",
        "    # RL adaptive prediction\n",
        "    env = ThresholdRefinementEnv(image, cnn_prob, ground_truth, patch_size=64, baseline_threshold=0.5)\n",
        "    rl_pred = np.zeros_like(ground_truth, dtype=np.uint8)\n",
        "    \n",
        "    obs, _ = env.reset()\n",
        "    for _ in range(env.num_patches):\n",
        "        i, j = env.current_pos\n",
        "        action, _ = rl_model.predict(obs, deterministic=True)\n",
        "        threshold_delta = np.clip(action[0], -0.3, 0.3)\n",
        "        adjusted_threshold = np.clip(0.5 + threshold_delta, 0.1, 0.9)\n",
        "        \n",
        "        cnn_patch = cnn_prob[i:i+64, j:j+64]\n",
        "        rl_pred[i:i+64, j:j+64] = (cnn_patch > adjusted_threshold).astype(np.uint8)\n",
        "        \n",
        "        obs, _, done, _, _ = env.step(action)\n",
        "        if done:\n",
        "            break\n",
        "    \n",
        "    # Ground truth\n",
        "    gt_binary = (ground_truth > 0).astype(np.uint8)\n",
        "    \n",
        "    # RGB visualization (bands 4,3,2 for true color)\n",
        "    rgb = image[:, :, [3, 2, 1]]  # B04, B03, B02\n",
        "    rgb = np.clip(rgb / 3000, 0, 1)  # Normalize\n",
        "    \n",
        "    # Plot\n",
        "    axes[row, 0].imshow(rgb)\n",
        "    axes[row, 0].set_title(f'Patch {patch_idx+1}\\nRGB Image')\n",
        "    axes[row, 0].axis('off')\n",
        "    \n",
        "    axes[row, 1].imshow(gt_binary, cmap='gray', vmin=0, vmax=1)\n",
        "    axes[row, 1].set_title('Ground Truth')\n",
        "    axes[row, 1].axis('off')\n",
        "    \n",
        "    axes[row, 2].imshow(baseline_pred, cmap='gray', vmin=0, vmax=1)\n",
        "    axes[row, 2].set_title(f'Baseline (0.5)\\nF1: {f1_score(gt_binary.flatten(), baseline_pred.flatten()):.3f}')\n",
        "    axes[row, 2].axis('off')\n",
        "    \n",
        "    axes[row, 3].imshow(optimal_pred, cmap='gray', vmin=0, vmax=1)\n",
        "    axes[row, 3].set_title(f'Optimal ({opt_threshold:.2f})\\nF1: {f1_score(gt_binary.flatten(), optimal_pred.flatten()):.3f}')\n",
        "    axes[row, 3].axis('off')\n",
        "    \n",
        "    axes[row, 4].imshow(rl_pred, cmap='gray', vmin=0, vmax=1)\n",
        "    axes[row, 4].set_title(f'RL Adaptive\\nF1: {f1_score(gt_binary.flatten(), rl_pred.flatten()):.3f}')\n",
        "    axes[row, 4].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/comparison_visualization.png', dpi=150, bbox_inches='tight')\n",
        "print(f\"\\nðŸ’¾ Visualization saved to: results/comparison_visualization.png\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
