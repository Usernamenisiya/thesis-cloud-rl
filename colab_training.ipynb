{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30e39e0",
   "metadata": {},
   "source": [
    "## üìã Prerequisites\n",
    "\n",
    "Before running this notebook:\n",
    "\n",
    "1. **GitHub Repository**: Push your local code to GitHub\n",
    "2. **Data Files**: Ensure `data/sentinel2_image.tif` and `data/ground_truth.tif` exist\n",
    "3. **GPU Runtime**: This notebook requires GPU acceleration\n",
    "\n",
    "**Estimated Training Time**: 2-4 hours with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72ea1f",
   "metadata": {},
   "source": [
    "## üöÄ Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your GitHub repository\n",
    "# Replace 'yourusername/your-repo-name' with your actual GitHub repo\n",
    "!git clone https://github.com/Usernamenisiya/thesis-cloud-rl.git\n",
    "%cd thesis-cloud-rl\n",
    "\n",
    "# Verify we're in the right directory\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b96ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies\n",
    "!pip install -r requirements.txt\n",
    "!pip install zarr scipy  # Additional dependencies for data processing\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "import stable_baselines3\n",
    "import rasterio\n",
    "import zarr\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d18a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Training will be slow on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcadd960",
   "metadata": {},
   "source": [
    "## üìä Step 2: Data Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc8688",
   "metadata": {},
   "source": [
    "## üìÅ Step 1.5: Data Storage Setup\n",
    "\n",
    "**Choose your preferred data storage method:**\n",
    "\n",
    "### Option 1: Google Drive (Recommended - Persistent Storage)\n",
    "Store your data files in Google Drive for persistent access across Colab sessions.\n",
    "\n",
    "1. **Create a folder** in your Google Drive called `Colab_Data/thesis_cloud_rl/`\n",
    "2. **Upload your data files** to this folder:\n",
    "   - `sentinel2_image.tif`\n",
    "   - `ground_truth.tif`\n",
    "3. **Run the cell below** to mount Google Drive and create symlinks\n",
    "\n",
    "**Benefits:** No need to re-upload files every session!\n",
    "\n",
    "### Option 2: Upload via Colab File Browser\n",
    "1. Click the **folder icon** on the left sidebar in Colab\n",
    "2. Navigate to `thesis-cloud-rl/data/` (create the folder if needed)\n",
    "3. Click the **upload button** (up arrow icon)\n",
    "4. Select and upload:\n",
    "   - `sentinel2_image.tif`\n",
    "   - `ground_truth.tif`\n",
    "5. Wait for uploads to complete\n",
    "\n",
    "### Option 3: Upload via Code (Alternative)\n",
    "Run this cell to upload files programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent data storage\n",
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define paths\n",
    "drive_data_dir = Path('/content/drive/MyDrive/Colab_Data/thesis_cloud_rl')\n",
    "local_data_dir = Path('data')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "drive_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "local_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Debug: List contents of Google Drive root\n",
    "print(\"üîç Checking Google Drive structure...\")\n",
    "drive_root = Path('/content/drive/MyDrive')\n",
    "if drive_root.exists():\n",
    "    print(\"Google Drive contents:\")\n",
    "    try:\n",
    "        items = list(drive_root.iterdir())\n",
    "        for item in items[:10]:  # Show first 10 items\n",
    "            print(f\"  {item.name}/\" if item.is_dir() else f\"  {item.name}\")\n",
    "        if len(items) > 10:\n",
    "            print(f\"  ... and {len(items) - 10} more items\")\n",
    "    except:\n",
    "        print(\"  Unable to list contents (permission issue?)\")\n",
    "else:\n",
    "    print(\"  Google Drive not accessible\")\n",
    "\n",
    "# Check Colab_Data directory\n",
    "colab_data_dir = Path('/content/drive/MyDrive/Colab_Data')\n",
    "if colab_data_dir.exists():\n",
    "    print(f\"\\n‚úÖ Found Colab_Data directory\")\n",
    "    try:\n",
    "        items = list(colab_data_dir.iterdir())\n",
    "        print(\"Colab_Data contents:\")\n",
    "        for item in items:\n",
    "            print(f\"  {item.name}/\" if item.is_dir() else f\"  {item.name}\")\n",
    "    except:\n",
    "        print(\"  Unable to list Colab_Data contents\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Colab_Data directory not found at {colab_data_dir}\")\n",
    "    print(\"Creating it...\")\n",
    "    colab_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check for existing data files in Google Drive\n",
    "sentinel_file = drive_data_dir / 'sentinel2_image.tif'\n",
    "ground_truth_file = drive_data_dir / 'ground_truth.tif'\n",
    "\n",
    "print(f\"\\nüîç Checking for data files in {drive_data_dir}...\")\n",
    "print(f\"  Sentinel-2 file: {'‚úÖ Found' if sentinel_file.exists() else '‚ùå Not found'}\")\n",
    "print(f\"  Ground truth file: {'‚úÖ Found' if ground_truth_file.exists() else '‚ùå Not found'}\")\n",
    "\n",
    "if sentinel_file.exists() and ground_truth_file.exists():\n",
    "    print('\\n‚úÖ Found data files in Google Drive!')\n",
    "    print('Creating symlinks for easy access...')\n",
    "    \n",
    "    # Create symlinks\n",
    "    os.symlink(str(sentinel_file), str(local_data_dir / 'sentinel2_image.tif'))\n",
    "    os.symlink(str(ground_truth_file), str(local_data_dir / 'ground_truth.tif'))\n",
    "    \n",
    "    print('‚úÖ Symlinks created! Data files are now accessible.')\n",
    "    print(f'Sentinel-2 image: {local_data_dir / \"sentinel2_image.tif\"}')\n",
    "    print(f'Ground truth: {local_data_dir / \"ground_truth.tif\"}')\n",
    "    \n",
    "else:\n",
    "    print('\\nüìÅ Data files not found in Google Drive.')\n",
    "    print('Please follow these steps:')\n",
    "    print('1. Open Google Drive in a new tab: https://drive.google.com')\n",
    "    print('2. Create folder: Colab_Data/thesis_cloud_rl')\n",
    "    print('3. Upload your files:')\n",
    "    print('   - sentinel2_image.tif')\n",
    "    print('   - ground_truth.tif')\n",
    "    print(f'4. Files should be at: {drive_data_dir}')\n",
    "    print('\\nAfter uploading, re-run this cell.')\n",
    "    \n",
    "    # Alternative: Check if files are elsewhere\n",
    "    print('\\nüîç Searching for .tif files in Google Drive...')\n",
    "    tif_files = []\n",
    "    try:\n",
    "        for root, dirs, files in os.walk('/content/drive/MyDrive'):\n",
    "            for file in files:\n",
    "                if file.endswith('.tif') or file.endswith('.tiff'):\n",
    "                    rel_path = os.path.relpath(root, '/content/drive/MyDrive')\n",
    "                    tif_files.append(f\"{rel_path}/{file}\")\n",
    "                    if len(tif_files) >= 5:  # Limit results\n",
    "                        break\n",
    "            if len(tif_files) >= 5:\n",
    "                break\n",
    "        \n",
    "        if tif_files:\n",
    "            print(\"Found .tif files:\")\n",
    "            for tif in tif_files:\n",
    "                print(f\"  {tif}\")\n",
    "            print(\"\\nIf your files are in a different location, you can move them or update the path in this cell.\")\n",
    "        else:\n",
    "            print(\"No .tif files found in Google Drive.\")\n",
    "    except:\n",
    "        print(\"Unable to search for files (permission issue?)\")\n",
    "\n",
    "    print('\\nüîç Searching for .tif files in Google Drive...')\n",
    "    tif_files = []\n",
    "    try:\n",
    "        for root, dirs, files in os.walk('/content/drive/MyDrive'):\n",
    "            for file in files:\n",
    "                if file.endswith('.tif') or file.endswith('.tiff'):\n",
    "                    rel_path = os.path.relpath(root, '/content/drive/MyDrive')\n",
    "                    tif_files.append(f\"{rel_path}/{file}\")\n",
    "                    if len(tif_files) >= 5:  # Limit results\n",
    "                        break\n",
    "            if len(tif_files) >= 5:\n",
    "                break\n",
    "        \n",
    "        if tif_files:\n",
    "            print(\"Found .tif files:\")\n",
    "            for tif in tif_files:\n",
    "                print(f\"  {tif}\")\n",
    "            print(\"\\nIf your files are in a different location, you can move them or update the path in this cell.\")\n",
    "        else:\n",
    "            print(\"No .tif files found in Google Drive.\")\n",
    "    except:\n",
    "        print(\"Unable to search for files (permission issue?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b7e866",
   "metadata": {},
   "source": [
    "### üîß Manual Path Setup (If Files Are Elsewhere)\n",
    "\n",
    "If your files are in a different location in Google Drive, run this cell to manually specify the paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61fe5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual path setup for data files\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# If your files are in a different location, update these paths\n",
    "# Example: If you uploaded to \"My Drive/Data/\" instead of \"Colab_Data/thesis_cloud_rl/\"\n",
    "\n",
    "# CUSTOMIZE THESE PATHS IF NEEDED:\n",
    "sentinel_drive_path = \"/content/drive/MyDrive/Colab_Data/thesis_cloud_rl/sentinel2_image.tif\"  # Default location\n",
    "ground_truth_drive_path = \"/content/drive/MyDrive/Colab_Data/thesis_cloud_rl/ground_truth.tif\"  # Default location\n",
    "\n",
    "# Alternative common locations (uncomment and modify if needed):\n",
    "# sentinel_drive_path = \"/content/drive/MyDrive/Data/sentinel2_image.tif\"\n",
    "# ground_truth_drive_path = \"/content/drive/MyDrive/Data/ground_truth.tif\"\n",
    "# sentinel_drive_path = \"/content/drive/MyDrive/sentinel2_image.tif\"\n",
    "# ground_truth_drive_path = \"/content/drive/MyDrive/ground_truth.tif\"\n",
    "\n",
    "print(\"üîß Manual Data Path Setup\")\n",
    "print(\"Current paths:\")\n",
    "print(f\"  Sentinel-2: {sentinel_drive_path}\")\n",
    "print(f\"  Ground truth: {ground_truth_drive_path}\")\n",
    "\n",
    "# Check if files exist at specified paths\n",
    "sentinel_exists = Path(sentinel_drive_path).exists()\n",
    "ground_truth_exists = Path(ground_truth_drive_path).exists()\n",
    "\n",
    "print(f\"\\nFile status:\")\n",
    "print(f\"  Sentinel-2: {'‚úÖ Found' if sentinel_exists else '‚ùå Not found'}\")\n",
    "print(f\"  Ground truth: {'‚úÖ Found' if ground_truth_exists else '‚ùå Not found'}\")\n",
    "\n",
    "if sentinel_exists and ground_truth_exists:\n",
    "    print(\"\\n‚úÖ Both files found! Creating symlinks...\")\n",
    "    \n",
    "    local_data_dir = Path('data')\n",
    "    local_data_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create symlinks\n",
    "    os.symlink(sentinel_drive_path, str(local_data_dir / 'sentinel2_image.tif'))\n",
    "    os.symlink(ground_truth_drive_path, str(local_data_dir / 'ground_truth.tif'))\n",
    "    \n",
    "    print(\"‚úÖ Symlinks created successfully!\")\n",
    "    print(\"You can now proceed to data verification.\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå Files not found at specified paths.\")\n",
    "    print(\"Please:\")\n",
    "    print(\"1. Check the file paths above\")\n",
    "    print(\"2. Update the paths in this cell if needed\")\n",
    "    print(\"3. Or use the automatic upload options below\")\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-17eec971\" language=\"markdown\">\n",
    "## üîç Step 1.6: Data Verification\n",
    "\n",
    "Verify that your data files are properly loaded and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files are accessible\n",
    "import os\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "\n",
    "data_dir = Path('data')\n",
    "sentinel_path = data_dir / 'sentinel2_image.tif'\n",
    "ground_truth_path = data_dir / 'ground_truth.tif'\n",
    "\n",
    "print('üîç Checking data files...')\n",
    "\n",
    "# Check if files exist\n",
    "sentinel_exists = sentinel_path.exists()\n",
    "ground_truth_exists = ground_truth_path.exists()\n",
    "\n",
    "print(f'Sentinel-2 image: {\"‚úÖ Found\" if sentinel_exists else \"‚ùå Missing\"} at {sentinel_path}')\n",
    "print(f'Ground truth: {\"‚úÖ Found\" if ground_truth_exists else \"‚ùå Missing\"} at {ground_truth_path}')\n",
    "\n",
    "if sentinel_exists and ground_truth_exists:\n",
    "    try:\n",
    "        # Verify file integrity\n",
    "        with rasterio.open(sentinel_path) as src:\n",
    "            sentinel_shape = src.shape\n",
    "            sentinel_bands = src.count\n",
    "            print(f'‚úÖ Sentinel-2: {sentinel_shape} pixels, {sentinel_bands} bands')\n",
    "        \n",
    "        with rasterio.open(ground_truth_path) as src:\n",
    "            gt_shape = src.shape\n",
    "            print(f'‚úÖ Ground truth: {gt_shape} pixels')\n",
    "            \n",
    "        if sentinel_shape[:2] == gt_shape:\n",
    "            print('‚úÖ Shapes match! Data is ready for training.')\n",
    "        else:\n",
    "            print(f'‚ö†Ô∏è  Shape mismatch: Sentinel-2 {sentinel_shape[:2]} vs Ground truth {gt_shape}')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error reading files: {e}')\n",
    "        \n",
    "else:\n",
    "    print('\\nüìã To set up your data:')\n",
    "    print('1. Use Google Drive option above (recommended)')\n",
    "    print('2. Or upload files using the cells below')\n",
    "    print('3. Re-run this verification cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83753811",
   "metadata": {},
   "source": [
    "### üí° Advanced Data Options\n",
    "\n",
    "**For even more convenience, consider these options:**\n",
    "\n",
    "#### Option A: Cloud Storage URLs\n",
    "If you have your data hosted on cloud storage (Dropbox, OneDrive, etc.), you can download them automatically:\n",
    "\n",
    "```python\n",
    "# Example for Dropbox direct download\n",
    "# !wget -O data/sentinel2_image.tif \"YOUR_DROPBOX_LINK\"\n",
    "# !wget -O data/ground_truth.tif \"YOUR_DROPBOX_LINK\"\n",
    "```\n",
    "\n",
    "#### Option B: Automatic Dataset Download\n",
    "For reproducible research, you could modify `data_download.py` to download from public datasets.\n",
    "\n",
    "#### Option C: Persistent Colab Storage\n",
    "Colab Pro users can use persistent storage, but Google Drive is more reliable for large files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data files programmatically (fallback option)\n",
    "from google.colab import files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Upload your data files:\")\n",
    "print(\"- sentinel2_image.tif\")\n",
    "print(\"- ground_truth.tif\")\n",
    "print(\"\\nClick 'Choose Files' and select both files...\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded files to data directory\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith(('.tif', '.tiff')):\n",
    "        os.rename(filename, f\"data/{filename}\")\n",
    "        print(f\"‚úÖ Moved {filename} to data/\")\n",
    "\n",
    "print(\"\\n‚úÖ Upload complete! You can now proceed to Step 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files exist\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "required_files = [\n",
    "    \"sentinel2_image.tif\",\n",
    "    \"ground_truth.tif\"\n",
    "]\n",
    "\n",
    "print(\"Checking data files...\")\n",
    "for file in required_files:\n",
    "    file_path = data_dir / file\n",
    "    if file_path.exists():\n",
    "        size = file_path.stat().st_size / (1024*1024)  # MB\n",
    "        print(f\"‚úÖ {file}: {size:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file}: MISSING\")\n",
    "\n",
    "# Verify data integrity\n",
    "if all((data_dir / f).exists() for f in required_files):\n",
    "    print(\"\\n‚úÖ All data files present!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Some data files missing. Please upload them to the data/ directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data inspection\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "print(\"Inspecting Sentinel-2 data...\")\n",
    "\n",
    "with rasterio.open('data/sentinel2_image.tif') as src:\n",
    "    print(f\"Image shape: {src.shape}\")\n",
    "    print(f\"Number of bands: {src.count}\")\n",
    "    print(f\"CRS: {src.crs}\")\n",
    "    print(f\"Bounds: {src.bounds}\")\n",
    "\n",
    "print(\"\\nInspecting ground truth...\")\n",
    "\n",
    "with rasterio.open('data/ground_truth.tif') as src:\n",
    "    print(f\"Ground truth shape: {src.shape}\")\n",
    "    print(f\"Ground truth bands: {src.count}\")\n",
    "\n",
    "    # Show class distribution\n",
    "    gt_data = src.read(1)\n",
    "    unique, counts = np.unique(gt_data, return_counts=True)\n",
    "    total_pixels = gt_data.size\n",
    "\n",
    "    print(\"\\nGround truth class distribution:\")\n",
    "    class_names = {0: \"Clear\", 1: \"Thick Cloud\", 2: \"Thin Cloud\", 3: \"Cloud Shadow\"}\n",
    "    for cls, count in zip(unique, counts):\n",
    "        percentage = (count / total_pixels) * 100\n",
    "        name = class_names.get(cls, f\"Class {cls}\")\n",
    "        print(f\"  {name}: {count:,} pixels ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b4e12",
   "metadata": {},
   "source": [
    "## üß† Step 3: CNN Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CNN inference and get baseline performance\n",
    "print(\"Testing s2cloudless CNN performance...\")\n",
    "\n",
    "# Import our modules\n",
    "from cnn_inference import load_sentinel2_image, get_cloud_mask\n",
    "from rl_environment import CloudMaskRefinementEnv\n",
    "import rasterio\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load data\n",
    "image = load_sentinel2_image('data/sentinel2_image.tif')\n",
    "cnn_prob = get_cloud_mask(image)\n",
    "\n",
    "# Load ground truth and convert to binary\n",
    "with rasterio.open('data/ground_truth.tif') as src:\n",
    "    ground_truth = src.read(1)\n",
    "\n",
    "# Convert to binary (cloud vs no-cloud)\n",
    "gt_binary = (ground_truth > 0).astype(np.uint8)\n",
    "cnn_binary = (cnn_prob > 0.5).astype(np.uint8)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(gt_binary.flatten(), cnn_binary.flatten())\n",
    "precision = precision_score(gt_binary.flatten(), cnn_binary.flatten(), zero_division=0)\n",
    "recall = recall_score(gt_binary.flatten(), cnn_binary.flatten(), zero_division=0)\n",
    "f1 = f1_score(gt_binary.flatten(), cnn_binary.flatten(), zero_division=0)\n",
    "\n",
    "print(\"üéØ CNN Baseline Performance:\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Ground truth clouds: {gt_binary.sum():,} pixels\")\n",
    "print(f\"üìä CNN predicted clouds: {cnn_binary.sum():,} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CNN results (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Show RGB image (bands 4,3,2 for true color)\n",
    "rgb_image = image[:, :, [3, 2, 1]]  # B04, B03, B02\n",
    "rgb_image = np.clip(rgb_image / 3000, 0, 1)  # Normalize for display\n",
    "\n",
    "axes[0].imshow(rgb_image)\n",
    "axes[0].set_title('Sentinel-2 RGB Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(ground_truth, cmap='viridis')\n",
    "axes[1].set_title('Ground Truth Labels')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cnn_binary, cmap='gray')\n",
    "axes[2].set_title('CNN Cloud Mask')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° The CNN baseline shows room for improvement, especially for thin clouds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19679587",
   "metadata": {},
   "source": [
    "## ü§ñ Step 4: RL Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RL environment before training\n",
    "print(\"Testing RL environment...\")\n",
    "\n",
    "env = CloudMaskRefinementEnv(image, cnn_prob, ground_truth, patch_size=64)\n",
    "\n",
    "# Test a few steps\n",
    "obs = env.reset()\n",
    "print(f\"Observation shape: {obs.shape}\")\n",
    "\n",
    "for i in range(5):\n",
    "    action = env.action_space.sample()  # Random action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"Step {i+1}: Action={action}, Reward={reward:.3f}, Done={done}\")\n",
    "\n",
    "print(\"‚úÖ RL environment working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7091fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training parameters\n",
    "TRAINING_CONFIG = {\n",
    "    \"total_timesteps\": 50000,  # Adjust based on time/compute\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 64,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_starts\": 1000,\n",
    "    \"target_update_interval\": 1000,\n",
    "    \"train_freq\": (4, \"step\"),  # Train every 4 steps\n",
    "    \"gradient_steps\": 1,\n",
    "    \"exploration_fraction\": 0.1,\n",
    "    \"exploration_final_eps\": 0.01,\n",
    "}\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c54488",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Start RL Training\n",
    "\n",
    "**This is the main training phase. It will take 1-2 hours with GPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f667cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install shimmy for RL compatibility (required for stable-baselines3)\n",
    "!pip install 'shimmy>=2.0'\n",
    "\n",
    "print(\"‚úÖ Shimmy installed for RL environment compatibility!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d208a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training modules\n",
    "import gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import time\n",
    "\n",
    "class TrainingProgressCallback(BaseCallback):\n",
    "    def __init__(self, check_freq=1000, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            elapsed = time.time() - self.start_time\n",
    "            print(f\"Step {self.n_calls}: {elapsed:.1f}s elapsed, Reward: {self.locals['rewards'][-1]:.3f}\")\n",
    "        return True\n",
    "\n",
    "# Create environment\n",
    "print(\"Creating RL environment...\")\n",
    "env = CloudMaskRefinementEnv(image, cnn_prob, ground_truth, patch_size=64)\n",
    "\n",
    "# Create DQN model\n",
    "print(\"Creating DQN model...\")\n",
    "model = DQN(\n",
    "    'CnnPolicy',  # Convolutional policy for image inputs\n",
    "    env,\n",
    "    learning_rate=TRAINING_CONFIG[\"learning_rate\"],\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    buffer_size=TRAINING_CONFIG[\"buffer_size\"],\n",
    "    learning_starts=TRAINING_CONFIG[\"learning_starts\"],\n",
    "    target_update_interval=TRAINING_CONFIG[\"target_update_interval\"],\n",
    "    train_freq=TRAINING_CONFIG[\"train_freq\"],\n",
    "    gradient_steps=TRAINING_CONFIG[\"gradient_steps\"],\n",
    "    exploration_fraction=TRAINING_CONFIG[\"exploration_fraction\"],\n",
    "    exploration_final_eps=TRAINING_CONFIG[\"exploration_final_eps\"],\n",
    "    verbose=1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting RL training...\")\n",
    "print(f\"Training for {TRAINING_CONFIG['total_timesteps']:,} timesteps\")\n",
    "print(\"This will take approximately 30-60 minutes with GPU...\")\n",
    "\n",
    "# Train the model\n",
    "callback = TrainingProgressCallback(check_freq=5000)\n",
    "model.learn(\n",
    "    total_timesteps=TRAINING_CONFIG[\"total_timesteps\"],\n",
    "    callback=callback\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec0d45",
   "metadata": {},
   "source": [
    "## üìà Step 6: Evaluate RL Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model\n",
    "print(\"Evaluating trained RL agent...\")\n",
    "\n",
    "# Create evaluation environment\n",
    "eval_env = CloudMaskRefinementEnv(image, cnn_prob, ground_truth, patch_size=64)\n",
    "\n",
    "# Collect predictions from trained agent\n",
    "rl_predictions = np.zeros_like(ground_truth, dtype=np.uint8)\n",
    "\n",
    "# Reset environment\n",
    "obs = eval_env.reset()\n",
    "done = False\n",
    "step_count = 0\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = eval_env.step(action)\n",
    "\n",
    "    # Store prediction\n",
    "    if 'patch_position' in info:\n",
    "        row, col = info['patch_position']\n",
    "        patch_size = eval_env.patch_size\n",
    "        rl_predictions[row:row+patch_size, col:col+patch_size] = action\n",
    "\n",
    "    step_count += 1\n",
    "    if step_count % 10000 == 0:\n",
    "        print(f\"Evaluation step: {step_count}\")\n",
    "\n",
    "print(f\"Evaluation completed in {step_count} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CNN vs RL performance\n",
    "print(\"Comparing CNN baseline vs RL-refined results...\")\n",
    "\n",
    "# Calculate RL metrics\n",
    "rl_binary = (rl_predictions > 0).astype(np.uint8)\n",
    "rl_accuracy = accuracy_score(gt_binary.flatten(), rl_binary.flatten())\n",
    "rl_precision = precision_score(gt_binary.flatten(), rl_binary.flatten(), zero_division=0)\n",
    "rl_recall = recall_score(gt_binary.flatten(), rl_binary.flatten(), zero_division=0)\n",
    "rl_f1 = f1_score(gt_binary.flatten(), rl_binary.flatten(), zero_division=0)\n",
    "\n",
    "print(\"üìä Performance Comparison:\")\n",
    "print(\"CNN Baseline:\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nRL Refined:\")\n",
    "print(f\"  Accuracy: {rl_accuracy:.4f}\")\n",
    "print(f\"  Precision: {rl_precision:.4f}\")\n",
    "print(f\"  Recall: {rl_recall:.4f}\")\n",
    "print(f\"  F1-Score: {rl_f1:.4f}\")\n",
    "\n",
    "improvement = ((rl_f1 - f1) / f1) * 100\n",
    "print(f\"\\nüéØ F1-Score Improvement: {improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Row 1: CNN results\n",
    "axes[0,0].imshow(rgb_image)\n",
    "axes[0,0].set_title('Sentinel-2 RGB')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(ground_truth, cmap='viridis')\n",
    "axes[0,1].set_title('Ground Truth')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(cnn_binary, cmap='gray')\n",
    "axes[0,2].set_title(f'CNN Mask\\nF1: {f1:.3f}')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "# Row 2: RL results\n",
    "axes[1,0].imshow(rgb_image)\n",
    "axes[1,0].set_title('Sentinel-2 RGB')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(ground_truth, cmap='viridis')\n",
    "axes[1,1].set_title('Ground Truth')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(rl_binary, cmap='gray')\n",
    "axes[1,2].set_title(f'RL Refined Mask\\nF1: {rl_f1:.3f}')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéâ Training and evaluation complete!\")\n",
    "print(\"üíæ Don't forget to save your trained model:\")\n",
    "print(\"model.save('rl_cloud_refinement_model')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb34abe",
   "metadata": {},
   "source": [
    "## üíæ Step 7: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = \"rl_cloud_refinement_model\"\n",
    "model.save(model_path)\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "\n",
    "# Save performance metrics\n",
    "import json\n",
    "metrics = {\n",
    "    \"cnn_baseline\": {\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1)\n",
    "    },\n",
    "    \"rl_refined\": {\n",
    "        \"accuracy\": float(rl_accuracy),\n",
    "        \"precision\": float(rl_precision),\n",
    "        \"recall\": float(rl_recall),\n",
    "        \"f1_score\": float(rl_f1)\n",
    "    },\n",
    "    \"improvement\": {\n",
    "        \"f1_improvement_percent\": float(improvement)\n",
    "    },\n",
    "    \"training_config\": TRAINING_CONFIG,\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "with open(\"training_results.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Results saved to: training_results.json\")\n",
    "\n",
    "# Optional: Save refined cloud mask\n",
    "refined_mask_path = \"data/rl_refined_cloud_mask.tif\"\n",
    "with rasterio.open('data/ground_truth.tif') as src:\n",
    "    profile = src.profile.copy()\n",
    "    profile.update(count=1, dtype='uint8')\n",
    "\n",
    "    with rasterio.open(refined_mask_path, 'w', **profile) as dst:\n",
    "        dst.write(rl_binary, 1)\n",
    "\n",
    "print(f\"‚úÖ Refined cloud mask saved to: {refined_mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8d22a",
   "metadata": {},
   "source": [
    "## üéì Thesis Summary\n",
    "\n",
    "**Congratulations!** You have successfully:\n",
    "\n",
    "1. ‚úÖ **Set up RL pipeline** for cloud mask refinement\n",
    "2. ‚úÖ **Established CNN baseline** (~42% accuracy)\n",
    "3. ‚úÖ **Trained RL agent** to improve cloud detection\n",
    "4. ‚úÖ **Evaluated performance** and quantified improvements\n",
    "5. ‚úÖ **Saved results** for your thesis\n",
    "\n",
    "### Key Findings:\n",
    "- **CNN Baseline**: F1-score of {f1:.3f}\n",
    "- **RL Improvement**: {improvement:+.2f}% F1-score improvement\n",
    "- **Focus**: Enhanced thin cloud detection\n",
    "\n",
    "### Next Steps for Thesis:\n",
    "1. **Experiment with different RL algorithms** (PPO, SAC)\n",
    "2. **Tune hyperparameters** for better performance\n",
    "3. **Test on real CloudSEN12 ground truth**\n",
    "4. **Compare with other refinement methods**\n",
    "\n",
    "**Your RL approach shows promise for improving cloud mask accuracy!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
