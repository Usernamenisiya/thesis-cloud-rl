{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe41eb39",
      "metadata": {
        "id": "fe41eb39"
      },
      "source": [
        "## 1Ô∏è‚É£ Clone & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fe28e572",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe28e572",
        "outputId": "a66d68bb-c6d2-4319-fecd-1eed63998002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'thesis-cloud-rl'...\n",
            "remote: Enumerating objects: 1684, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 1684 (delta 69), reused 73 (delta 31), pack-reused 1572 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1684/1684), 653.95 MiB | 16.13 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n",
            "Updating files: 100% (2624/2624), done.\n",
            "/content/thesis-cloud-rl\n",
            "/content/thesis-cloud-rl\n",
            "total 39828\n",
            "drwxr-xr-x 4 root root     4096 Jan 12 05:30 .\n",
            "drwxr-xr-x 1 root root     4096 Jan 12 05:29 ..\n",
            "-rw-r--r-- 1 root root     1661 Jan 12 05:30 cnn_inference.py\n",
            "-rw-r--r-- 1 root root    10073 Jan 12 05:30 colab_training.ipynb\n",
            "drwxr-xr-x 3 root root     4096 Jan 12 05:30 data\n",
            "-rw-r--r-- 1 root root     4697 Jan 12 05:30 data_download.py\n",
            "-rw-r--r-- 1 root root     4735 Jan 12 05:30 evaluate_rl_model.py\n",
            "drwxr-xr-x 8 root root     4096 Jan 12 05:30 .git\n",
            "-rw-r--r-- 1 root root      375 Jan 12 05:30 .gitignore\n",
            "-rw-r--r-- 1 root root     2167 Jan 12 05:30 README.md\n",
            "-rw-r--r-- 1 root root      136 Jan 12 05:30 requirements.txt\n",
            "-rw-r--r-- 1 root root 28305032 Jan 12 05:30 rl_cloud_refinement_model.zip\n",
            "-rw-r--r-- 1 root root     4258 Jan 12 05:30 rl_environment.py\n",
            "-rw-r--r-- 1 root root     4252 Jan 12 05:30 rl_environment_v2.py\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/Usernamenisiya/thesis-cloud-rl.git\n",
        "%cd thesis-cloud-rl\n",
        "\n",
        "# Verify\n",
        "!pwd\n",
        "!ls -la | head -15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "690b0055",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "690b0055",
        "outputId": "1f3458ce-f3cd-4bf6-8175-be8831d478ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.24.0+cu126)\n",
            "Collecting s2cloudless (from -r requirements.txt (line 3))\n",
            "  Downloading s2cloudless-1.7.3-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting stable-baselines3 (from -r requirements.txt (line 4))\n",
            "  Downloading stable_baselines3-2.7.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.4.4)\n",
            "Collecting zarr (from -r requirements.txt (line 11))\n",
            "  Downloading zarr-3.1.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting shimmy>=2.0 (from -r requirements.txt (line 12))\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.15.0->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: lightgbm>=2.0.11 in /usr/local/lib/python3.12/dist-packages (from s2cloudless->-r requirements.txt (line 3)) (4.6.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from s2cloudless->-r requirements.txt (line 3)) (4.12.0.88)\n",
            "Collecting sentinelhub>=3.9.0 (from s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading sentinelhub-3.11.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3->-r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym->-r requirements.txt (line 5)) (0.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (2025.11.12)\n",
            "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio->-r requirements.txt (line 10)) (1.1.1.2)\n",
            "Collecting donfig>=0.8 (from zarr->-r requirements.txt (line 11))\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: google-crc32c>=1.5 in /usr/local/lib/python3.12/dist-packages (from zarr->-r requirements.txt (line 11)) (1.7.1)\n",
            "Collecting numcodecs>=0.14 (from zarr->-r requirements.txt (line 11))\n",
            "  Downloading numcodecs-0.16.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr->-r requirements.txt (line 11)) (6.0.3)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3->-r requirements.txt (line 4)) (0.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 8)) (1.17.0)\n",
            "Collecting aenum>=2.1.4 (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dataclasses-json (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.3.1)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.1.2)\n",
            "Requirement already satisfied: tifffile>=2020.9.30 in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2025.12.12)\n",
            "Collecting tomli (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading tomli-2.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting tomli-w (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (4.67.1)\n",
            "Collecting utm (from sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading utm-0.8.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3->-r requirements.txt (line 4)) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3)) (2.5.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->sentinelhub>=3.9.0->s2cloudless->-r requirements.txt (line 3))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading s2cloudless-1.7.3-py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.7.1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zarr-3.1.5-py3-none-any.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m284.1/284.1 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Downloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading numcodecs-0.16.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (9.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m160.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentinelhub-3.11.3-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading tomli-2.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading utm-0.8.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: aenum, utm, tomli-w, tomli, numcodecs, mypy-extensions, marshmallow, donfig, zarr, typing-inspect, shimmy, dataclasses-json, stable-baselines3, sentinelhub, s2cloudless\n",
            "Successfully installed aenum-3.1.16 dataclasses-json-0.6.7 donfig-0.8.1.post1 marshmallow-3.26.2 mypy-extensions-1.1.0 numcodecs-0.16.5 s2cloudless-1.7.3 sentinelhub-3.11.3 shimmy-2.0.0 stable-baselines3-2.7.1 tomli-2.4.0 tomli-w-1.2.0 typing-inspect-0.9.0 utm-0.8.1 zarr-3.1.5\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dependencies installed\n",
            "PyTorch: 2.9.0+cu126\n",
            "CUDA available: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install gymnasium  # Updated from deprecated gym\n",
        "\n",
        "import torch\n",
        "import stable_baselines3\n",
        "import rasterio\n",
        "\n",
        "print(\"‚úÖ Dependencies installed\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ced755bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ced755bc",
        "outputId": "f2bdba9c-75a6-41f8-d8b9-db77350fd94e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Jan 12 05:30:46 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0             45W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "‚úÖ Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\n‚úÖ Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2974c679",
      "metadata": {
        "id": "2974c679"
      },
      "source": [
        "## 2Ô∏è‚É£ Setup CloudSEN12 Real Ground Truth Data\n",
        "\n",
        "**Using CloudSEN12 expert-labeled dataset:**\n",
        "- Already downloaded: 100 patches in `Colab_Data/cloudsen12_subset/`\n",
        "- Process with `cloudsen12_loader.py` to extract 10 bands\n",
        "- **26M pixels** for robust evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c8ad7c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c8ad7c8",
        "outputId": "5b7e44d7-88d0-469f-cf5c-726b0cd0d1cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Files copied from Google Drive\n",
            "total 604M\n",
            "drwxr-xr-x 3 root root 4.0K Jan 12 05:30 data\n",
            "-rw------- 1 root root  29M Jan 12 05:31 ground_truth.tif\n",
            "-rw------- 1 root root 575M Jan 12 05:31 sentinel2_image.tif\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify CloudSEN12 data exists\n",
        "cloudsen_path = '/content/drive/MyDrive/Colab_Data/cloudsen12_subset'\n",
        "\n",
        "if os.path.exists(cloudsen_path):\n",
        "    num_patches = len([d for d in Path(cloudsen_path).iterdir() if d.is_dir()])\n",
        "    print(f\"‚úÖ CloudSEN12 data found: {num_patches} patches\")\n",
        "    print(f\"üìÇ Location: {cloudsen_path}\")\n",
        "    \n",
        "    # Process CloudSEN12 data with loader (extracts 10 bands, converts masks)\n",
        "    print(\"\\nüîß Processing CloudSEN12 patches...\")\n",
        "    !python cloudsen12_loader.py\n",
        "else:\n",
        "    print(f\"‚ùå CloudSEN12 data not found at: {cloudsen_path}\")\n",
        "    print(\"Please run CloudSEN12 download notebook first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e4f059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45e4f059",
        "outputId": "4ba93ef8-ffd8-4a87-a39d-7b235e1eca31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All data files present!\n",
            "Ready to proceed.\n"
          ]
        }
      ],
      "source": [
        "# Verify processed CloudSEN12 data\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "processed_dir = 'data/cloudsen12_processed'\n",
        "image_files = glob.glob(f'{processed_dir}/*_image.tif')\n",
        "mask_files = glob.glob(f'{processed_dir}/*_mask.tif')\n",
        "\n",
        "if len(image_files) > 0 and len(mask_files) > 0:\n",
        "    print(f\"‚úÖ CloudSEN12 data processed successfully!\")\n",
        "    print(f\"üìä Found {len(image_files)} image patches\")\n",
        "    print(f\"üìä Found {len(mask_files)} mask patches\")\n",
        "    print(\"\\nüéØ Ready for training with real ground truth!\")\n",
        "else:\n",
        "    print(\"‚ùå Processed data not found\")\n",
        "    print(\"Please check cloudsen12_loader.py output for errors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71cc30ed",
      "metadata": {
        "id": "71cc30ed"
      },
      "source": [
        "## 3Ô∏è‚É£ Check CNN Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f381a12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f381a12",
        "outputId": "fd5b87ac-daf2-4637-ae90-8be9c4f33b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.4187\n",
            "  Precision: 0.1706\n",
            "  Recall:    0.6232\n",
            "  F1-Score:  0.2679\n",
            "\n",
            "üìä Ground truth: 5,144,277 cloud pixels\n",
            "üìä CNN predicted: 18,786,327 cloud pixels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# Load and test CNN baseline on CloudSEN12 patches\n",
        "from cnn_inference import load_sentinel2_image, get_cloud_mask\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "print(\"üß† Evaluating CNN Baseline on CloudSEN12 Real Ground Truth\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load all processed CloudSEN12 patches\n",
        "image_files = sorted(glob.glob('data/cloudsen12_processed/*_image.tif'))\n",
        "mask_files = sorted(glob.glob('data/cloudsen12_processed/*_mask.tif'))\n",
        "\n",
        "all_gt = []\n",
        "all_cnn = []\n",
        "\n",
        "print(f\"Processing {len(image_files)} patches...\\n\")\n",
        "\n",
        "for img_path, mask_path in zip(image_files, mask_files):  # Use ALL patches\n",
        "    # Load image and get CNN prediction\n",
        "    image = load_sentinel2_image(img_path)\n",
        "    cnn_prob = get_cloud_mask(image)\n",
        "    \n",
        "    # Load real ground truth\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        ground_truth = src.read(1)\n",
        "    \n",
        "    # Binary conversion\n",
        "    gt_binary = (ground_truth > 0).astype(np.uint8)\n",
        "    cnn_binary = (cnn_prob > 0.5).astype(np.uint8)\n",
        "    \n",
        "    all_gt.append(gt_binary.flatten())\n",
        "    all_cnn.append(cnn_binary.flatten())\n",
        "\n",
        "# Combine all patches\n",
        "all_gt = np.concatenate(all_gt)\n",
        "all_cnn = np.concatenate(all_cnn)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(all_gt, all_cnn)\n",
        "precision = precision_score(all_gt, all_cnn, zero_division=0)\n",
        "recall = recall_score(all_gt, all_cnn, zero_division=0)\n",
        "f1 = f1_score(all_gt, all_cnn, zero_division=0)\n",
        "\n",
        "print(f\"\\nüìä Evaluated on {len(image_files)} CloudSEN12 patches\")\n",
        "print(f\"üìä Total pixels: {len(all_gt):,}\")\n",
        "print(\"\\nüß† CNN Baseline (Real Ground Truth):\")\n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "\n",
        "print(f\"  F1-Score:  {f1:.4f}\")print(f\"üìä CNN predicted: {all_cnn.sum():,} cloud pixels ({all_cnn.mean()*100:.1f}%)\")\n",
        "print(f\"\\nüìä Ground truth: {all_gt.sum():,} cloud pixels ({all_gt.mean()*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "088c8f8a",
      "metadata": {
        "id": "088c8f8a"
      },
      "source": [
        "## 4Ô∏è‚É£ Pull Latest Code & Train PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6f2470c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f2470c4",
        "outputId": "252034e3-ae13-486e-9d9c-902c3c8eb27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 3), reused 5 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  16% (1/6)\rUnpacking objects:  33% (2/6)\rUnpacking objects:  50% (3/6)\rUnpacking objects:  66% (4/6)\rUnpacking objects:  83% (5/6)\rUnpacking objects: 100% (6/6)\rUnpacking objects: 100% (6/6), 2.40 KiB | 2.40 MiB/s, done.\n",
            "From https://github.com/Usernamenisiya/thesis-cloud-rl\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   057b377..7debeb7  master     -> origin/master\n",
            "Updating 057b377..7debeb7\n",
            "Fast-forward\n",
            " download_cloudsen12_subset.py | 123 \u001b[32m++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " 1 file changed, 123 insertions(+)\n",
            " create mode 100644 download_cloudsen12_subset.py\n",
            "‚úÖ Repository updated\n"
          ]
        }
      ],
      "source": [
        "# Get latest code with PPO improvements\n",
        "!git pull origin master\n",
        "print(\"‚úÖ Repository updated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c35457",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimize CNN threshold for fair baseline comparison\n",
        "print(\"üîç Finding optimal CNN threshold...\")\n",
        "!python optimize_cnn_threshold.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a94b2378",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a94b2378",
        "outputId": "ccddbf2b-7142-4495-b054-1d4518a27a51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting PPO training...\n",
            "This will take 1-2 hours with GPU\n",
            "============================================================\n",
            "2026-01-12 06:28:41.461458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768199321.483381   17100 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768199321.489958   17100 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768199321.506152   17100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768199321.506194   17100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768199321.506197   17100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768199321.506200   17100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "============================================================\n",
            "ü§ñ Training PPO Agent for Cloud Mask Refinement\n",
            "============================================================\n",
            "\n",
            "üìÇ Loading data files...\n",
            "‚úÖ Data loaded: Image shape (5490, 5490, 10), CNN prob shape (5490, 5490)\n",
            "\n",
            "üéÆ Creating RL environment...\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 7225\n",
            "üéØ Using EPISODE-PER-PATCH configuration for stable learning\n",
            "\n",
            "üß† Creating PPO model with CUSTOM CNN for 11-channel input:\n",
            "   learning_rate: 0.0003\n",
            "   n_steps: 4096\n",
            "   batch_size: 256\n",
            "   n_epochs: 10\n",
            "   gamma: 0.99\n",
            "   gae_lambda: 0.95\n",
            "   clip_range: 0.2\n",
            "   clip_range_vf: None\n",
            "   ent_coef: 0.01\n",
            "   vf_coef: 0.1\n",
            "   max_grad_norm: 0.5\n",
            "   use_sde: False\n",
            "   sde_sample_freq: -1\n",
            "   target_kl: None\n",
            "\n",
            "üñ•Ô∏è  Using device: cuda\n",
            "Using cuda device\n",
            "\n",
            "============================================================\n",
            "üöÄ Starting PPO Training\n",
            "============================================================\n",
            "Training for 500,000 timesteps...\n",
            "This will take approximately 20-25 minutes with GPU...\n",
            "Logging to ./logs/PPO_6\n",
            "\u001b[2K-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 433  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 9    |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n",
            "\u001b[2KTimestep 5000: 16.4s elapsed, Mean Reward: 1.8270\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 349       |\n",
            "|    iterations           | 2         |\n",
            "|    time_elapsed         | 23        |\n",
            "|    total_timesteps      | 8192      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 6.3390446 |\n",
            "|    clip_fraction        | 0.433     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.179    |\n",
            "|    explained_variance   | -7.49e+04 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.7       |\n",
            "|    n_updates            | 10        |\n",
            "|    policy_gradient_loss | 0.0991    |\n",
            "|    value_loss           | 2.6e+05   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 10000: 32.2s elapsed, Mean Reward: 2.4357\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 328         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012314874 |\n",
            "|    clip_fraction        | 0.0326      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.32       |\n",
            "|    explained_variance   | -5.33       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.582       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0162     |\n",
            "|    value_loss           | 19.7        |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 15000: 48.1s elapsed, Mean Reward: 2.7795\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 320         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013447784 |\n",
            "|    clip_fraction        | 0.0911      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.13       |\n",
            "|    explained_variance   | -1.29       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.13        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0345     |\n",
            "|    value_loss           | 2.7         |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 20000: 63.9s elapsed, Mean Reward: 3.1246\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 315       |\n",
            "|    iterations           | 5         |\n",
            "|    time_elapsed         | 65        |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.3729849 |\n",
            "|    clip_fraction        | 0.454     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.0297   |\n",
            "|    explained_variance   | -1.29     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.05      |\n",
            "|    n_updates            | 40        |\n",
            "|    policy_gradient_loss | -0.101    |\n",
            "|    value_loss           | 1.82      |\n",
            "---------------------------------------\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 312         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 78          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003110406 |\n",
            "|    clip_fraction        | 0.0012      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.00102    |\n",
            "|    explained_variance   | -10.5       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0448      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00285    |\n",
            "|    value_loss           | 0.378       |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 25000: 84.4s elapsed, Mean Reward: 3.1993\n",
            "\u001b[2K-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 309         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 92          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 5.16593e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.000741   |\n",
            "|    explained_variance   | -711        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00515     |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | 5.48e-07    |\n",
            "|    value_loss           | 0.172       |\n",
            "-----------------------------------------\n",
            "\u001b[2KTimestep 30000: 100.1s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 308           |\n",
            "|    iterations           | 8             |\n",
            "|    time_elapsed         | 106           |\n",
            "|    total_timesteps      | 32768         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.6353518e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.00122      |\n",
            "|    explained_variance   | -624          |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0178        |\n",
            "|    n_updates            | 70            |\n",
            "|    policy_gradient_loss | -4.09e-06     |\n",
            "|    value_loss           | 0.109         |\n",
            "-------------------------------------------\n",
            "\u001b[2KTimestep 35000: 115.8s elapsed, Mean Reward: 3.1991\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 307          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 119          |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005583682 |\n",
            "|    clip_fraction        | 0.000244     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.000305    |\n",
            "|    explained_variance   | -30.2        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00532      |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -8.25e-05    |\n",
            "|    value_loss           | 0.152        |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 40000: 131.5s elapsed, Mean Reward: 3.1979\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 306          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 133          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.208452e-08 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.000543    |\n",
            "|    explained_variance   | -1.05e+03    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0139       |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -4e-05       |\n",
            "|    value_loss           | 0.117        |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 45000: 147.2s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 305          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 147          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011272697 |\n",
            "|    clip_fraction        | 0.000708     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.00021     |\n",
            "|    explained_variance   | -6.5         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00604      |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    value_loss           | 0.0853       |\n",
            "------------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 304       |\n",
            "|    iterations           | 12        |\n",
            "|    time_elapsed         | 161       |\n",
            "|    total_timesteps      | 49152     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.000342 |\n",
            "|    explained_variance   | -1.11e+03 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.00163   |\n",
            "|    n_updates            | 110       |\n",
            "|    policy_gradient_loss | -2.06e-05 |\n",
            "|    value_loss           | 0.0556    |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 50000: 167.8s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 304          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 174          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.712515e-10 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.42e-05    |\n",
            "|    explained_variance   | -283         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00154      |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | 1.21e-07     |\n",
            "|    value_loss           | 0.0464       |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 55000: 183.6s elapsed, Mean Reward: 3.1992\n",
            "\u001b[2K------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 303          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 188          |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060967514 |\n",
            "|    clip_fraction        | 0.00022      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.81e-05    |\n",
            "|    explained_variance   | -2.54        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00174      |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.000631    |\n",
            "|    value_loss           | 0.0174       |\n",
            "------------------------------------------\n",
            "\u001b[2KTimestep 60000: 199.3s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 303       |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 202       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.93e-15 |\n",
            "|    explained_variance   | -155      |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.0013    |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | -4.42e-10 |\n",
            "|    value_loss           | 0.018     |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 65000: 215.2s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 16        |\n",
            "|    time_elapsed         | 216       |\n",
            "|    total_timesteps      | 65536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.62e-15 |\n",
            "|    explained_variance   | -97.6     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.000367  |\n",
            "|    n_updates            | 150       |\n",
            "|    policy_gradient_loss | 4.89e-10  |\n",
            "|    value_loss           | 0.00817   |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 17        |\n",
            "|    time_elapsed         | 230       |\n",
            "|    total_timesteps      | 69632     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.77e-14 |\n",
            "|    explained_variance   | -58.7     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.00029   |\n",
            "|    n_updates            | 160       |\n",
            "|    policy_gradient_loss | 3.41e-10  |\n",
            "|    value_loss           | 0.00466   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 70000: 235.6s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 18        |\n",
            "|    time_elapsed         | 243       |\n",
            "|    total_timesteps      | 73728     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.5e-14  |\n",
            "|    explained_variance   | -61.9     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.00032   |\n",
            "|    n_updates            | 170       |\n",
            "|    policy_gradient_loss | -1.03e-09 |\n",
            "|    value_loss           | 0.0117    |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 75000: 251.3s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 19        |\n",
            "|    time_elapsed         | 257       |\n",
            "|    total_timesteps      | 77824     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.88e-14 |\n",
            "|    explained_variance   | -30.2     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.48e-05  |\n",
            "|    n_updates            | 180       |\n",
            "|    policy_gradient_loss | -5.08e-10 |\n",
            "|    value_loss           | 0.00179   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 80000: 267.0s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 302       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 271       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -5.39e-14 |\n",
            "|    explained_variance   | -23.5     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.000132  |\n",
            "|    n_updates            | 190       |\n",
            "|    policy_gradient_loss | -1.19e-09 |\n",
            "|    value_loss           | 0.00193   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 85000: 282.8s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 21        |\n",
            "|    time_elapsed         | 285       |\n",
            "|    total_timesteps      | 86016     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.68e-13 |\n",
            "|    explained_variance   | -9.57     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.58e-05  |\n",
            "|    n_updates            | 200       |\n",
            "|    policy_gradient_loss | 1.04e-09  |\n",
            "|    value_loss           | 0.000829  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 90000: 298.4s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 22        |\n",
            "|    time_elapsed         | 298       |\n",
            "|    total_timesteps      | 90112     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.29e-13 |\n",
            "|    explained_variance   | -11       |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.23e-05  |\n",
            "|    n_updates            | 210       |\n",
            "|    policy_gradient_loss | 1.86e-09  |\n",
            "|    value_loss           | 0.000913  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 312       |\n",
            "|    total_timesteps      | 94208     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2e-13    |\n",
            "|    explained_variance   | -9.99     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.1e-05   |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -1.19e-09 |\n",
            "|    value_loss           | 0.000725  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 95000: 318.7s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 325       |\n",
            "|    total_timesteps      | 98304     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.72e-13 |\n",
            "|    explained_variance   | -6.98     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.99e-05  |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | 5.52e-10  |\n",
            "|    value_loss           | 0.000451  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 100000: 334.2s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 25        |\n",
            "|    time_elapsed         | 339       |\n",
            "|    total_timesteps      | 102400    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.68e-13 |\n",
            "|    explained_variance   | -7.49     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.84e-05  |\n",
            "|    n_updates            | 240       |\n",
            "|    policy_gradient_loss | -1.02e-09 |\n",
            "|    value_loss           | 0.000563  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 105000: 349.9s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 26        |\n",
            "|    time_elapsed         | 353       |\n",
            "|    total_timesteps      | 106496    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.05e-13 |\n",
            "|    explained_variance   | -3.91     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.22e-05  |\n",
            "|    n_updates            | 250       |\n",
            "|    policy_gradient_loss | -9.69e-10 |\n",
            "|    value_loss           | 0.000529  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 110000: 365.5s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 27        |\n",
            "|    time_elapsed         | 366       |\n",
            "|    total_timesteps      | 110592    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.23e-13 |\n",
            "|    explained_variance   | -4.77     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.12e-05  |\n",
            "|    n_updates            | 260       |\n",
            "|    policy_gradient_loss | -1.78e-10 |\n",
            "|    value_loss           | 0.00063   |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 28        |\n",
            "|    time_elapsed         | 380       |\n",
            "|    total_timesteps      | 114688    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.14e-13 |\n",
            "|    explained_variance   | -4.36     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.01e-05  |\n",
            "|    n_updates            | 270       |\n",
            "|    policy_gradient_loss | 3e-10     |\n",
            "|    value_loss           | 0.00151   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 115000: 386.0s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 29        |\n",
            "|    time_elapsed         | 394       |\n",
            "|    total_timesteps      | 118784    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.45e-13 |\n",
            "|    explained_variance   | -6.47     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.17e-05  |\n",
            "|    n_updates            | 280       |\n",
            "|    policy_gradient_loss | 5.15e-10  |\n",
            "|    value_loss           | 0.000406  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 120000: 401.6s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 408       |\n",
            "|    total_timesteps      | 122880    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.32e-12 |\n",
            "|    explained_variance   | -2.23     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.71e-05  |\n",
            "|    n_updates            | 290       |\n",
            "|    policy_gradient_loss | 6.64e-10  |\n",
            "|    value_loss           | 0.000244  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 125000: 417.4s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 301       |\n",
            "|    iterations           | 31        |\n",
            "|    time_elapsed         | 421       |\n",
            "|    total_timesteps      | 126976    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.51e-12 |\n",
            "|    explained_variance   | -1.77     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.33e-05  |\n",
            "|    n_updates            | 300       |\n",
            "|    policy_gradient_loss | -6.34e-10 |\n",
            "|    value_loss           | 0.000179  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 130000: 433.3s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 300       |\n",
            "|    iterations           | 32        |\n",
            "|    time_elapsed         | 435       |\n",
            "|    total_timesteps      | 131072    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.35e-13 |\n",
            "|    explained_variance   | -1.36     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.26e-05  |\n",
            "|    n_updates            | 310       |\n",
            "|    policy_gradient_loss | 1.72e-09  |\n",
            "|    value_loss           | 0.000294  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 135000: 449.1s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 300       |\n",
            "|    iterations           | 33        |\n",
            "|    time_elapsed         | 449       |\n",
            "|    total_timesteps      | 135168    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.95e-12 |\n",
            "|    explained_variance   | -1.37     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.14e-05  |\n",
            "|    n_updates            | 320       |\n",
            "|    policy_gradient_loss | -8.29e-11 |\n",
            "|    value_loss           | 0.000147  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 300       |\n",
            "|    iterations           | 34        |\n",
            "|    time_elapsed         | 463       |\n",
            "|    total_timesteps      | 139264    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.02e-12 |\n",
            "|    explained_variance   | -0.698    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.07e-05  |\n",
            "|    n_updates            | 330       |\n",
            "|    policy_gradient_loss | -6.32e-10 |\n",
            "|    value_loss           | 0.000186  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 140000: 469.8s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 300       |\n",
            "|    iterations           | 35        |\n",
            "|    time_elapsed         | 477       |\n",
            "|    total_timesteps      | 143360    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.47e-12 |\n",
            "|    explained_variance   | -0.585    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.11e-05  |\n",
            "|    n_updates            | 340       |\n",
            "|    policy_gradient_loss | 2.6e-10   |\n",
            "|    value_loss           | 0.000173  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 145000: 485.7s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 300       |\n",
            "|    iterations           | 36        |\n",
            "|    time_elapsed         | 491       |\n",
            "|    total_timesteps      | 147456    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.41e-12 |\n",
            "|    explained_variance   | -2.61     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.42e-05  |\n",
            "|    n_updates            | 350       |\n",
            "|    policy_gradient_loss | -4.06e-10 |\n",
            "|    value_loss           | 0.000305  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 150000: 501.4s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 300       |\n",
            "|    iterations           | 37        |\n",
            "|    time_elapsed         | 504       |\n",
            "|    total_timesteps      | 151552    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.96e-12 |\n",
            "|    explained_variance   | -1.04     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9e-06     |\n",
            "|    n_updates            | 360       |\n",
            "|    policy_gradient_loss | -1.71e-09 |\n",
            "|    value_loss           | 0.000122  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 155000: 517.3s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 300       |\n",
            "|    iterations           | 38        |\n",
            "|    time_elapsed         | 518       |\n",
            "|    total_timesteps      | 155648    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.04e-12 |\n",
            "|    explained_variance   | -0.563    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.31e-05  |\n",
            "|    n_updates            | 370       |\n",
            "|    policy_gradient_loss | 5.92e-10  |\n",
            "|    value_loss           | 0.000187  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 300       |\n",
            "|    iterations           | 39        |\n",
            "|    time_elapsed         | 532       |\n",
            "|    total_timesteps      | 159744    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.38e-12 |\n",
            "|    explained_variance   | -0.546    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.21e-05  |\n",
            "|    n_updates            | 380       |\n",
            "|    policy_gradient_loss | -1.24e-09 |\n",
            "|    value_loss           | 0.000223  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 160000: 537.7s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 546       |\n",
            "|    total_timesteps      | 163840    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.41e-12 |\n",
            "|    explained_variance   | -0.661    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.19e-06  |\n",
            "|    n_updates            | 390       |\n",
            "|    policy_gradient_loss | 1.75e-10  |\n",
            "|    value_loss           | 0.0001    |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 165000: 553.6s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 41        |\n",
            "|    time_elapsed         | 560       |\n",
            "|    total_timesteps      | 167936    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.47e-12 |\n",
            "|    explained_variance   | -0.148    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.27e-05  |\n",
            "|    n_updates            | 400       |\n",
            "|    policy_gradient_loss | -1.95e-10 |\n",
            "|    value_loss           | 0.000252  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 170000: 569.3s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 42        |\n",
            "|    time_elapsed         | 573       |\n",
            "|    total_timesteps      | 172032    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -6.14e-12 |\n",
            "|    explained_variance   | -0.613    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.24e-06  |\n",
            "|    n_updates            | 410       |\n",
            "|    policy_gradient_loss | 2.01e-10  |\n",
            "|    value_loss           | 0.000103  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 175000: 585.1s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 43        |\n",
            "|    time_elapsed         | 587       |\n",
            "|    total_timesteps      | 176128    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.17e-09 |\n",
            "|    explained_variance   | -0.0648   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.000302  |\n",
            "|    n_updates            | 420       |\n",
            "|    policy_gradient_loss | 7.16e-10  |\n",
            "|    value_loss           | 0.000678  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 180000: 600.9s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 44        |\n",
            "|    time_elapsed         | 601       |\n",
            "|    total_timesteps      | 180224    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.53e-09 |\n",
            "|    explained_variance   | -13.4     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.06e-05  |\n",
            "|    n_updates            | 430       |\n",
            "|    policy_gradient_loss | 1.4e-09   |\n",
            "|    value_loss           | 0.000562  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 45        |\n",
            "|    time_elapsed         | 614       |\n",
            "|    total_timesteps      | 184320    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.47e-10 |\n",
            "|    explained_variance   | -2.33     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.23e-05  |\n",
            "|    n_updates            | 440       |\n",
            "|    policy_gradient_loss | 8.73e-12  |\n",
            "|    value_loss           | 0.00019   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 185000: 621.1s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 46        |\n",
            "|    time_elapsed         | 628       |\n",
            "|    total_timesteps      | 188416    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.56e-10 |\n",
            "|    explained_variance   | -0.323    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.84e-06  |\n",
            "|    n_updates            | 450       |\n",
            "|    policy_gradient_loss | -1.72e-10 |\n",
            "|    value_loss           | 0.000126  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 190000: 636.8s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 47        |\n",
            "|    time_elapsed         | 642       |\n",
            "|    total_timesteps      | 192512    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.45e-10 |\n",
            "|    explained_variance   | -0.319    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.11e-05  |\n",
            "|    n_updates            | 460       |\n",
            "|    policy_gradient_loss | 1.14e-09  |\n",
            "|    value_loss           | 0.000109  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 195000: 652.6s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 48        |\n",
            "|    time_elapsed         | 656       |\n",
            "|    total_timesteps      | 196608    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.51e-10 |\n",
            "|    explained_variance   | -0.298    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.29e-05  |\n",
            "|    n_updates            | 470       |\n",
            "|    policy_gradient_loss | 3.43e-10  |\n",
            "|    value_loss           | 0.000112  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 200000: 668.5s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 49        |\n",
            "|    time_elapsed         | 670       |\n",
            "|    total_timesteps      | 200704    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.01e-10 |\n",
            "|    explained_variance   | -0.209    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.31e-06  |\n",
            "|    n_updates            | 480       |\n",
            "|    policy_gradient_loss | 5.7e-10   |\n",
            "|    value_loss           | 0.000112  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 50        |\n",
            "|    time_elapsed         | 683       |\n",
            "|    total_timesteps      | 204800    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.54e-10 |\n",
            "|    explained_variance   | -0.039    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.57e-06  |\n",
            "|    n_updates            | 490       |\n",
            "|    policy_gradient_loss | 1.25e-10  |\n",
            "|    value_loss           | 9.43e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 205000: 689.0s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 51        |\n",
            "|    time_elapsed         | 697       |\n",
            "|    total_timesteps      | 208896    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.23e-10 |\n",
            "|    explained_variance   | -0.0114   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.41e-05  |\n",
            "|    n_updates            | 500       |\n",
            "|    policy_gradient_loss | -5.85e-10 |\n",
            "|    value_loss           | 9.71e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 210000: 704.7s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 52        |\n",
            "|    time_elapsed         | 711       |\n",
            "|    total_timesteps      | 212992    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.58e-10 |\n",
            "|    explained_variance   | -0.397    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.1e-05   |\n",
            "|    n_updates            | 510       |\n",
            "|    policy_gradient_loss | 1.22e-10  |\n",
            "|    value_loss           | 0.000104  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 215000: 720.5s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 53        |\n",
            "|    time_elapsed         | 725       |\n",
            "|    total_timesteps      | 217088    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -6.65e-10 |\n",
            "|    explained_variance   | -0.0395   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.75e-06  |\n",
            "|    n_updates            | 520       |\n",
            "|    policy_gradient_loss | 5.38e-10  |\n",
            "|    value_loss           | 0.000106  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 220000: 736.2s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 299      |\n",
            "|    iterations           | 54       |\n",
            "|    time_elapsed         | 738      |\n",
            "|    total_timesteps      | 221184   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.0      |\n",
            "|    clip_fraction        | 0        |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -6.2e-10 |\n",
            "|    explained_variance   | -0.152   |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 8.49e-06 |\n",
            "|    n_updates            | 530      |\n",
            "|    policy_gradient_loss | 5.18e-10 |\n",
            "|    value_loss           | 0.000109 |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 225000: 752.0s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 55        |\n",
            "|    time_elapsed         | 752       |\n",
            "|    total_timesteps      | 225280    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.34e-09 |\n",
            "|    explained_variance   | -0.0995   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.86e-05  |\n",
            "|    n_updates            | 540       |\n",
            "|    policy_gradient_loss | 1.43e-09  |\n",
            "|    value_loss           | 0.000123  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 56        |\n",
            "|    time_elapsed         | 766       |\n",
            "|    total_timesteps      | 229376    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.18e-09 |\n",
            "|    explained_variance   | -0.132    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.58e-06  |\n",
            "|    n_updates            | 550       |\n",
            "|    policy_gradient_loss | 1.86e-10  |\n",
            "|    value_loss           | 0.000118  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 230000: 772.6s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 57        |\n",
            "|    time_elapsed         | 780       |\n",
            "|    total_timesteps      | 233472    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.29e-09 |\n",
            "|    explained_variance   | -0.0529   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.86e-06  |\n",
            "|    n_updates            | 560       |\n",
            "|    policy_gradient_loss | -3.68e-10 |\n",
            "|    value_loss           | 0.000111  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 235000: 788.4s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 58        |\n",
            "|    time_elapsed         | 794       |\n",
            "|    total_timesteps      | 237568    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.85e-09 |\n",
            "|    explained_variance   | -0.0531   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.02e-06  |\n",
            "|    n_updates            | 570       |\n",
            "|    policy_gradient_loss | 1.28e-10  |\n",
            "|    value_loss           | 0.000105  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 240000: 804.4s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 59        |\n",
            "|    time_elapsed         | 808       |\n",
            "|    total_timesteps      | 241664    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.56e-09 |\n",
            "|    explained_variance   | -0.0178   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.01e-06  |\n",
            "|    n_updates            | 580       |\n",
            "|    policy_gradient_loss | 1.2e-09   |\n",
            "|    value_loss           | 0.000124  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 245000: 820.3s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 60        |\n",
            "|    time_elapsed         | 822       |\n",
            "|    total_timesteps      | 245760    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -6.08e-09 |\n",
            "|    explained_variance   | -0.00592  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.52e-06  |\n",
            "|    n_updates            | 590       |\n",
            "|    policy_gradient_loss | -3.9e-10  |\n",
            "|    value_loss           | 0.000114  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 61        |\n",
            "|    time_elapsed         | 836       |\n",
            "|    total_timesteps      | 249856    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -6.5e-09  |\n",
            "|    explained_variance   | -0.103    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.43e-06  |\n",
            "|    n_updates            | 600       |\n",
            "|    policy_gradient_loss | -2.04e-10 |\n",
            "|    value_loss           | 0.000101  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 250000: 841.1s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 62        |\n",
            "|    time_elapsed         | 849       |\n",
            "|    total_timesteps      | 253952    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.88e-08 |\n",
            "|    explained_variance   | -0.0132   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.83e-06  |\n",
            "|    n_updates            | 610       |\n",
            "|    policy_gradient_loss | -6.01e-10 |\n",
            "|    value_loss           | 0.000142  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 255000: 856.9s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 63        |\n",
            "|    time_elapsed         | 863       |\n",
            "|    total_timesteps      | 258048    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.69e-09 |\n",
            "|    explained_variance   | -0.0496   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.54e-06  |\n",
            "|    n_updates            | 620       |\n",
            "|    policy_gradient_loss | -9.65e-10 |\n",
            "|    value_loss           | 0.000107  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 260000: 872.7s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 64        |\n",
            "|    time_elapsed         | 877       |\n",
            "|    total_timesteps      | 262144    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.06e-08 |\n",
            "|    explained_variance   | 0.00457   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.01e-05  |\n",
            "|    n_updates            | 630       |\n",
            "|    policy_gradient_loss | -1.11e-10 |\n",
            "|    value_loss           | 0.00012   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 265000: 888.4s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 65        |\n",
            "|    time_elapsed         | 891       |\n",
            "|    total_timesteps      | 266240    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.63e-08 |\n",
            "|    explained_variance   | -0.23     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.53e-06  |\n",
            "|    n_updates            | 640       |\n",
            "|    policy_gradient_loss | 1.11e-10  |\n",
            "|    value_loss           | 0.000105  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 270000: 904.1s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 66        |\n",
            "|    time_elapsed         | 904       |\n",
            "|    total_timesteps      | 270336    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.42e-07 |\n",
            "|    explained_variance   | 0.0176    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.39e-06  |\n",
            "|    n_updates            | 650       |\n",
            "|    policy_gradient_loss | -3.97e-09 |\n",
            "|    value_loss           | 0.0563    |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 67        |\n",
            "|    time_elapsed         | 918       |\n",
            "|    total_timesteps      | 274432    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.55e-07 |\n",
            "|    explained_variance   | -2.04     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.82e-06  |\n",
            "|    n_updates            | 660       |\n",
            "|    policy_gradient_loss | 7.4e-08   |\n",
            "|    value_loss           | 0.00142   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 275000: 924.4s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 68        |\n",
            "|    time_elapsed         | 932       |\n",
            "|    total_timesteps      | 278528    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.89e-07 |\n",
            "|    explained_variance   | -6.26     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.08e-05  |\n",
            "|    n_updates            | 670       |\n",
            "|    policy_gradient_loss | 9.65e-08  |\n",
            "|    value_loss           | 0.000341  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 280000: 940.0s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 69        |\n",
            "|    time_elapsed         | 945       |\n",
            "|    total_timesteps      | 282624    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.03e-07 |\n",
            "|    explained_variance   | -0.0556   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.24e-06  |\n",
            "|    n_updates            | 680       |\n",
            "|    policy_gradient_loss | -3.26e-10 |\n",
            "|    value_loss           | 8.73e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 285000: 955.8s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 70        |\n",
            "|    time_elapsed         | 959       |\n",
            "|    total_timesteps      | 286720    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.47e-07 |\n",
            "|    explained_variance   | -0.0225   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.11e-06  |\n",
            "|    n_updates            | 690       |\n",
            "|    policy_gradient_loss | -5.56e-10 |\n",
            "|    value_loss           | 8.88e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 290000: 971.7s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 71        |\n",
            "|    time_elapsed         | 973       |\n",
            "|    total_timesteps      | 290816    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.27e-07 |\n",
            "|    explained_variance   | -0.00355  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.85e-06  |\n",
            "|    n_updates            | 700       |\n",
            "|    policy_gradient_loss | -8.09e-10 |\n",
            "|    value_loss           | 8.69e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 72        |\n",
            "|    time_elapsed         | 987       |\n",
            "|    total_timesteps      | 294912    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.87e-07 |\n",
            "|    explained_variance   | 0.000852  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.72e-06  |\n",
            "|    n_updates            | 710       |\n",
            "|    policy_gradient_loss | 6.23e-10  |\n",
            "|    value_loss           | 8.55e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 295000: 992.2s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 73        |\n",
            "|    time_elapsed         | 1001      |\n",
            "|    total_timesteps      | 299008    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.61e-07 |\n",
            "|    explained_variance   | 0.00111   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.97e-06  |\n",
            "|    n_updates            | 720       |\n",
            "|    policy_gradient_loss | -5.7e-10  |\n",
            "|    value_loss           | 8.89e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 300000: 1008.1s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 74        |\n",
            "|    time_elapsed         | 1015      |\n",
            "|    total_timesteps      | 303104    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.38e-07 |\n",
            "|    explained_variance   | 0.00143   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1e-05     |\n",
            "|    n_updates            | 730       |\n",
            "|    policy_gradient_loss | -1.69e-10 |\n",
            "|    value_loss           | 8.99e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 305000: 1024.0s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 75        |\n",
            "|    time_elapsed         | 1028      |\n",
            "|    total_timesteps      | 307200    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.49e-07 |\n",
            "|    explained_variance   | 0.00305   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.81e-06  |\n",
            "|    n_updates            | 740       |\n",
            "|    policy_gradient_loss | 2.82e-10  |\n",
            "|    value_loss           | 8.8e-05   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 310000: 1039.8s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 76        |\n",
            "|    time_elapsed         | 1042      |\n",
            "|    total_timesteps      | 311296    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.55e-07 |\n",
            "|    explained_variance   | -0.000213 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.35e-06  |\n",
            "|    n_updates            | 750       |\n",
            "|    policy_gradient_loss | -5.38e-10 |\n",
            "|    value_loss           | 8.8e-05   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 315000: 1055.7s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 77        |\n",
            "|    time_elapsed         | 1056      |\n",
            "|    total_timesteps      | 315392    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.22e-07 |\n",
            "|    explained_variance   | 0.00516   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.26e-06  |\n",
            "|    n_updates            | 760       |\n",
            "|    policy_gradient_loss | 2.91e-11  |\n",
            "|    value_loss           | 8.89e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 78        |\n",
            "|    time_elapsed         | 1070      |\n",
            "|    total_timesteps      | 319488    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.06e-07 |\n",
            "|    explained_variance   | 0.000461  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.09e-06  |\n",
            "|    n_updates            | 770       |\n",
            "|    policy_gradient_loss | -8e-10    |\n",
            "|    value_loss           | 8.75e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 320000: 1076.3s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 79        |\n",
            "|    time_elapsed         | 1084      |\n",
            "|    total_timesteps      | 323584    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.94e-07 |\n",
            "|    explained_variance   | 0.00403   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.92e-06  |\n",
            "|    n_updates            | 780       |\n",
            "|    policy_gradient_loss | 5.27e-10  |\n",
            "|    value_loss           | 8.72e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 325000: 1092.1s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 80        |\n",
            "|    time_elapsed         | 1097      |\n",
            "|    total_timesteps      | 327680    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.81e-07 |\n",
            "|    explained_variance   | 0.000843  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.23e-06  |\n",
            "|    n_updates            | 790       |\n",
            "|    policy_gradient_loss | 4.86e-10  |\n",
            "|    value_loss           | 8.99e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 330000: 1107.7s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 81        |\n",
            "|    time_elapsed         | 1111      |\n",
            "|    total_timesteps      | 331776    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.12e-06 |\n",
            "|    explained_variance   | 0.00244   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.18e-06  |\n",
            "|    n_updates            | 800       |\n",
            "|    policy_gradient_loss | -9.31e-11 |\n",
            "|    value_loss           | 9.06e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 335000: 1123.5s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 82        |\n",
            "|    time_elapsed         | 1125      |\n",
            "|    total_timesteps      | 335872    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.13e-06 |\n",
            "|    explained_variance   | -0.0188   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.79e-06  |\n",
            "|    n_updates            | 810       |\n",
            "|    policy_gradient_loss | -1.72e-09 |\n",
            "|    value_loss           | 9.1e-05   |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 83        |\n",
            "|    time_elapsed         | 1139      |\n",
            "|    total_timesteps      | 339968    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.19e-06 |\n",
            "|    explained_variance   | -0.0508   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.1e-05   |\n",
            "|    n_updates            | 820       |\n",
            "|    policy_gradient_loss | -2.21e-10 |\n",
            "|    value_loss           | 0.000102  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 340000: 1144.1s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 84        |\n",
            "|    time_elapsed         | 1153      |\n",
            "|    total_timesteps      | 344064    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.28e-06 |\n",
            "|    explained_variance   | -0.211    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.46e-06  |\n",
            "|    n_updates            | 830       |\n",
            "|    policy_gradient_loss | -7.6e-10  |\n",
            "|    value_loss           | 0.000117  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 345000: 1160.0s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 85        |\n",
            "|    time_elapsed         | 1167      |\n",
            "|    total_timesteps      | 348160    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.41e-06 |\n",
            "|    explained_variance   | -0.0157   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.04e-05  |\n",
            "|    n_updates            | 840       |\n",
            "|    policy_gradient_loss | -8.24e-10 |\n",
            "|    value_loss           | 9.03e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 350000: 1176.0s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 86        |\n",
            "|    time_elapsed         | 1181      |\n",
            "|    total_timesteps      | 352256    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.58e-06 |\n",
            "|    explained_variance   | -0.305    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.22e-06  |\n",
            "|    n_updates            | 850       |\n",
            "|    policy_gradient_loss | -3.06e-10 |\n",
            "|    value_loss           | 0.000101  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 355000: 1191.9s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 87        |\n",
            "|    time_elapsed         | 1194      |\n",
            "|    total_timesteps      | 356352    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.68e-06 |\n",
            "|    explained_variance   | -0.00177  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.65e-06  |\n",
            "|    n_updates            | 860       |\n",
            "|    policy_gradient_loss | -2.36e-10 |\n",
            "|    value_loss           | 8.98e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 360000: 1207.8s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 88        |\n",
            "|    time_elapsed         | 1208      |\n",
            "|    total_timesteps      | 360448    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2e-06    |\n",
            "|    explained_variance   | 0.0034    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.12e-05  |\n",
            "|    n_updates            | 870       |\n",
            "|    policy_gradient_loss | -2.87e-10 |\n",
            "|    value_loss           | 9.14e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 89        |\n",
            "|    time_elapsed         | 1222      |\n",
            "|    total_timesteps      | 364544    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.12e-06 |\n",
            "|    explained_variance   | 0.00332   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.86e-06  |\n",
            "|    n_updates            | 880       |\n",
            "|    policy_gradient_loss | 5.38e-10  |\n",
            "|    value_loss           | 8.8e-05   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 365000: 1228.2s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 90        |\n",
            "|    time_elapsed         | 1236      |\n",
            "|    total_timesteps      | 368640    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.42e-06 |\n",
            "|    explained_variance   | 0.0018    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.74e-06  |\n",
            "|    n_updates            | 890       |\n",
            "|    policy_gradient_loss | -3.07e-10 |\n",
            "|    value_loss           | 9.5e-05   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 370000: 1243.7s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 91        |\n",
            "|    time_elapsed         | 1249      |\n",
            "|    total_timesteps      | 372736    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.86e-06 |\n",
            "|    explained_variance   | 0.00331   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.27e-06  |\n",
            "|    n_updates            | 900       |\n",
            "|    policy_gradient_loss | -8.73e-12 |\n",
            "|    value_loss           | 9.04e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 375000: 1259.5s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 92        |\n",
            "|    time_elapsed         | 1263      |\n",
            "|    total_timesteps      | 376832    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.18e-06 |\n",
            "|    explained_variance   | -0.00819  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.01e-05  |\n",
            "|    n_updates            | 910       |\n",
            "|    policy_gradient_loss | -3.06e-10 |\n",
            "|    value_loss           | 0.000104  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 380000: 1275.3s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 93        |\n",
            "|    time_elapsed         | 1277      |\n",
            "|    total_timesteps      | 380928    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.01e-06 |\n",
            "|    explained_variance   | -0.0424   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.54e-06  |\n",
            "|    n_updates            | 920       |\n",
            "|    policy_gradient_loss | -3.53e-09 |\n",
            "|    value_loss           | 9.33e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 385000: 1291.1s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 94        |\n",
            "|    time_elapsed         | 1291      |\n",
            "|    total_timesteps      | 385024    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.64e-06 |\n",
            "|    explained_variance   | -0.476    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.61e-06  |\n",
            "|    n_updates            | 930       |\n",
            "|    policy_gradient_loss | 6.37e-09  |\n",
            "|    value_loss           | 0.000147  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 95        |\n",
            "|    time_elapsed         | 1305      |\n",
            "|    total_timesteps      | 389120    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -6.77e-06 |\n",
            "|    explained_variance   | -0.414    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 6.47e-06  |\n",
            "|    n_updates            | 940       |\n",
            "|    policy_gradient_loss | -1.78e-10 |\n",
            "|    value_loss           | 0.000127  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 390000: 1311.7s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 96        |\n",
            "|    time_elapsed         | 1318      |\n",
            "|    total_timesteps      | 393216    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.37e-06 |\n",
            "|    explained_variance   | -0.265    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.22e-05  |\n",
            "|    n_updates            | 950       |\n",
            "|    policy_gradient_loss | -2.88e-10 |\n",
            "|    value_loss           | 0.000104  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 395000: 1327.6s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 97        |\n",
            "|    time_elapsed         | 1332      |\n",
            "|    total_timesteps      | 397312    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.63e-05 |\n",
            "|    explained_variance   | -0.0199   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.87e-06  |\n",
            "|    n_updates            | 960       |\n",
            "|    policy_gradient_loss | -1.85e-09 |\n",
            "|    value_loss           | 9.51e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 400000: 1343.7s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------------\n",
            "| time/                   |                 |\n",
            "|    fps                  | 298             |\n",
            "|    iterations           | 98              |\n",
            "|    time_elapsed         | 1346            |\n",
            "|    total_timesteps      | 401408          |\n",
            "| train/                  |                 |\n",
            "|    approx_kl            | -1.41590135e-08 |\n",
            "|    clip_fraction        | 0               |\n",
            "|    clip_range           | 0.2             |\n",
            "|    entropy_loss         | -3.41e-05       |\n",
            "|    explained_variance   | -0.000301       |\n",
            "|    learning_rate        | 0.0003          |\n",
            "|    loss                 | 8.35e-06        |\n",
            "|    n_updates            | 970             |\n",
            "|    policy_gradient_loss | -8.07e-09       |\n",
            "|    value_loss           | 9.28e-05        |\n",
            "---------------------------------------------\n",
            "\u001b[2KTimestep 405000: 1359.6s elapsed, Mean Reward: 3.1696\n",
            "\u001b[2K-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 297           |\n",
            "|    iterations           | 99            |\n",
            "|    time_elapsed         | 1360          |\n",
            "|    total_timesteps      | 405504        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.8720457e-06 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.00116      |\n",
            "|    explained_variance   | -0.0053       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.000314     |\n",
            "|    n_updates            | 980           |\n",
            "|    policy_gradient_loss | 4.27e-07      |\n",
            "|    value_loss           | 9.51e-05      |\n",
            "-------------------------------------------\n",
            "\u001b[2K----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 297        |\n",
            "|    iterations           | 100        |\n",
            "|    time_elapsed         | 1374       |\n",
            "|    total_timesteps      | 409600     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13471438 |\n",
            "|    clip_fraction        | 0.00994    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.000495  |\n",
            "|    explained_variance   | -0.0002    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.007     |\n",
            "|    n_updates            | 990        |\n",
            "|    policy_gradient_loss | -0.0191    |\n",
            "|    value_loss           | 0.144      |\n",
            "----------------------------------------\n",
            "\u001b[2KTimestep 410000: 1380.2s elapsed, Mean Reward: 3.1991\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 297       |\n",
            "|    iterations           | 101       |\n",
            "|    time_elapsed         | 1388      |\n",
            "|    total_timesteps      | 413696    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.73e-08 |\n",
            "|    explained_variance   | -0.823    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.28e-06  |\n",
            "|    n_updates            | 1000      |\n",
            "|    policy_gradient_loss | -1.02e-08 |\n",
            "|    value_loss           | 0.000125  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 415000: 1395.9s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 297       |\n",
            "|    iterations           | 102       |\n",
            "|    time_elapsed         | 1402      |\n",
            "|    total_timesteps      | 417792    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.27e-08 |\n",
            "|    explained_variance   | -0.045    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.79e-06  |\n",
            "|    n_updates            | 1010      |\n",
            "|    policy_gradient_loss | -9.87e-10 |\n",
            "|    value_loss           | 8.68e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 420000: 1411.7s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 297       |\n",
            "|    iterations           | 103       |\n",
            "|    time_elapsed         | 1415      |\n",
            "|    total_timesteps      | 421888    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.79e-08 |\n",
            "|    explained_variance   | -0.0117   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.74e-06  |\n",
            "|    n_updates            | 1020      |\n",
            "|    policy_gradient_loss | -2.59e-10 |\n",
            "|    value_loss           | 8.89e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 425000: 1427.3s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 297       |\n",
            "|    iterations           | 104       |\n",
            "|    time_elapsed         | 1429      |\n",
            "|    total_timesteps      | 425984    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.29e-08 |\n",
            "|    explained_variance   | -0.000213 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.91e-06  |\n",
            "|    n_updates            | 1030      |\n",
            "|    policy_gradient_loss | 6.94e-10  |\n",
            "|    value_loss           | 8.82e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 430000: 1443.1s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 297       |\n",
            "|    iterations           | 105       |\n",
            "|    time_elapsed         | 1443      |\n",
            "|    total_timesteps      | 430080    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.21e-08 |\n",
            "|    explained_variance   | 0.00119   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.8e-06   |\n",
            "|    n_updates            | 1040      |\n",
            "|    policy_gradient_loss | -4.18e-10 |\n",
            "|    value_loss           | 8.83e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 106       |\n",
            "|    time_elapsed         | 1456      |\n",
            "|    total_timesteps      | 434176    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.03e-08 |\n",
            "|    explained_variance   | -5.2e-05  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.52e-06  |\n",
            "|    n_updates            | 1050      |\n",
            "|    policy_gradient_loss | -4.51e-10 |\n",
            "|    value_loss           | 8.72e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 435000: 1463.5s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 297      |\n",
            "|    iterations           | 107      |\n",
            "|    time_elapsed         | 1470     |\n",
            "|    total_timesteps      | 438272   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.0      |\n",
            "|    clip_fraction        | 0        |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -9.4e-08 |\n",
            "|    explained_variance   | 0.00324  |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 9.57e-06 |\n",
            "|    n_updates            | 1060     |\n",
            "|    policy_gradient_loss | 8.44e-11 |\n",
            "|    value_loss           | 8.76e-05 |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 440000: 1479.1s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 108       |\n",
            "|    time_elapsed         | 1484      |\n",
            "|    total_timesteps      | 442368    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -8.99e-08 |\n",
            "|    explained_variance   | 0.000676  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.58e-06  |\n",
            "|    n_updates            | 1070      |\n",
            "|    policy_gradient_loss | -6.32e-10 |\n",
            "|    value_loss           | 8.81e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 445000: 1494.8s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 109       |\n",
            "|    time_elapsed         | 1498      |\n",
            "|    total_timesteps      | 446464    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.6e-08  |\n",
            "|    explained_variance   | 0.00227   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.41e-06  |\n",
            "|    n_updates            | 1080      |\n",
            "|    policy_gradient_loss | -9.68e-10 |\n",
            "|    value_loss           | 8.77e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 450000: 1510.4s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 110       |\n",
            "|    time_elapsed         | 1511      |\n",
            "|    total_timesteps      | 450560    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.13e-08 |\n",
            "|    explained_variance   | 0.00161   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.78e-06  |\n",
            "|    n_updates            | 1090      |\n",
            "|    policy_gradient_loss | -1.55e-09 |\n",
            "|    value_loss           | 8.87e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 111       |\n",
            "|    time_elapsed         | 1525      |\n",
            "|    total_timesteps      | 454656    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.87e-08 |\n",
            "|    explained_variance   | 0.00271   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.32e-06  |\n",
            "|    n_updates            | 1100      |\n",
            "|    policy_gradient_loss | 4.86e-10  |\n",
            "|    value_loss           | 9.06e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 455000: 1530.6s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 112       |\n",
            "|    time_elapsed         | 1538      |\n",
            "|    total_timesteps      | 458752    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.71e-08 |\n",
            "|    explained_variance   | 0.00162   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.98e-06  |\n",
            "|    n_updates            | 1110      |\n",
            "|    policy_gradient_loss | 3.38e-10  |\n",
            "|    value_loss           | 8.99e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 460000: 1546.4s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 113       |\n",
            "|    time_elapsed         | 1552      |\n",
            "|    total_timesteps      | 462848    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.72e-08 |\n",
            "|    explained_variance   | 0.000717  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.83e-06  |\n",
            "|    n_updates            | 1120      |\n",
            "|    policy_gradient_loss | 3.55e-10  |\n",
            "|    value_loss           | 8.9e-05   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 465000: 1562.2s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 114       |\n",
            "|    time_elapsed         | 1566      |\n",
            "|    total_timesteps      | 466944    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.02e-07 |\n",
            "|    explained_variance   | 0.00338   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.58e-06  |\n",
            "|    n_updates            | 1130      |\n",
            "|    policy_gradient_loss | 2.36e-10  |\n",
            "|    value_loss           | 8.98e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 470000: 1577.9s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 115       |\n",
            "|    time_elapsed         | 1580      |\n",
            "|    total_timesteps      | 471040    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.81e-08 |\n",
            "|    explained_variance   | 0.000966  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8e-06     |\n",
            "|    n_updates            | 1140      |\n",
            "|    policy_gradient_loss | -1.32e-09 |\n",
            "|    value_loss           | 9.1e-05   |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 475000: 1593.7s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 116       |\n",
            "|    time_elapsed         | 1594      |\n",
            "|    total_timesteps      | 475136    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.05e-07 |\n",
            "|    explained_variance   | 0.000944  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.68e-06  |\n",
            "|    n_updates            | 1150      |\n",
            "|    policy_gradient_loss | -5.15e-10 |\n",
            "|    value_loss           | 8.82e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2K--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 298      |\n",
            "|    iterations           | 117      |\n",
            "|    time_elapsed         | 1607     |\n",
            "|    total_timesteps      | 479232   |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.0      |\n",
            "|    clip_fraction        | 0        |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1e-07   |\n",
            "|    explained_variance   | -0.00484 |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 1.02e-05 |\n",
            "|    n_updates            | 1160     |\n",
            "|    policy_gradient_loss | 5.53e-11 |\n",
            "|    value_loss           | 8.86e-05 |\n",
            "--------------------------------------\n",
            "\u001b[2KTimestep 480000: 1614.2s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 118       |\n",
            "|    time_elapsed         | 1621      |\n",
            "|    total_timesteps      | 483328    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.09e-07 |\n",
            "|    explained_variance   | 0.00153   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.14e-06  |\n",
            "|    n_updates            | 1170      |\n",
            "|    policy_gradient_loss | 2.91e-10  |\n",
            "|    value_loss           | 9.39e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 485000: 1630.0s elapsed, Mean Reward: 3.1999\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 119       |\n",
            "|    time_elapsed         | 1635      |\n",
            "|    total_timesteps      | 487424    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.08e-07 |\n",
            "|    explained_variance   | -0.000823 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.27e-05  |\n",
            "|    n_updates            | 1180      |\n",
            "|    policy_gradient_loss | 3.43e-10  |\n",
            "|    value_loss           | 9.41e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 490000: 1645.8s elapsed, Mean Reward: 3.1998\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 120       |\n",
            "|    time_elapsed         | 1649      |\n",
            "|    total_timesteps      | 491520    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.12e-07 |\n",
            "|    explained_variance   | -0.216    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.03e-05  |\n",
            "|    n_updates            | 1190      |\n",
            "|    policy_gradient_loss | 1.31e-09  |\n",
            "|    value_loss           | 9.98e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 495000: 1661.7s elapsed, Mean Reward: 3.2001\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 298       |\n",
            "|    iterations           | 121       |\n",
            "|    time_elapsed         | 1663      |\n",
            "|    total_timesteps      | 495616    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.16e-07 |\n",
            "|    explained_variance   | -0.0455   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.56e-06  |\n",
            "|    n_updates            | 1200      |\n",
            "|    policy_gradient_loss | -1.43e-10 |\n",
            "|    value_loss           | 9.26e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 297       |\n",
            "|    iterations           | 122       |\n",
            "|    time_elapsed         | 1676      |\n",
            "|    total_timesteps      | 499712    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.13e-07 |\n",
            "|    explained_variance   | -0.0447   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.73e-06  |\n",
            "|    n_updates            | 1210      |\n",
            "|    policy_gradient_loss | 1.43e-10  |\n",
            "|    value_loss           | 9.42e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2KTimestep 500000: 1682.4s elapsed, Mean Reward: 3.2000\n",
            "\u001b[2K---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 297       |\n",
            "|    iterations           | 123       |\n",
            "|    time_elapsed         | 1690      |\n",
            "|    total_timesteps      | 503808    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.25e-07 |\n",
            "|    explained_variance   | -0.00251  |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.06e-06  |\n",
            "|    n_updates            | 1220      |\n",
            "|    policy_gradient_loss | -6.58e-10 |\n",
            "|    value_loss           | 9.24e-05  |\n",
            "---------------------------------------\n",
            "\u001b[2K\u001b[35m 100%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m503,808/500,000 \u001b[0m [ \u001b[33m0:28:02\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m297 it/s\u001b[0m ]\n",
            "\u001b[?25h\n",
            "============================================================\n",
            "‚úÖ Training completed in 1695.4 seconds (28.3 minutes)\n",
            "============================================================\n",
            "\n",
            "üíæ Model saved to: models/ppo_cloud_refinement_model_20260112_065746\n",
            "üîç Model params hash: -5177920756088945444\n",
            "\n",
            "============================================================\n",
            "üìä Evaluating PPO Agent\n",
            "============================================================\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 7225\n",
            "\n",
            "Generating predictions...\n",
            "üîç Using trained model for evaluation (params hash: -5177920756088945444)\n",
            "‚úÖ Evaluation completed in 1 steps\n",
            "\n",
            "============================================================\n",
            "üìà Performance Comparison:\n",
            "============================================================\n",
            "\n",
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.4187\n",
            "  Precision: 0.1706\n",
            "  Recall:    0.6232\n",
            "  F1-Score:  0.2679\n",
            "\n",
            "ü§ñ PPO Refined:\n",
            "  Accuracy:  0.8292\n",
            "  Precision: 0.1611\n",
            "  Recall:    0.0001\n",
            "  F1-Score:  0.0003\n",
            "\n",
            "üéØ Improvements:\n",
            "  F1-Score:  -99.90%\n",
            "  Accuracy:  +98.03%\n",
            "  Precision: -0.0095\n",
            "  Recall:    -0.6230\n",
            "\n",
            "üíæ Results saved to: results/ppo_training_results.json\n",
            "üíæ Refined cloud mask saved to: data/ppo_refined_cloud_mask.tif\n",
            "\n",
            "============================================================\n",
            "‚úÖ PPO Training and Evaluation Complete!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Run PPO training (main step - takes 1-2 hours)\n",
        "print(\"üöÄ Starting PPO training...\")\n",
        "print(\"This will take 1-2 hours with GPU\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python train_ppo.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7yfzCWR5Dpt4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yfzCWR5Dpt4",
        "outputId": "c9c4afed-b733-4d02-aca2-7269d593d10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-12 07:23:24.410071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768202604.431626   31076 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768202604.438035   31076 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768202604.454205   31076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202604.454240   31076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202604.454243   31076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202604.454246   31076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Loading model from: models/ppo_cloud_refinement_model_20260112_062116\n",
            "Loading data...\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 7225\n",
            "\n",
            "Evaluating on 7225 patches...\n",
            "  Progress: 1000/7225\n",
            "  Progress: 2000/7225\n",
            "  Progress: 3000/7225\n",
            "  Progress: 4000/7225\n",
            "  Progress: 5000/7225\n",
            "  Progress: 6000/7225\n",
            "  Progress: 7000/7225\n",
            "‚úÖ Evaluation complete!\n",
            "\n",
            "============================================================\n",
            "üìà RESULTS\n",
            "============================================================\n",
            "\n",
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.4187\n",
            "  Precision: 0.1706\n",
            "  Recall:    0.6232\n",
            "  F1-Score:  0.2679\n",
            "\n",
            "ü§ñ PPO Refined:\n",
            "  Accuracy:  0.1826\n",
            "  Precision: 0.1707\n",
            "  Recall:    0.9819\n",
            "  F1-Score:  0.2908\n",
            "\n",
            "üéØ F1-Score Improvement: +8.54%\n"
          ]
        }
      ],
      "source": [
        "!python evaluate_saved_model.py models/ppo_cloud_refinement_model_20260112_062116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "EP2RYcJqCuEX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP2RYcJqCuEX",
        "outputId": "418e380d-6edc-4125-c158-0d0004689e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-12 07:14:10.610183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768202050.631174   28746 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768202050.637559   28746 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768202050.653443   28746 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202050.653470   28746 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202050.653473   28746 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768202050.653476   28746 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Loading model from: models/ppo_cloud_refinement_model_20260112_065746\n",
            "Loading data...\n",
            "üîß Initializing CloudMaskRefinementEnv - Episode-per-Patch Design\n",
            "üìä Total patches: 7225\n",
            "\n",
            "Evaluating on 7225 patches...\n",
            "  Progress: 1000/7225\n",
            "  Progress: 2000/7225\n",
            "  Progress: 3000/7225\n",
            "  Progress: 4000/7225\n",
            "  Progress: 5000/7225\n",
            "  Progress: 6000/7225\n",
            "  Progress: 7000/7225\n",
            "‚úÖ Evaluation complete!\n",
            "\n",
            "============================================================\n",
            "üìà RESULTS\n",
            "============================================================\n",
            "\n",
            "üß† CNN Baseline:\n",
            "  Accuracy:  0.4187\n",
            "  Precision: 0.1706\n",
            "  Recall:    0.6232\n",
            "  F1-Score:  0.2679\n",
            "\n",
            "ü§ñ PPO Refined:\n",
            "  Accuracy:  0.1826\n",
            "  Precision: 0.1707\n",
            "  Recall:    0.9819\n",
            "  F1-Score:  0.2908\n",
            "\n",
            "üéØ F1-Score Improvement: +8.54%\n"
          ]
        }
      ],
      "source": [
        "!python evaluate_saved_model.py models/ppo_cloud_refinement_model_20260112_065746"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84ada1a3",
      "metadata": {
        "id": "84ada1a3"
      },
      "source": [
        "## 5Ô∏è‚É£ Results & Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e0513a",
      "metadata": {
        "id": "81e0513a"
      },
      "outputs": [],
      "source": [
        "# Display training results\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "results_file = Path('results/ppo_training_results.json')\n",
        "\n",
        "if results_file.exists():\n",
        "    with open(results_file) as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    cnn = results['cnn_baseline']\n",
        "    ppo = results['ppo_refined']\n",
        "    imp = results['improvements']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìà PPO TRAINING RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\nüß† CNN Baseline:\")\n",
        "    print(f\"  Accuracy:  {cnn['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {cnn['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {cnn['recall']:.4f}\")\n",
        "    print(f\"  F1-Score:  {cnn['f1_score']:.4f}\")\n",
        "\n",
        "    print(\"\\nü§ñ PPO Refined:\")\n",
        "    print(f\"  Accuracy:  {ppo['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {ppo['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {ppo['recall']:.4f}\")\n",
        "    print(f\"  F1-Score:  {ppo['f1_score']:.4f}\")\n",
        "\n",
        "    print(\"\\nüéØ Improvements:\")\n",
        "    print(f\"  F1-Score:  {imp['f1_score_percent']:+.2f}%\")\n",
        "    print(f\"  Accuracy:  {imp['accuracy_percent']:+.2f}%\")\n",
        "    print(f\"  Precision: {imp['precision_delta']:+.4f}\")\n",
        "    print(f\"  Recall:    {imp['recall_delta']:+.4f}\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "else:\n",
        "    print(\"‚ùå Results file not found\")\n",
        "    print(\"Make sure PPO training completed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1345f2",
      "metadata": {
        "id": "7b1345f2"
      },
      "outputs": [],
      "source": [
        "# Save to Google Drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "gdrive_results = '/content/drive/MyDrive/Colab_Data/thesis_results'\n",
        "Path(gdrive_results).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy results\n",
        "try:\n",
        "    shutil.copy('results/ppo_training_results.json', f'{gdrive_results}/ppo_results.json')\n",
        "    print(\"‚úÖ Results saved to Google Drive\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è  Could not save results to Google Drive\")\n",
        "\n",
        "# Copy model\n",
        "try:\n",
        "    import glob\n",
        "    model_files = glob.glob('models/ppo_cloud_refinement_model*')\n",
        "    for f in model_files:\n",
        "        shutil.copy(f, f'{gdrive_results}/{Path(f).name}')\n",
        "    print(\"‚úÖ Model saved to Google Drive\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è  Could not save model\")\n",
        "\n",
        "print(f\"\\nüìÇ Results at: {gdrive_results}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37b8fd9",
      "metadata": {
        "id": "b37b8fd9"
      },
      "source": [
        "## ‚úÖ Summary\n",
        "\n",
        "**Done!** Your PPO agent has been trained.\n",
        "\n",
        "**What happened:**\n",
        "1. ‚úÖ Loaded CNN baseline performance\n",
        "2. ‚úÖ Trained PPO with balanced reward structure\n",
        "3. ‚úÖ Evaluated on test data\n",
        "4. ‚úÖ Saved results and model\n",
        "\n",
        "**Key improvements in PPO:**\n",
        "- Better exploration with entropy coefficient\n",
        "- Policy gradient approach handles reward shaping better\n",
        "- Larger patch size (64√ó64) for better context\n",
        "- 100k timesteps for better convergence\n",
        "\n",
        "**Next steps:**\n",
        "1. Download results from Google Drive\n",
        "2. Analyze the refined cloud mask\n",
        "3. Consider hyperparameter tuning if needed\n",
        "\n",
        "**For thesis writing:**\n",
        "- See `thesis_recommendations.md` for advanced techniques\n",
        "- Check `training_results.json` for detailed metrics"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
