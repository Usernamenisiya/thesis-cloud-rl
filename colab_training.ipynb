{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe41eb39",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Clone & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/Usernamenisiya/thesis-cloud-rl.git\n",
    "%cd thesis-cloud-rl\n",
    "\n",
    "# Verify\n",
    "!pwd\n",
    "!ls -la | head -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "!pip install gymnasium  # Updated from deprecated gym\n",
    "\n",
    "import torch\n",
    "import stable_baselines3\n",
    "import rasterio\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced755bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n‚úÖ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974c679",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Setup Data from Google Drive\n",
    "\n",
    "**Create in Google Drive first:**\n",
    "- Folder: `Colab_Data/thesis_cloud_rl/`\n",
    "- Files: `sentinel2_image.tif`, `ground_truth.tif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ad7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create data directory\n",
    "Path('data').mkdir(exist_ok=True)\n",
    "\n",
    "# Copy from Google Drive\n",
    "gdrive_path = '/content/drive/MyDrive/Colab_Data/thesis_cloud_rl'\n",
    "\n",
    "if os.path.exists(gdrive_path):\n",
    "    !cp {gdrive_path}/sentinel2_image.tif data/ 2>/dev/null || true\n",
    "    !cp {gdrive_path}/ground_truth.tif data/ 2>/dev/null || true\n",
    "    print(\"‚úÖ Files copied from Google Drive\")\n",
    "else:\n",
    "    print(f\"‚ùå Path not found: {gdrive_path}\")\n",
    "    print(\"Please create folder structure in Google Drive first\")\n",
    "\n",
    "!ls -lh data/ 2>/dev/null || echo \"No data files yet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e4f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "files_ok = os.path.exists('data/sentinel2_image.tif') and os.path.exists('data/ground_truth.tif')\n",
    "\n",
    "if files_ok:\n",
    "    print(\"‚úÖ All data files present!\")\n",
    "    print(\"Ready to proceed.\")\n",
    "else:\n",
    "    print(\"‚ùå Missing data files\")\n",
    "    print(\"\\nüìÇ Create in Google Drive:\")\n",
    "    print(\"   MyDrive/Colab_Data/thesis_cloud_rl/\")\n",
    "    print(\"\\nUpload files:\")\n",
    "    print(\"   - sentinel2_image.tif\")\n",
    "    print(\"   - ground_truth.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc30ed",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Check CNN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f381a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and test CNN baseline\n",
    "from cnn_inference import load_sentinel2_image, get_cloud_mask\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "image = load_sentinel2_image('data/sentinel2_image.tif')\n",
    "cnn_prob = get_cloud_mask(image)\n",
    "\n",
    "with rasterio.open('data/ground_truth.tif') as src:\n",
    "    ground_truth = src.read(1)\n",
    "\n",
    "# Binary conversion\n",
    "gt_binary = (ground_truth > 0).astype(np.uint8)\n",
    "cnn_binary = (cnn_prob > 0.5).astype(np.uint8)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(gt_binary.flatten(), cnn_binary.flatten())\n",
    "precision = precision_score(gt_binary.flatten(), cnn_binary.flatten(), zero_division=0)\n",
    "recall = recall_score(gt_binary.flatten(), cnn_binary.flatten(), zero_division=0)\n",
    "f1 = f1_score(gt_binary.flatten(), cnn_binary.flatten(), zero_division=0)\n",
    "\n",
    "print(\"üß† CNN Baseline:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "print(f\"\\nüìä Ground truth: {gt_binary.sum():,} cloud pixels\")\n",
    "print(f\"üìä CNN predicted: {cnn_binary.sum():,} cloud pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c8f8a",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Pull Latest Code & Train PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2470c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest code with PPO improvements\n",
    "!git pull origin master\n",
    "print(\"‚úÖ Repository updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PPO training (main step - takes 1-2 hours)\n",
    "print(\"üöÄ Starting PPO training...\")\n",
    "print(\"This will take 1-2 hours with GPU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python train_ppo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ada1a3",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Results & Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "results_file = Path('results/ppo_training_results.json')\n",
    "\n",
    "if results_file.exists():\n",
    "    with open(results_file) as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    cnn = results['cnn_baseline']\n",
    "    ppo = results['ppo_refined']\n",
    "    imp = results['improvements']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìà PPO TRAINING RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüß† CNN Baseline:\")\n",
    "    print(f\"  Accuracy:  {cnn['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {cnn['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {cnn['recall']:.4f}\")\n",
    "    print(f\"  F1-Score:  {cnn['f1_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nü§ñ PPO Refined:\")\n",
    "    print(f\"  Accuracy:  {ppo['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {ppo['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {ppo['recall']:.4f}\")\n",
    "    print(f\"  F1-Score:  {ppo['f1_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nüéØ Improvements:\")\n",
    "    print(f\"  F1-Score:  {imp['f1_score_percent']:+.2f}%\")\n",
    "    print(f\"  Accuracy:  {imp['accuracy_percent']:+.2f}%\")\n",
    "    print(f\"  Precision: {imp['precision_delta']:+.4f}\")\n",
    "    print(f\"  Recall:    {imp['recall_delta']:+.4f}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"‚ùå Results file not found\")\n",
    "    print(\"Make sure PPO training completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1345f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Google Drive\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "gdrive_results = '/content/drive/MyDrive/Colab_Data/thesis_results'\n",
    "Path(gdrive_results).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy results\n",
    "try:\n",
    "    shutil.copy('results/ppo_training_results.json', f'{gdrive_results}/ppo_results.json')\n",
    "    print(\"‚úÖ Results saved to Google Drive\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Could not save results to Google Drive\")\n",
    "\n",
    "# Copy model\n",
    "try:\n",
    "    import glob\n",
    "    model_files = glob.glob('models/ppo_cloud_refinement_model*')\n",
    "    for f in model_files:\n",
    "        shutil.copy(f, f'{gdrive_results}/{Path(f).name}')\n",
    "    print(\"‚úÖ Model saved to Google Drive\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Could not save model\")\n",
    "\n",
    "print(f\"\\nüìÇ Results at: {gdrive_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b8fd9",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "**Done!** Your PPO agent has been trained.\n",
    "\n",
    "**What happened:**\n",
    "1. ‚úÖ Loaded CNN baseline performance\n",
    "2. ‚úÖ Trained PPO with balanced reward structure\n",
    "3. ‚úÖ Evaluated on test data\n",
    "4. ‚úÖ Saved results and model\n",
    "\n",
    "**Key improvements in PPO:**\n",
    "- Better exploration with entropy coefficient\n",
    "- Policy gradient approach handles reward shaping better\n",
    "- Larger patch size (64√ó64) for better context\n",
    "- 100k timesteps for better convergence\n",
    "\n",
    "**Next steps:**\n",
    "1. Download results from Google Drive\n",
    "2. Analyze the refined cloud mask\n",
    "3. Consider hyperparameter tuning if needed\n",
    "\n",
    "**For thesis writing:**\n",
    "- See `thesis_recommendations.md` for advanced techniques\n",
    "- Check `training_results.json` for detailed metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
